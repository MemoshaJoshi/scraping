{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapingbee import ScrapingBeeClient\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    client = ScrapingBeeClient(api_key='7RGXHBFZ5Z598EJFDXJT5F7JMXY15EGTQ2FSDKX53QL8Y8G8975BPAY1LT0EH86WRFI3WOOK75ILGQYE')\n",
    "    response = client.get(url)\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one_page(job_links):\n",
    "    data_list = []\n",
    "    \n",
    "    for job_list in job_links:\n",
    "        single_page_scrape = scrape_page(job_list)\n",
    "        #Job_Title\n",
    "        job_title = single_page_scrape.h2\n",
    "        if job_title is not None:\n",
    "            job_title = job_title.get_text('h2').strip()\n",
    "        else:\n",
    "            job_title = \" \"\n",
    "\n",
    "        #Job Url\n",
    "        job_url = job_list\n",
    "\n",
    "        #location\n",
    "        location = single_page_scrape.find('h6', {'class': 'location inline-block m-r-30 m-t-0'})\n",
    "        if location is not None:\n",
    "            location_txt = location.text.strip()\n",
    "        else:\n",
    "            location_txt = \" \"\n",
    "        \n",
    "        # posted\n",
    "\n",
    "        job_posted_time = None  # Initialize the variable with a default value\n",
    "        posted_element = single_page_scrape.find('h6', class_='semi-bold date-posted')\n",
    "\n",
    "        if posted_element is not None:\n",
    "            job_posted_time = posted_element.text.strip()\n",
    "        else:\n",
    "            job_posted_time = \"\"\n",
    "\n",
    "        # Define the date format\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "\n",
    "        # Check if the time is given in days\n",
    "        if \"Posted days\" in job_posted_time:\n",
    "            # Subtract the corresponding number of days from the current date\n",
    "            job_posted_date = datetime.now() - timedelta(days=int(job_posted_time.split()[0]))\n",
    "            # Format the resulting date as a string\n",
    "            job_posted_dates = job_posted_date.strftime(date_format)\n",
    "        # Check if the time is given in hours\n",
    "        elif \"Posted hours\" in job_posted_time:\n",
    "            # Subtract the corresponding number of hours from the current date\n",
    "            job_posted_date = datetime.now() - timedelta(hours=int(job_posted_time.split()[0]))\n",
    "            # Format the resulting date as a string\n",
    "            job_posted_dates = job_posted_date.strftime(date_format)\n",
    "        # If the time is not given in days or hours, use the current date\n",
    "        else:\n",
    "            job_posted_dates = datetime.now()\n",
    "\n",
    "        # Print the formatted date\n",
    "        print(job_posted_dates)\n",
    "        \n",
    "        # description\n",
    "\n",
    "        job_description = single_page_scrape.find(\"div\", class_=\"main-content\")\n",
    "        if job_description is not None:\n",
    "            description = job_description.find(\"div\", class_=\"job-description hidden-text shadow\")\n",
    "            if description is not None:\n",
    "                description_txt = description.text.strip()\n",
    "            else:\n",
    "                description_txt = \"\"\n",
    "        else:\n",
    "            description_txt = \"\"\n",
    "\n",
    "        data = {\n",
    "            'job_title':job_title,\n",
    "            'job_url':job_url,\n",
    "            'location':location_txt,\n",
    "            'posted':job_posted_dates,\n",
    "            'description':description_txt\n",
    "\n",
    "           \n",
    "        }\n",
    "        data_list.append(data)\n",
    "    print(data_list)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_to_scrape = 'Data Engineer'\n",
    "l='Texas'\n",
    "distance = 10\n",
    "posted = \"1d\"\n",
    "scrape = scrape_page(f\"https://search.linkup.com/search/results/data-engineer-jobs-in-texas?pageNum=1&posted=7d\")\n",
    "\n",
    "\n",
    "roles = [\"Data engineer\", \"Machine learning\"]\n",
    "cleaned_role = [role.replace(\" \", \"-\") for role in roles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To find page number\n",
    "search_details = scrape.find('div', {'class': 'search-details'})\n",
    "job_count_text = search_details.find('div').text.strip()\n",
    "job_count = int(job_count_text.split()[-2].replace(',', ''))\n",
    "page_number = math.ceil((job_count)/25)\n",
    "print(job_count)\n",
    "page_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page number 1\n",
      "['https://search.linkup.com/details/6eeaf54901814c7b69ebcec610324802', 'https://search.linkup.com/details/969f19899c2311c01b61461fcd040bce', 'https://search.linkup.com/details/052ed23cc8354f9b78d7df577ecb1717', 'https://search.linkup.com/details/fd1b92f4facb5bfabcb2d01311e4442e', 'https://search.linkup.com/details/e6bdfe673e3e719b82f7e20fbb6ef14f', 'https://search.linkup.com/details/51e8c63cda388b6293599c139e814975', 'https://search.linkup.com/details/645e51650bdc3b8eea13073772892acf', 'https://search.linkup.com/details/0886b61a8431957ac34a5d462eaa1a8f', 'https://search.linkup.com/details/5b8578a2679225298b96f7a61599b29d', 'https://search.linkup.com/details/226279dd270a59d9fec3928b6cf0379b', 'https://search.linkup.com/details/6cc8acb14cfa933e6ddb1a55ce78ff1a', 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'https://search.linkup.com/details/97c6da0f6fa1eff39d20351f74498d8c', 'https://search.linkup.com/details/154024681efab3b43b738f9b2d34458d', 'https://search.linkup.com/details/746e85b6d08e79bf573b254f799cb362', 'https://search.linkup.com/details/ebb3418fbf0feb9c546457a04759025f', 'https://search.linkup.com/details/4047f32514bccd3d78c0b1a34a92b771', 'https://search.linkup.com/details/b498fa46bcd32fa2c5110874e25a20de', 'https://search.linkup.com/details/25118b7ecf525153b0a8a7395e185f49', 'https://search.linkup.com/details/e7a2368a3ce77f92053b3d2f18a20b25', 'https://search.linkup.com/details/2093a8ba29661155f65323407f1801bb', 'https://search.linkup.com/details/51eef2a9e46cea99f3124494cbb3f916', 'https://search.linkup.com/details/e6f873d97749b467e84e3279efbf5083', 'https://search.linkup.com/details/aa2ef1a792d7433af78d8ff52d69e69e', 'https://search.linkup.com/details/16955240eb1184ade8dd38d0f0f1ff8a']\n",
      "Page number 2\n",
      "['https://search.linkup.com/details/6eeaf54901814c7b69ebcec610324802', 'https://search.linkup.com/details/969f19899c2311c01b61461fcd040bce', 'https://search.linkup.com/details/052ed23cc8354f9b78d7df577ecb1717', 'https://search.linkup.com/details/fd1b92f4facb5bfabcb2d01311e4442e', 'https://search.linkup.com/details/e6bdfe673e3e719b82f7e20fbb6ef14f', 'https://search.linkup.com/details/51e8c63cda388b6293599c139e814975', 'https://search.linkup.com/details/645e51650bdc3b8eea13073772892acf', 'https://search.linkup.com/details/0886b61a8431957ac34a5d462eaa1a8f', 'https://search.linkup.com/details/5b8578a2679225298b96f7a61599b29d', 'https://search.linkup.com/details/226279dd270a59d9fec3928b6cf0379b', 'https://search.linkup.com/details/6cc8acb14cfa933e6ddb1a55ce78ff1a', 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'https://search.linkup.com/details/97c6da0f6fa1eff39d20351f74498d8c', 'https://search.linkup.com/details/154024681efab3b43b738f9b2d34458d', 'https://search.linkup.com/details/746e85b6d08e79bf573b254f799cb362', 'https://search.linkup.com/details/ebb3418fbf0feb9c546457a04759025f', 'https://search.linkup.com/details/4047f32514bccd3d78c0b1a34a92b771', 'https://search.linkup.com/details/b498fa46bcd32fa2c5110874e25a20de', 'https://search.linkup.com/details/25118b7ecf525153b0a8a7395e185f49', 'https://search.linkup.com/details/e7a2368a3ce77f92053b3d2f18a20b25', 'https://search.linkup.com/details/2093a8ba29661155f65323407f1801bb', 'https://search.linkup.com/details/51eef2a9e46cea99f3124494cbb3f916', 'https://search.linkup.com/details/e6f873d97749b467e84e3279efbf5083', 'https://search.linkup.com/details/aa2ef1a792d7433af78d8ff52d69e69e', 'https://search.linkup.com/details/16955240eb1184ade8dd38d0f0f1ff8a', 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'https://search.linkup.com/details/1e1d498e06896934a5db16dd0c1d7d27', 'https://search.linkup.com/details/b524d9ceadd34a7fbf2d7be03790aa1c', 'https://search.linkup.com/details/d1d6e5ee9ffc53e0ac2367faa081b836', 'https://search.linkup.com/details/a87fafe7f5bcef6d2c5860e3aa5b01d4', 'https://search.linkup.com/details/ef3b7afd1bc4b5997400ed37548f700f', 'https://search.linkup.com/details/e16ec58ef3de98b7c051b49e76e2cc3b', 'https://search.linkup.com/details/06c35a8de2906a00de55b65a48572a1d', 'https://search.linkup.com/details/395af8e80be6ee0bc29faaae4ca7765d', 'https://search.linkup.com/details/0844fbee1216cea5db70414b659e37aa', 'https://search.linkup.com/details/f65802fd4cd3c4bd446caa276c2bba88', 'https://search.linkup.com/details/a90cd65b910ea281b261ff4d61d5b1c4', 'https://search.linkup.com/details/28fe132e5486811ccd0f7f7994878252', 'https://search.linkup.com/details/3d1712d0ac343b81cf4eff28858f7233', 'https://search.linkup.com/details/39b800fa55d4867f5df2c35425a4858f', 'https://search.linkup.com/details/b09ad8d15180c44bac902ab0f1cc8a4d', 'https://search.linkup.com/details/6693f06c2f8ea5f01454a7abc1eb62c0', 'https://search.linkup.com/details/0676baa176ed587a59d093070aec2ded', 'https://search.linkup.com/details/07c274be6f187eb8bcbe8f886ebc3c4a', 'https://search.linkup.com/details/f8073bcd7f025ec7bac10cdb1f216384', 'https://search.linkup.com/details/825bd31f92d52eac53c953f91bb3ed2e', 'https://search.linkup.com/details/e7ec0ae378918fe78acd0f6191a25d56', 'https://search.linkup.com/details/904357bf4df1453bd25b79272704d887', 'https://search.linkup.com/details/0bba9c9e75f0685be79493e1a0e7139a', 'https://search.linkup.com/details/99b001d48c042fdcb71b5e092336860a']\n",
      "Page number 3\n",
      "['https://search.linkup.com/details/6eeaf54901814c7b69ebcec610324802', 'https://search.linkup.com/details/969f19899c2311c01b61461fcd040bce', 'https://search.linkup.com/details/052ed23cc8354f9b78d7df577ecb1717', 'https://search.linkup.com/details/fd1b92f4facb5bfabcb2d01311e4442e', 'https://search.linkup.com/details/e6bdfe673e3e719b82f7e20fbb6ef14f', 'https://search.linkup.com/details/51e8c63cda388b6293599c139e814975', 'https://search.linkup.com/details/645e51650bdc3b8eea13073772892acf', 'https://search.linkup.com/details/0886b61a8431957ac34a5d462eaa1a8f', 'https://search.linkup.com/details/5b8578a2679225298b96f7a61599b29d', 'https://search.linkup.com/details/226279dd270a59d9fec3928b6cf0379b', 'https://search.linkup.com/details/6cc8acb14cfa933e6ddb1a55ce78ff1a', 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'https://search.linkup.com/details/97c6da0f6fa1eff39d20351f74498d8c', 'https://search.linkup.com/details/154024681efab3b43b738f9b2d34458d', 'https://search.linkup.com/details/746e85b6d08e79bf573b254f799cb362', 'https://search.linkup.com/details/ebb3418fbf0feb9c546457a04759025f', 'https://search.linkup.com/details/4047f32514bccd3d78c0b1a34a92b771', 'https://search.linkup.com/details/b498fa46bcd32fa2c5110874e25a20de', 'https://search.linkup.com/details/25118b7ecf525153b0a8a7395e185f49', 'https://search.linkup.com/details/e7a2368a3ce77f92053b3d2f18a20b25', 'https://search.linkup.com/details/2093a8ba29661155f65323407f1801bb', 'https://search.linkup.com/details/51eef2a9e46cea99f3124494cbb3f916', 'https://search.linkup.com/details/e6f873d97749b467e84e3279efbf5083', 'https://search.linkup.com/details/aa2ef1a792d7433af78d8ff52d69e69e', 'https://search.linkup.com/details/16955240eb1184ade8dd38d0f0f1ff8a', 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'https://search.linkup.com/details/1e1d498e06896934a5db16dd0c1d7d27', 'https://search.linkup.com/details/b524d9ceadd34a7fbf2d7be03790aa1c', 'https://search.linkup.com/details/d1d6e5ee9ffc53e0ac2367faa081b836', 'https://search.linkup.com/details/a87fafe7f5bcef6d2c5860e3aa5b01d4', 'https://search.linkup.com/details/ef3b7afd1bc4b5997400ed37548f700f', 'https://search.linkup.com/details/e16ec58ef3de98b7c051b49e76e2cc3b', 'https://search.linkup.com/details/06c35a8de2906a00de55b65a48572a1d', 'https://search.linkup.com/details/395af8e80be6ee0bc29faaae4ca7765d', 'https://search.linkup.com/details/0844fbee1216cea5db70414b659e37aa', 'https://search.linkup.com/details/f65802fd4cd3c4bd446caa276c2bba88', 'https://search.linkup.com/details/a90cd65b910ea281b261ff4d61d5b1c4', 'https://search.linkup.com/details/28fe132e5486811ccd0f7f7994878252', 'https://search.linkup.com/details/3d1712d0ac343b81cf4eff28858f7233', 'https://search.linkup.com/details/39b800fa55d4867f5df2c35425a4858f', 'https://search.linkup.com/details/b09ad8d15180c44bac902ab0f1cc8a4d', 'https://search.linkup.com/details/6693f06c2f8ea5f01454a7abc1eb62c0', 'https://search.linkup.com/details/0676baa176ed587a59d093070aec2ded', 'https://search.linkup.com/details/07c274be6f187eb8bcbe8f886ebc3c4a', 'https://search.linkup.com/details/f8073bcd7f025ec7bac10cdb1f216384', 'https://search.linkup.com/details/825bd31f92d52eac53c953f91bb3ed2e', 'https://search.linkup.com/details/e7ec0ae378918fe78acd0f6191a25d56', 'https://search.linkup.com/details/904357bf4df1453bd25b79272704d887', 'https://search.linkup.com/details/0bba9c9e75f0685be79493e1a0e7139a', 'https://search.linkup.com/details/99b001d48c042fdcb71b5e092336860a', 'https://search.linkup.com/details/0158f4163040bc2152a25502e91c3eea', 'https://search.linkup.com/details/b921021a730a0c7911959d44a20715da', 'https://search.linkup.com/details/a129bb5fd7d1bac4be5f974a9a8d337e', 'https://search.linkup.com/details/a4c5a01049a0a9b282a89c4db4f44fce', 'https://search.linkup.com/details/ab74ecd82277919d75465cec30220306', 'https://search.linkup.com/details/69e1f613f2caa1441c10b1c98d0c3db4', 'https://search.linkup.com/details/4a6f64bcb842b492b04b4a5ac946d91e', 'https://search.linkup.com/details/27a1d006d122fc245d974d027a59b8ab', 'https://search.linkup.com/details/66d0cb87c44dc9ee11269081f6394390', 'https://search.linkup.com/details/44b019c643d3e29251d4d472f2ec7041', 'https://search.linkup.com/details/be8f69dd74413f98fca89b47dacc7f52', 'https://search.linkup.com/details/8168074cc2bfb8ef8d3535ee4674d4ce', 'https://search.linkup.com/details/e05a3579c979b3a7cc3a0cbf6fcf98bf', 'https://search.linkup.com/details/2bd0537c5df16f00fa8c93da26d4233a', 'https://search.linkup.com/details/583774b8cbe80af81bd416a603d1b3e4', 'https://search.linkup.com/details/69f1094b7f43fc37163a6f1859e84ba8', 'https://search.linkup.com/details/e973139362d5b71b565e1a605e34d7e9', 'https://search.linkup.com/details/0456f2ff642e3f75c8060a03aa6c406f', 'https://search.linkup.com/details/7c59573b1db4da716c0b47f331b8ccaf', 'https://search.linkup.com/details/d4e3395b2be9e478c4a77b8cb7514e51', 'https://search.linkup.com/details/555fc6d02699636e884b3dc51142ccdc', 'https://search.linkup.com/details/aca3a0fa8155f3381d52cfede6fb584a', 'https://search.linkup.com/details/31881776170c6b6125c87cee919c2b12', 'https://search.linkup.com/details/81cd4d9569c17cddacdeb7032f6b9cc7', 'https://search.linkup.com/details/20781ebc7249db57f76b8225f81bc778']\n"
     ]
    }
   ],
   "source": [
    "job_links = []\n",
    "i = 1\n",
    "\n",
    "for cleaned_roles in cleaned_role:\n",
    "\n",
    "\n",
    "    while i <= 3:\n",
    "        print('Page number', i)\n",
    "        scrape_result = scrape_page(f\"https://search.linkup.com/search/results/{cleaned_roles}-jobs-in-texas?pageNum={i}&posted=7d\")\n",
    "\n",
    "        for link in scrape_result.find_all('a', class_='organic-link search-result-link'):\n",
    "            x = \"https://search.linkup.com\"+link.get('href')\n",
    "            job_links.append(x)\n",
    "\n",
    "        # for j in range(len(job_links)):\n",
    "        #     job_links[j] = 'https://search.linkup.com' + job_links[j]\n",
    "\n",
    "        i = i + 1\n",
    "        print(job_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-24 15:51:12.714567\n",
      "2023-07-24 15:51:17.681848\n",
      "2023-07-24 15:51:22.133385\n",
      "2023-07-24 15:51:42.792081\n",
      "2023-07-24 15:51:47.068751\n",
      "2023-07-24 15:51:51.988506\n",
      "2023-07-24 15:51:56.698928\n",
      "2023-07-24 15:52:01.506645\n",
      "2023-07-24 15:52:07.351960\n",
      "2023-07-24 15:52:12.332690\n",
      "2023-07-24 15:52:17.075797\n",
      "2023-07-24 15:52:21.269117\n",
      "2023-07-24 15:52:26.113647\n",
      "2023-07-24 15:52:30.279432\n",
      "2023-07-24 15:52:34.994176\n",
      "2023-07-24 15:52:40.415299\n",
      "2023-07-24 15:52:44.621391\n",
      "2023-07-24 15:52:49.254565\n",
      "2023-07-24 15:52:53.407355\n",
      "2023-07-24 15:52:57.893722\n",
      "2023-07-24 15:53:02.427402\n",
      "2023-07-24 15:53:06.939821\n",
      "2023-07-24 15:53:11.962738\n",
      "2023-07-24 15:53:16.419582\n",
      "2023-07-24 15:53:22.295821\n",
      "2023-07-24 15:53:26.296478\n",
      "2023-07-24 15:53:31.315174\n",
      "2023-07-24 15:53:39.739559\n",
      "2023-07-24 15:53:43.906100\n",
      "2023-07-24 15:53:48.721781\n",
      "2023-07-24 15:53:53.530939\n",
      "2023-07-24 15:53:58.249638\n",
      "2023-07-24 15:54:02.430012\n",
      "2023-07-24 15:54:07.044600\n",
      "2023-07-24 15:54:11.348942\n",
      "2023-07-24 15:54:16.056017\n",
      "2023-07-24 15:54:20.095044\n",
      "2023-07-24 15:54:25.785168\n",
      "2023-07-24 15:54:30.570427\n",
      "2023-07-24 15:54:35.613340\n",
      "2023-07-24 15:54:40.018184\n",
      "2023-07-24 15:54:47.393173\n",
      "2023-07-24 15:54:52.403710\n",
      "2023-07-24 15:54:57.281977\n",
      "2023-07-24 15:55:02.078818\n",
      "2023-07-24 15:55:07.867881\n",
      "2023-07-24 15:55:12.679583\n",
      "2023-07-24 15:55:22.455120\n",
      "2023-07-24 15:55:28.355885\n",
      "2023-07-24 15:55:33.158781\n",
      "2023-07-24 15:55:37.800659\n",
      "2023-07-24 15:55:42.482074\n",
      "2023-07-24 15:55:47.702890\n",
      "2023-07-24 15:55:52.516134\n",
      "2023-07-24 15:55:57.191148\n",
      "2023-07-24 15:56:01.732062\n",
      "2023-07-24 15:56:06.339551\n",
      "2023-07-24 15:56:11.157102\n",
      "2023-07-24 15:56:16.036724\n",
      "2023-07-24 15:56:20.775649\n",
      "2023-07-24 15:56:25.894185\n",
      "2023-07-24 15:56:30.920377\n",
      "2023-07-24 15:56:35.422423\n",
      "2023-07-24 15:56:40.130818\n",
      "2023-07-24 15:56:44.837570\n",
      "2023-07-24 15:56:49.682900\n",
      "2023-07-24 15:56:53.956178\n",
      "2023-07-24 15:56:58.857795\n",
      "2023-07-24 15:57:06.715289\n",
      "2023-07-24 15:57:11.566106\n",
      "2023-07-24 15:57:16.484332\n",
      "2023-07-24 15:57:21.178644\n",
      "2023-07-24 15:57:26.210407\n",
      "2023-07-24 15:57:31.292976\n",
      "2023-07-24 15:57:36.346560\n",
      "[{'job_title': 'Data Engineer', 'job_url': 'https://search.linkup.com/details/6eeaf54901814c7b69ebcec610324802', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 12, 714567), 'description': 'Req ID: 246917 \\nNTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.\\nWe are currently seeking a Data Engineer to join our team within the Eastern or Central Time Zones of United States (US). (REMOTE)\\nCandidates for the Data Engineer role need a strong technical foundation in database architecture, database infrastructure, configuration, installation, and practice, hands-on experience with building and supporting highly available and scalable systems. Candidates must have strong knowledge and experience of data replication strategies and technologies. \\nResponsibilities:\\n\\nThis role supports the day-to-day development activities by working as a member of a software engineering team.\\nThe Data Engineer will perform as a hands-on Database Technologist with both Database Development and Database Administration experience.\\nCreate, troubleshoot, and optimize SQL queries, stored packages/procedures, views, functions, etc. \\nAnalyze query execution plans for performance improvements. \\nCreate and review SQL code from performance, scalability, and security perspectives.\\nEnsuring data integrity \\nRecommend improvements in the reporting and batch processing code. \\nCreating solutions and implementing complex data projects with a focus on collecting, parsing, managing, analyzing, and visualizing large sets of data using multiple platforms. \\nWork with business owners to identify information needed. \\nCollaborate with other software engineers to create optimized SQL code.'}, {'job_title': 'Data Engineer', 'job_url': 'https://search.linkup.com/details/969f19899c2311c01b61461fcd040bce', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 17, 681848), 'description': \"Job Title: (Back End) Data Engineer\\nLocation: Houston, Texas 1430 Enclave \\nJob Description\\nThe SLB (Back End) Data Engineer develops the back end of a data processing application, i.e., handling the logic, database interactions, user authentication, configuration, data processing, performance and scalability tuning etc. The Data engineer implements given requirements as per standard engineering practices and company standards, performs requirements analysis and design, as well as evaluates technologies and patterns suitable for the solution. The position reports to the software project manager.\\nResponsibilities\\n\\nContributes to and supports re-use through common components that are well documented and tested. \\nProvide timely corrective actions on all assigned defects and issues.\\nContributes to development plan by providing task estimates.\\nDesign and implement solutions for problems arising out of large-scale and high velocity data processing.\\nEnsure end-to-end ownership of all tasks being aligned.\\nDesign, build & maintain efficient, reusable & reliable code.\\nTest implementation, troubleshoot & correct problems.\\nCapable of working as an individual contributor and within team too.\\nEnsure high quality software development with complete documentation and traceability.\\nFulfil organizational responsibilities (sharing knowledge & experience with other teams/ groups).\\nBuild robust, fault-tolerant data pipelines that process, clean, transform and aggregate data into consumable storage format.\\nGood understanding of database technologies, able to write complex and scalable queries.\\nPerformance tuning and testing.\\nProficiency in Google cloud technologies. Proficiency in python, C# programing languages.\\nFamiliar with Azure DevOps.\\nExcellent communication skills.\\nMinimum 3 years' experience as Data Engineer, Cloud software engineer, or similar.\\n\\nBackground\\n\\nBachelor's degree or higher in Computer Science or related with minimum 3 years working experience.\\n\\nSkills and knowledge\\n\\nMandatory\\n2 years python programing experience. \\n2 years Google Cloud experience. \\nExcellent communication skills, team player.\\nFamiliar with Azure DevOps, Git, CI/CD.\\nStrong GCP experience with BigQuery, Pub/Sub, Kubernetes Engine, Cloud Function, Cloud Run, Cloud Storage, and other data products.\\nExperience in database technology, proficient in writing SQL queries.\\nExperience in building ETL data processing and data ingestion pipelines in GCP. \\nProficient in python programming.\\nProficient in C# programming.\\nExperienced in application profiling, bottleneck analysis and performance tuning.\\nExperience in containerization and orchestration (such as Docker, Kubernetes)\\n\\nExperience in implementing automated testing and validation processes for data pipelines on GCP.\\nMust have a technical bachelor's degree (Computer Science, IT, Electrical Engineer, etc.)\\n\\nNice to have\\nBuild, test and maintain tools, infrastructure to support Data science initiatives.\\nExperience in PowerBI.\\nExperience in Dataiku.\\nExperience in Azure cloud.\"}, {'job_title': 'Data Engineer', 'job_url': 'https://search.linkup.com/details/052ed23cc8354f9b78d7df577ecb1717', 'location': 'Irving, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 22, 133385), 'description': 'At Greystar, we\\'ve launched a program aimed at bringing the real estate leasing experience for residents into the digital era.\\nAs a data engineer, you will join the global Enterprise Data Organization and Apex Organization, which builds a resident-centric ecosystem of products that enable a 360 view of the prospect/resident to improve operational efficiency and resident satisfaction.\\nYou will provide data capabilities and build out a common data model that supports 360 view of our prospect/resident powered by Azure SQL, Synapse data warehouse, and Microsoft Customer Insights. You will also work and support our industry-changing products and features designed to make shopping for an apartment more streamlined, e-commerce friendly, and efficient.\\nWith your help, we will improve our customer\\'s apartment shopping journey and enable business intelligence to help us personalize the apartment shopping experience for our residents.\\nThe successful candidate will have a strong sense of teamwork, personal integrity, accountability, and the ability to understand business functions and requirements, translating to innovative working applications while navigating competing priority tradeoffs.\\nJOB DESCRIPTION\\nWhat You Will do\\n\\n\\n100% hands-on development – develop and unit test database code, including but not limited to T-SQL, stored procedures, functions and views.\\n\\n\\nCreate and maintain database structures\\n\\n\\nAs part of the Scrum team, you will work with BAs, Scrum Master, Leads and engineers to provide data support to our products and build creative solutions and features to move our product roadmap forward.\\n\\n\\nParticipate in the design of databases, using first, second or third normalized form as needed to support business requirements.\\n\\n\\nCreate and deploy ADF pipelines, adhering to Greystar\\'s standards and documented best practices.\\n\\n\\nPerform analysis of complex data and document findings.\\n\\n\\nPrepare data for prescriptive and predictive modeling.\\n\\n\\nCombine raw data from different external sources.\\n\\n\\nCollaborate with data scientists and architects.\\n\\nPlay a direct role in the maintenance, technical support, documentation, and administration of databases.\\n\\nWho You Are\\n\\n\\nStrong problem solver with excellent communication skills\\n\\n\\nHave a growth mindset with a desire to learn and embrace challenges.\\n\\n\\nInnovative and passionate about your work\\n\\n\"Self-starter\" attitude and the ability to make decisions independently.\\n\\nWhat You Have\\n\\n\\nMinimum of 3 years of relevant experience in database design and development\\n\\n\\nMinimum of 2 years of relevant experience in working with Azure PaaS databases\\n\\n\\nMinimum of 1 year of relevant experience working with Azure Data Factory.\\n\\n\\nMinimum of 1 year of relevant experience working with Azure Data Lakes Gen 2.\\n\\n\\nWorking knowledge of Azure Synapse.\\n\\n\\nPreferred: Experience with Customer Insights and/or Dataverse.\\n\\n\\nPreferred: Experience with Power BI.\\n\\nBachelor\\'s in Computer Science, related field, or equivalent work experience\\n\\nTechnical Pre-screening test will be required for all candidates\\nWhat the Right Candidate will Enjoy!\\n\\n\\n100% Remote flexibility!\\n\\n\\nCompetitive pay, benefits, and overall compensation packages.\\n\\n\\nThe chance to be part of a technology team for a thriving organization that prioritizes accountability, respect, and operational excellence!\\n\\nThe opportunity to join a thriving, highly visible organization during its technology transformation!\\n\\nThe base compensation rate will vary based on education, experience, skills, and geographic location, as applicable. \\nGreystar seeks to attract, recruit, advance and retain top talent. Greystar\\'s compensation strategy is tailored to appropriately reward the skillset and experience that a team member will bring to the organization.\\nDepending on the position offered, regular full-time and part-time team members may be eligible to participate in a bonus program in addition to their salary. Team members may also participate in the 401k plan, once eligible. Regular, full-time team members are offered a range of medical, financial, and other benefits from which to choose.\\nFor Union and Prevailing Wage roles compensation and benefits may vary from the listed information above due to Collective Bargaining Agreements and/or local governing authority.\\nGreystar will consider for employment qualified applicants with arrest and conviction records.'}, {'job_title': 'Data Engineer', 'job_url': 'https://search.linkup.com/details/fd1b92f4facb5bfabcb2d01311e4442e', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 42, 792081), 'description': 'Position Summary\\nAre you an experienced, passionate pioneer in technology who wants to work in a collaborative environment? As an experienced Data Engineer you will have the ability to share new ideas and collaborate on projects as a consultant without the extensive demands of travel. If so, consider an opportunity with Deloitte under our Project Delivery Talent Model. Project Delivery Model (PDM) is a talent model that is tailored specifically for long-term, onsite client service delivery.\\nWork you\\'ll do/Responsibilities\\nThis is an opportunity to join a fast-paced team that plays a key role in the overall success of our client\\'s organization through technology enablement. You\\'ll play a critical part in driving the technology vision forward and ensuring that we execute across multiple initiatives. \\n\\nYou will be responsible for collecting, analyzing, and reporting on customer insights. From this data you will generate insights into how customers interact with our clients\\' products and use these insights to drive improvements to user-facing features\\nCommunicate regularly with Engagement Managers (Directors), project team members, and representatives from various functional and / or technical teams, including escalating any matters that require additional attention and consideration from engagement management \\nIndependently and collaboratively lead client engagement workstreams focused on improvement, optimization, and transformation of processes including implementing leading practice workflows, addressing deficits in quality, and driving operational outcomes\\n\\nThe Team \\nAs a part of the US Strategy & Analytics Offering Portfolio, the AI & Data Operations offering provides managed AI, Intelligent Automation, and Data DevOps services across the advise-implement-operate spectrum.\\nQualifications\\nRequired\\n\\nBachelor\\'s degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience\\n5+ years of prior experience in a Senior Data Engineering role or as a technical lead on Data Engineering projects\\nAdvanced experience working with both relational databases (e.g. Teradata, Vertica, etc.) and Big Data platforms (e.g. Hadoop, etc) require\\nAdvanced hands-on experience with Java and Scala programming languages\\nIntermediate understanding of OLAP systems and Data warehousing & Data modelling concepts\\nAdvanced experience working on Big Data, BI or Analytics related projects as a technical lead and individual contributor\\nAdvanced knowledge of SQL/Hive/Trino\\nIntermediate experience with various performance tuning techniques in Spark/Hive/Teradata\\nAdvanced experience with job schedulers developing shell scripts, CRON, Airflow jobs to automate data workflows \\nExperienced in leading a team of data engineers or individually developing technical solutions to business problems\\nExperienced in leading a team of data engineers or individually working on the implementation of data integration requirements and developing the pipeline of data from raw to curation layers including the cleansing, transformation, derivation, and aggregation of data\\nAbility to communicate effectively (written and spoken)\\nAbility to work with the multi-location development teams and self-manage individual and others work\\nLimited immigration sponsorship may be available\\nAbility to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve\\nRole is remote\\n\\nPreferred\\n\\nAnalytical/ Decision Making Responsibilities\\nAnalytical ability to manage multiple projects and prioritize tasks into manageable work products\\nCan operate independently or with minimum supervision\\nExcellent Written and Communication Skills\\nAbility to deliver technical demonstrations\\n\\nRecruiting tips\\nFrom developing a stand out resume to putting your best foot forward in the interview, we want you to feel prepared and confident as you explore opportunities at Deloitte. Check out recruiting tips from Deloitte recruiters.\\nBenefits\\nAt Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.\\nOur people and culture\\nOur diverse, equitable, and inclusive culture empowers our people to be who they are, contribute their unique perspectives, and make a difference individually and collectively. It enables us to leverage different ideas and perspectives, and bring more creativity and innovation to help solve our client most complex challenges. This makes Deloitte one of the most rewarding places to work. Learn more about our inclusive culture.\\nOur purpose\\nDeloitte\\'s purpose is to make an impact that matters for our clients, our people, and in our communities. We are creating trust and confidence in a more equitable society. At Deloitte, purpose is synonymous with how we work every day. It defines who we are. We are focusing our collective efforts to advance sustainability, equity, and trust that come to life through our core commitments. Learn more about Deloitte\\'s purpose, commitments, and impact.\\nProfessional development\\nFrom entry-level employees to senior leaders, we believe there\\'s always room to learn. We offer opportunities to build new skills, take on leadership opportunities and connect and grow through mentorship. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.\\nAs used in this posting, \"Deloitte\" means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see www.deloitte.com/us/about for a detailed description of the legal structure of Deloitte LLP and its subsidiaries.\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.\\nRequisition code: 150264'}, {'job_title': 'Data Engineer II', 'job_url': 'https://search.linkup.com/details/e6bdfe673e3e719b82f7e20fbb6ef14f', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 47, 68751), 'description': \"Company: \\nCox Automotive - USA\\nJob Family Group:\\nEngineering / Product Development\\nJob Profile: \\nSr Data Engineer\\nManagement Level: \\nIndividual Contributor\\nTravel %:\\nYes, 5% of the time\\nWork Shift:\\nDay (United States of America)\\nJob Description:\\nJob Title: Data Engineer II\\nCompany: Cox Automotive\\nLocation: Semi-Remote (Atlanta, Draper, or Austin based)\\nJob Type: Full-Time\\nJob Description:\\nWe are seeking a highly skilled and motivated Data Engineer II to join our Cox Automotive team. As a Data Engineer, you will be responsible for designing, developing, and maintaining data pipelines and analytical solutions. You will collaborate with cross-functional teams to ensure the availability, reliability, and scalability of our data infrastructure. The ideal candidate will have a strong background in SQL, Python, ELT development, and experience with AWS analytical services.\\nResponsibilities:\\nDesign, develop, and maintain data pipelines to process and transform large data sets in a database.\\nExtract and manipulate data using Python, ensuring accuracy, efficiency, and reliability.\\nDevelop ELT workflows in Snowflake or Redshift, optimizing performance and scalability.\\nBuild key data pipelines using AWS analytical services such as S3, EC2, EMR, Glue, and Athena.\\nCollaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver robust solutions.\\nImplement data quality controls and validation processes to ensure data accuracy and integrity.\\nMonitor and troubleshoot data pipelines and infrastructure to identify and resolve issues promptly.\\nStay up-to-date with industry trends and best practices in data engineering and recommend improvements to existing processes.\\nDocument technical specifications, data flows, and operational procedures.\\nRequirements:\\nBachelor's degree in Computer Science, Engineering, or a related field (or equivalent practical experience).\\nMinimum of 3 years of experience as a Data Engineer or a similar role.\\nProficient in SQL and manipulating large datasets in a database.\\nStrong experience in extracting and manipulating data using Python.\\nSolid understanding of ELT development, preferably in Snowflake or Redshift.\\nExpertise in building data pipelines using AWS analytical services such as S3, EC2, EMR, Glue, and Athena.\\nExperience in Spark\\nPreferred:\\nExperience with ELT orchestration using Airflow.\\nFamiliarity with any Reporting Tools, preferably MicroStrategy.\\nKnowledge of New Relic setup and maintenance.\\nExperience using GIT for version control.\\nFamiliarity with Rally for project management.\\nSkills and Abilities:\\nStrong analytical and problem-solving skills.\\nExcellent communication and collaboration abilities.\\nDetail-oriented with a focus on data accuracy and quality.\\nAbility to work in a fast-paced, dynamic environment.\\nSelf-motivated with a passion for continuous learning and professional growth.\\nIf you are a highly motivated Data Engineer with a strong technical background and a passion for data, we would love to hear from you. Apply today to join our talented team!\\nDrug Testing:\\nTo be employed in this role, you'll need to clear a pre-employment drug test. Cox Automotive does not currently administer a pre-employment drug test for marijuana for this position. However, we are a drug-free workplace, so the possession, use or being under the influence of drugs illegal under federal or state law during work hours, on company property and/or in company vehicles is prohibited.\\nAbout Us:\\nThrough groundbreaking technology and a commitment to stellar experiences for drivers and dealers alike, Cox Automotive employees are transforming the way the world buys, owns, sells – or simply uses – cars. Cox Automotive employees get to work on iconic consumer brands like Autotrader and Kelley Blue Book and industry-leading dealer-facing companies like vAuto and Manheim, all while enjoying the people-centered atmosphere that is central to our life at Cox. Benefits of working at Cox may include health care insurance (medical, dental, vision), retirement planning (401(k)), and paid days off (sick leave, parental leave, flexible vacation/wellness days, and/or PTO). For more details on what benefits you may be offered, visit our benefits page. Cox is an Equal Employment Opportunity employer – All qualified applicants/employees will receive consideration for employment without regard to that individual's age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law. Cox provides reasonable accommodations when requested by a qualified applicant or employee with disability, unless such accommodations would cause an undue hardship.\"}, {'job_title': 'Data Engineer H/F', 'job_url': 'https://search.linkup.com/details/51e8c63cda388b6293599c139e814975', 'location': 'Paris, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 51, 988506), 'description': 'About Us\\nESN : +25 ans d\\'existence, +1000 experts répartis dans toute la France (du Nord au Sud !)\\nNos Expertises : Infrastructure IT, Opérations IT, Cybersécurité Opérationnelle, Observabilité\\nUne Entreprise Humaine : Parce que votre épanouissement professionnel et personnel est notre priorité, nous vous accompagnons en vous assurant un management de confiance et de proximité.\\nNos engagements RSE : Engagement Social, Environnemental et Sociétal\\nEn savoir plus : https://www.itsservices.fr/ \\nAbout the Job\\nDe belles missions vous attendent chez nos clients grands comptes sur des environnements riches et variés :\\nEn tant que Data Engineer, vous contribuez à maintenir l\\'écosystème du Datawarehouse en étroite collaboration avec les équipes techniques, en plus d\\'assurer la collecte, le stockage, la transformation et l`analyse des données avec les équipes d\\'analystes et les métiers.\\nVos Missions:\\n\\nExtraire les données pertinentes des sources de données internes et externes, en utilisant les outils appropriés.\\nDévelopper d\\'outils de récupération et d\\'intégration des données d\\'un datalake et de sources variées (Sharepoint Online, FTP, APIs …) de différents formats (Connecteur Hive, CSV, XLS, JSON,GeoJSON, DBF ...) avec Python, Talend, SQL, JupyterLab\\nGérer pipelines et maintenance des scripts pour la mise à jour des flux de données.\\nOptimiser les performances l\\'écosystème du Datawarehouse.\\nMettre en place les procédures de contrôle qualité pour garantir l`intégrité et la fiabilité des données.\\nGérer (MCO) de l\\'écosystème. Renforcement des processus et chaînes de traitements. Création de Dashboard PowerBI.\\nRésoudre des incidents et anomalies des chaînes de traitements, des rapports PowerBi des clients.\\nCollaborer avec les équipes métier pour comprendre les besoins et proposer les solutions.\\nTravailler en étroite collaboration avec les équipes d`analyse de données pour fournir des données fiables, rédiger des Notebooks d\\'analyse et la documentation détaillée des données développées en assurant l\\'accessibilité et la transparence.\\nDocumenter les processus et les spécifications techniques, pour faciliter la compréhension et la collaboration entre les équipes.\\n\\nAbout US\\nESN : +25 ans d\\'existence, +1000 experts répartis dans toute la France (du Nord au Sud !) \\nNos Expertises : Infrastructure IT, Opérations IT, Cybersécurité Opérationnelle, Observabilité\\nUne Entreprise Humaine : Parce que votre épanouissement professionnel et personnel est notre priorité, nous vous accompagnons en vous assurant un management de confiance et de proximité.\\nNos engagements RSE : Engagement Social, Environnemental et Sociétal \\nEn savoir plus : https://www.itsgroup.com\\nAbout the Process :\\n\\nUn premier call pour faire connaissance\\nUn entretien RH\\nUn entretien Technique\\nUne proposition salariale\\n\\nAbout \" les petits + d\\'ITS Services \" :\\nChez nous …\\n\\nOn coopte : prime de cooptation de 2000 €\\nOn transmet : Communauté d\\'Experts\\nOn partage : Events et Afterworks\\nOn évolue : Management technique de Proximité et Formations\\n\\nEt c\\'est pas fini … ? \\n\\nAccords RTT (1 jour/ mois) et Télétravail (2 à 3 jours/ semaine)\\nPrise en charge pour moitié du titre de transport et de la Mutuelle\\nCarte titres restaurants Edenred\\n\\nChez ITS Services, nous célébrons la diversité et nous nous engageons à créer un environnement inclusif pour nos collaborateurs. \\nHandi-bienveillante, ITS Services accueille des collaborateurs en situation de handicap. \\nLet\\'s talk about You, the Job & Us ! \\nVous disposez des compétences suivantes :\\nMaitrise des systèmes de gestion de bases de données (relationnelles), et des languages associés (sql, psql …).\\nAdministration Linux (CentOS).\\nSolides compétences en programmation, en particulier en Python.\\nConnaissance des produits, Talend, Jira, Confluence (outillage EDF).\\nConnaissances de l\\'Agilité (SCRUM).\\nCapacité à travailler de manière autonome et à gérer plusieurs projets simultanément, collaborer efficacement avec les membres de l`équipe technique et les parties prenantes métier.\\nAbout You\\n\\nDiplômé d\\'une école d\\'ingénieurs ou équivalent BAC+5 universitaire\\nVous justifiez d\\'une expérience réussie de minimum 2 à 3 ans en tant que Data Engineer .\\nYou can say more than \" hello \" in English\\nVous avez un super mindset, êtes curieux et motivé … \\nAlors, il faut qu\\'on discute !\\n\\nAbout The Process\\n\\nUn premier call pour faire connaissance\\nUn entretien RH\\nUn entretien Technique\\nUne proposition salariale\\n\\nAbout \" les petits + d\\'ITS Services \" :\\nChez nous …\\n\\nOn coopte : prime de cooptation de 2000 €\\nOn transmet : Communauté d\\'Experts\\nOn partage : Events et Afterworks\\nOn évolue : Management technique de Proximité et Formations\\n\\nEt c\\'est pas fini …\\n\\nAccords RTT (1 jour/ mois) et Télétravail (2 à 3 jours/ semaine)\\nPrise en charge pour moitié du titre de transport et de la Mutuelle\\nCarte titres restaurants Edenred\\n\\nChez ITS Services, nous célébrons la diversité et nous nous engageons à créer un environnement inclusif pour nos collaborateurs.\\nHandi-bienveillante, ITS Services accueille des collaborateurs en situation de handicap.\\nLet\\'s talk about You, the Job & Us !'}, {'job_title': 'Senior Data Engineer', 'job_url': 'https://search.linkup.com/details/645e51650bdc3b8eea13073772892acf', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 51, 56, 698928), 'description': \"Where you fit in\\nYou will be part of a community of experts in different capabilities in Information Digital Engineering driving ideas to reality embedding AI in every part of our organisation from making our existing businesses more effective and efficient and make us competitive as we accelerate the development of the next generation of clean energy solutions. The Information Data & Analytics (IDA) family is a family of Data experts who create business value every day with their cutting[1]edge knowledge. We maximize value from information & data, using our domain knowledge & deep technical expertise in market leading information & data tools, to deliver actionable data driven insights for Shell. Want to join us at Shell to enable Powering Progress for a better future? With you part of our team, we will accelerate our digital journey at Shell.\\nWhat's the role?\\nAs a Senior Data engineer, you are a subject matter expert who is curious and an innovative thinker to mentor young professionals. You are a key person to convert Vision and Data Strategy for IT solutions and deliver them. With your knowledge you will help create data-driven thinking within the organization, not just within IT teams, but also in the wider Shell stakeholder community.\\nAccountabilities\\n\\nCommunicate with both technical developers and business managers and gain respect and trust of leaders and staff.\\nActively deliver the roll-out and embedding of Data Foundation initiatives in support of the key business programs advising on the technology and using leading market standard tools.\\nCoordinate the change management process, incident management and problem management process.\\nEnsure traceability of requirements from Data through testing and scope changes, to training and transition.\\nDrive implementation efficiency and effectiveness across the pilots and future projects to minimize cost, increase speed of implementation and maximize value delivery.\\n\\nWhat we need from you?\\n\\nMust have legal authorization to work in the US on a full-time basis for anyone other than current employer\\nMinimum of eight (7) years' experience in IT Industry\\nBachelor's Degree is preferred\\n\\nExpected Skills \\nProven technology champion in working with relational, Data warehouses databases, query authoring (SQL) as well as working familiarity with a variety of databases. Experience/Knowledge in working with NoSQL databases and can create E2E pipelines.\\nHighly Experienced in building and optimizing complex queries. Good with manipulating, processing and extracting value from large, disconnected datasets.\\nProven Experience in working any one of the data engineering technologies and ADLS, ADF, Azure Databricks, Azure SQL, Synapse, SAP HANA. Your experience in handling big data sets and big data technologies will be an asset.\\nProven champion with in-depth knowledge of any one of the scripting languages: Python, SQL, Spark-SQL/ PySpark.\\nVery Good understanding in Data Foundation initiatives, like Modelling, Data Quality Management, Data Governance, Data Maturity Assessments and Data Strategy in support of the key business stakeholders\\nLeadership Skills \\nWe value Leadership in Shell and have opportunities for you to explore, develop and build on your abilities. As part of our team, you will:\\nBe self-motivated, innovative, and very good in taking up new initiatives and driving them to closure.\\nCommunicate skilfully with both technical developers, architects, and business stake holders.\\nUnderstand well- data foundation initiatives like data modelling, data quality, data governance, data maturity assessments and data strategy in support of the key business stake holders.\\nWork with source control technologies (such as GITHUB, Azure DevOps)\\nHave experience in working with AGILE, KANBAN methodologies\\nNice to Have Skills \\nPreviously created or enhanced CI/CD build and releases pipelines.\\nExperience in working with scripting languages such as YAML, PowerShell, Terraform etc.\\nExperience with big data tools: Kafka, Hadoop, Spark and similar technologies. Experience with stream-processing systems.\\nExperience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow and more.\\nCore Python skills like: Numpy, Panda, Django\\nCertification in Azure\\nFor regular full-time or regular part-time employees of the Company (participating companies as listed in the Summary Plan Description), insurance coverage options include medical, dental, vision coverage, life Insurance, Business Travel Accident Insurance, and Occupational Accidental Death Benefit programs. Employees also participate in a company pension plan and a 401(k) plan. Paid leave includes up to 6 weeks of paid vacation time, up to 11 paid holidays, and parental leave offering 16 weeks of paid leave to birthing mothers, and 8 weeks of paid leave for non-birthing parents. Additionally, employees are eligible for disability leave for up to 52 weeks at 100% or 50% of base pay. Shell also offers other compensation such financial reimbursement for adoption, wellness, education, and personal learning expenses, and some roles are eligible for discretionary long-term incentives. For interns, eligible benefits include medical, dental, and vision coverage, life insurance, Business Travel Accident Insurance, and Occupational Accidental Death Benefit programs; participation in a 401(k) plan; and paid leave for up to 11 paid holidays. Additional information on Shell's US benefit programs can be found at https://www.shell.us/careers/about-careers-at-shell/rewards-and-benefits.html\\nCOMPANY DESCRIPTION\\nShell is a global group of energy and petrochemicals companies with over 90,000 employees in more than 70 countries and territories. In the US, we have operated for over a century and are a major oil and gas producer onshore and in the Gulf of Mexico, a recognized innovator in exploration and production technology, and a leading manufacturer and marketer of fuels, natural gas and petrochemicals. We deliver energy responsibly; operate safely with respect to our neighbours and work to minimize our environmental impact. We are in search of remarkable people who will thrive in a diverse and inclusive work environment to deliver exciting projects locally and globally. People who are passionate about exploring new frontiers. Innovators and pioneers. People with the drive to help shape our future. Because remarkable people achieve remarkable things.\\nAn innovative place to work\\nThere's never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change.\\nJoin us and you'll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy or developing technology that helps the world to use energy more efficiently.\\nAn inclusive place to work\\nTo power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we're nurturing an inclusive environment – one where you can express your ideas, extend your skills and reach your potentials.\\n\\nWe're creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply, and we'll take it from there.\\nWe're closing the gender gap – whether that's through action on equal pay or by enabling more women to reach senior roles in engineering and technology.\\nWe're striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity.\\nWe consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application.\\n\\nA rewarding place to work\\nCombine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice.\\nWe're huge advocates for career development. We'll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible.\"}, {'job_title': 'Big Data Engineer', 'job_url': 'https://search.linkup.com/details/0886b61a8431957ac34a5d462eaa1a8f', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 1, 506645), 'description': \"Docyt, a fast-growing FinTech startup based in Silicon Valley, is seeking a highly motivated Big Data Engineer to join our team. The ideal candidate will be responsible for maintaining our data processing infrastructure and optimizing our data architecture, as well as contributing to the development and implementation of new data-driven solutions. At Docyt, we are passionate about empowering businesses to take control of their financial data using an AI-driven super app, and we're looking for a skilled engineer to help us continue to innovate in this exciting space.\\nResponsibilities\\n\\nDevelop and manage data pipelines, ensuring the smooth flow of data from various sources to our data warehouse\\nMonitor and optimize data processing infrastructure, ensuring fast and reliable ETL pipelines\\nContribute to the design and implementation of new data-driven solutions, using cutting-edge machine learning and artificial intelligence techniques\\nCollaborate with other members of the engineering team, sharing knowledge and best practices to continuously improve our data processing capabilities\\nBuild and maintain data models and ensure data accuracy and consistency\\nImplement and manage data security measures, including backups and access controls\\nParticipate in code reviews, providing constructive feedback to ensure code quality\"}, {'job_title': 'Data Engineer h/f', 'job_url': 'https://search.linkup.com/details/5b8578a2679225298b96f7a61599b29d', 'location': 'Paris, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 7, 351960), 'description': 'Contexte\\nRejoignez le département dédié à la data \" stratégie et données \" de Valtech, qui aide les plus grandes marques et entreprises mondiales à atteindre une croissance ambitieuse dans différents secteurs (luxe, retail, médias, etc.).\\nNos clients nous choisissent en raison de la qualité de nos livrables et de notre engagement à produire des résultats commerciaux clairs et mesurables.\\nNotre expertise s\\'exprime dans les domaines de l\\'ingénierie et de la science des données, de l\\'analyse de celles-ci, de l\\'optimisation continue, de la technologie MarTech.\\nNotre passion est de relever les défis où nous réinventons le parcours client et construisons de nouvelles expériences connectées et où nous orchestrons les données afin d\\'aider nos clients à transformer leur mode de fonctionnement et optimiser les plateformes numériques pour le commerce et le marketing omnicanal.\\nRôle / Mission Consultant Data Engineer\\nEn association avec des contributeurs et des gestionnaires individuels de haut niveau, vos principales fonctions et responsabilités seront les suivantes :\\n\\nAméliorer la conception, mettre à jour et modifier la programmation pour des parties et des sous-systèmes de pipelines de données, de référentiels et de modèles pour les données structurées/non structurées ;\\nTravailler en tant qu\\'ingénieur Big Data, contributeur individuel et joueur d\\'équipe ;\\nExploiter les données à l\\'aide d\\'outils et de langages de programmation modernes ;\\nAnalyser, concevoir et déterminer les activités de codage, de programmation et d\\'intégration requises en fonction des objectifs spécifiques et des lignes directrices établies du projet ;\\nExécuter et écrire des parties de plans de test, de protocoles et de documentation pour la partie affectée de l\\'application ;\\nIdentifier et débogguer les problèmes liés au code et suggérer des modifications et/ou des améliorations ;\\nParticiper avec d\\'autres professionnels de la science des données pour développer des solutions fiables, rentables et de haute qualité pour les systèmes, modèles ou composants de données ;\\nCollaborer et communiquer avec l\\'équipe de projet concernant l\\'avancement du projet et la résolution des problèmes.\\n\\nProfil\\nVous justifiez de 6 ans d\\'expérience dans un rôle d\\'ingénierie de données, d\\'analyse commerciale, d\\'intelligence d\\'affaires ou d\\'ingénierie de données comparable, y compris les outils d\\'entreposage de données et d\\'intelligence d\\'affaires. \\nHardskills\\n\\nREQUIS : Snowflake, Snowpipe, devOps (Jenkins, Git), DBT and SQL, Fivetran (ou équivalent), Python, Data Platforms (design et implementation), Apache Kafka (ou platforme de streaming équivalente).\\nPLUS : Tableau, Qlik, Power BI, Data Studio, Tables delta, SGBDR traditionnel (SQL), NoSQL (MongoDB, DynamoDB, Cassandra, Neo4J, Titan), Docker, Kubernetes, Apache Airflow, API Rest, BigQuery, AWS Redshift, Azure Synapse Analytics, Databricks, Azure, AWS ou GCP.\\n\\nSoftskills\\n\\nDirection de projets et d\\'équipes d\\'ingénierie de data dans un cadre agile ;\\nÊtre capable de transformer des données structurées, semi-structurées et non structurées, selon les meilleurs modèles de conception ETL / ELT ;\\nSolide compréhension des principes de sécurité de l\\'information pour assurer un traitement et une gestion conformes des données ; \\nUne expérience dans le secteur du luxe est un must ;\\nAnglais ET Français impératifs.\\n\\nNos valeurs : Share - Dare - Care\\n\\nShare : Nous partageons les uns et les autres nos idées pour aller toujours plus loin - nous investissons dans la constitution d\\'équipes diversifiées et inclusives et dans une culture du travail et de l\\'excellence.\\nDare : Nous osons aller dans les territoires inconnus. Échouer, recommencer, fait partie de notre métier. Ce n\\'est ni un secret, ni un tabou, c\\'est une façon de penser, indissociable de l\\'exploration et de l\\'innovation.\\nCare : Nous nous soucions de la qualité de ce que nous produisons. Nous souhaitons contribuer à faire du monde un endroit meilleur grâce à ce que nous créons.\\n\\nDiversité & Inclusion\\nÀ Valtech, nous concevons des expériences fortes qui touchent chaque personne. Nous sommes donc proactifs en créant des lieux de travail qui conviennent à chaque personne. Notre objectif est de créer un lieu de travail équitable qui offre aux personnes de tous horizons le soutien dont elles ont besoin pour s\\'épanouir, grandir et atteindre leurs objectifs (quels qu\\'ils soient).\\nSi vous ne répondez pas à tous les critères ou si vous avez des lacunes dans votre CV, nous serons heureux d\\'en savoir plus sur vous et qui sait ? Vous serez peut-être le prochain Valtech !\\nL\\'agence\\nValtech est une agence digitale axée sur la transformation des entreprises et nourrie par l\\'innovation. \\nAvec +5500 experts en technologies, design, développement, création, marketing et data, dans 62 bureaux répartis dans 22 pays, nous sommes parfaitement positionnés pour soutenir la transformation globale de nos clients et leur permettre d\\'anticiper les défis de demain, de stimuler leur croissance et d\\'obtenir un retour sur investissement rapide. \\nLes clients font confiance à Valtech pour éliminer la complexité et fournir des solutions innovantes et sans friction comblant ainsi l\\'écart entre les attentes des clients et l\\'expérience réelle.\\nwww.valtech.com Transform by Doing'}, {'job_title': 'Principal-Big Data Engineer', 'job_url': 'https://search.linkup.com/details/226279dd270a59d9fec3928b6cf0379b', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 12, 332690), 'description': \"Job Overview \\nJOB LOCATION:208 S. Akard Street, Dallas, TX 75202 [and various unanticipated locations throughout the U.S.; may work from home]\\nDUTIES: Interpret the requirements of various big data analytic use cases and scenarios, and drive the design and implementation of specific data models to ultimately help drive better business decisions through insights from a combination of external and AT&T's data assets. Develop necessary enablers and data platform in the big data lake environment and has the responsibility of maintaining its integrity during the life cycle phases. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in the big data environment. Support the standardization, customization and ad-hoc data analysis, and develop the mechanisms in ingest, analyze, validate, normalize and clean data. Implement statistical data quality procedures on new data sources, and apply rigorous iterative data analytics. Support data scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with big data policy and security teams and legal to create data policy and develop interfaces and retention models which requires synthesizing or anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods and techniques. Technical design to ingest data into Palantir Foundry platform on Azure. Participate in creating ingestion strategy and technology patterns. Provide technical direction (architecture and design) for projects ingesting data into Palantir Foundry. Conduct design, architecture and code reviews. Engage with the vendor to meet AT&T requirements and deliverables. Create tasks for Data Replication and Data Synchronization. Utilize Oracle, Teradata, Vertica, Azure DataLake, Databricks and Snowflake. Utilize Hbase and Hbase Shell. Develop UNIX shell scripts. Develop database load scripts: VSQL for Vertica. Utilize BTEQ, Mload, Fastload and fast export scripts for Teradata. Utilize SnowSQL for Snowflake and PySpark for Databricks. Develop schedules using workload scheduling tools: TWS.\\nREQUIREMENTS: Requires a Master's Degree, or foreign equivalent degree, in Electrical and Electronic Engineering, Computer Science, or Computer Engineering and three (3) years of experience in the job offered or three (3) years of experience in a related occupation creating tasks for Data Replication and Data Synchronization; utilizing Oracle, Teradata, Vertica, Azure DataLake, Databricks, Snowflake and Palantir Foundry; utilizing Hbase and Hbase Shell; developing UNIX shell scripts; developing database load scripts: VSQL for Vertica; utilizing BTEQ, Mload, Fastload and fast export scripts for Teradata; utilizing SnowSQL for Snowflake and PySpark for Databricks; and developing schedules using workload scheduling tools: TWS.\\nOur Principal-Big Data Engineers earn between $158,200 - $254,300 yearly. Not to mention all the other amazing rewards that working at AT&T offers.\\nJoining our team comes with amazing perks and benefits:\\n\\nMedical/Dental/Vision coverage\\n401(k) plan\\nTuition reimbursement program\\nPaid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)\\nPaid Parental Leave\\nPaid Caregiver Leave\\nAdditional sick leave beyond what state and local law require may be available but is unprotected\\nAdoption Reimbursement\\nDisability Benefits (short term and long term)\\nLife and Accidental Death Insurance\\nSupplemental benefit programs: critical illness/accident hospital indemnity/group legal\\nEmployee Assistance Programs (EAP)\\nExtensive employee wellness programs\\nEmployee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone\\n\\nAT&T is an Affirmative Action/Equal Opportunity Employer, and we are committed to hiring a diverse and talented workforce. EOE/AA/M/F/D/V\\n\\nnp*\\n\\nJob ID 2323357 Date posted 07/20/2023 Apply Now\"}, {'job_title': 'Data Engineer II', 'job_url': 'https://search.linkup.com/details/6cc8acb14cfa933e6ddb1a55ce78ff1a', 'location': 'Arlington, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 17, 75797), 'description': \"Overview\\nWe are expanding our efforts into complementary data technologies for decision support in areas of ingesting and processing large data sets including data commonly referred to as semi-structured or unstructured data. Our interests are in enabling data science and search based applications on large and low latent data sets in both a batch and streaming context for processing. To that end, this role will engage with team counterparts in exploring and deploying technologies for creating data sets using a combination of batch and streaming transformation processes. These data sets support both off-line and in-line machine learning training and model execution. Other data sets support search engine based analytics. Exploration and deployment of technologies activities include identifying opportunities that impact business strategy, collaborating on the selection of data solutions software, and contributing to the identification of hardware requirements based on business requirements. Responsibility also includes coding, testing, and documentation of new or modified scalable analytic data systems including automation for deployment and monitoring. This role participates along with team counterparts to develop solutions in an end-to-end framework on a group of core data technologies.\\nResponsibilities\\nJOB DUTIES\\n\\nContribute to the evaluation, research, experimentation efforts with batch and streaming data engineering technologies in a lab to keep pace with industry innovation\\nWork with data engineering related groups to inform on and showcase capabilities of emerging technologies and to enable the adoption of these new technologies and associated techniques\\nContribute to the definition and refinement of processes and procedures for the data engineering practice\\nWork closely with data scientists, data architects, ETL developers, other IT counterparts, and business partners to identify, capture, collect and format data from the external sources, internal systems, and the data warehouse to extract features of interest\\nCode, test, deploy, monitor, document and troubleshoot data engineering processing and associated automation\\nPerform other duties as assigned\\nConform with all company policies and procedures\\n\\nREPORTING RELATIONSHIPData Integration Manager US\\nQualifications\\nKnowledge\\n\\nExcellent knowledge of Linux, AIX, or other Unix flavors\\nWorking knowledge of populating indexes for search engines such as Solr and Elastic Search\\nWorking knowledge of enterprise service bus technologies such as Tibco or Mule\\nWorking knowledge of Docker Datacenter, Mesos, Kubernetes, OpenShift and/or Deis or other such container/platform-as-a-service orchestrator\\nWorking knowledge of data science and building high performance algorithms\\n\\nSkills\\n\\nAbility to quickly prototype and perform critical analysis and use creative approaches for solving complex problems\\nExcellent written and verbal communication skills\\n\\nEducation\\n\\nBachelor's Degree in related field or equivalent work experience required\\nMaster's Degree in related field or equivalent work experience preferred\\n\\nExperience\\n\\n5-7 years of overall IT experience required\\n2-4 years of hands-on experience with software engineering to include Java, Scala, and Python required\\n2-4 years of hands-on experience with processing large data sets with Spark, Kafka, RabbitMQ, Flume, Hadoop, HBase, Cassandra or similar distributed system required\\n2-4 years of hands-on experience with NoSQL data stores such as HBase, MongoDB, Cassandra, Redis, Riak or other technologies that embed NoSQL with search such as MarkLogic or Lily Enterprise required\\n\\nWorking Conditions\\n\\nNormal office environment subject to stressful situations\\nFlexible schedule with possibility of working long hours including weekends/holidays, occasional overtime or split shifts may be required\\nLimited travel may be required to support business needs\"}, {'job_title': 'Lead Data Engineer', 'job_url': 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'location': 'Addison, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 21, 269117), 'description': \"Wells Fargo is seeking a Lead Data Engineer... \\nAbout this role: \\nWells Fargo is seeking a Lead Data Engineer with strong technical expertise to build a Data Pipeline using Big Data and Cloud technologies. This position will be required to have deep knowledge in Data, Steaming, self-service BI tools and Micro Services. This position will need to understand the current challenges and opportunities with existing technology implementation and drive formulate the target state aligned to our strategies. This supports our business partners in adapting new workflows, processes, and mindsets to meet their goals. Work with business stakeholders to support strategic business initiative by bringing value based and practical technology innovations and solutions. Collaborate with internal business and technical partner teams to improve effectiveness of delivery and reduce/eliminate wasteful activities (maintain service and operating level agreements) \\nIn this role, you will: \\n\\nReview and analyze complex, large-scale technology solutions for tactical and strategic business objectives, enterprise technological environment, and technical challenges that require in-depth evaluation of multiple factors, including intangibles or unprecedented technical factors \\nMake decisions in developing standard and companywide best practices for engineering and technology solutions requiring understanding of industry best practices and new technologies, influencing and leading technology team to meet deliverables and drive new initiatives \\nLead complex technology initiatives including those that are companywide with broad impact \\nAct as a key participant in developing standards and companywide best practices for engineering complex and large scale technology solutions for technology engineering disciplines \\nDesign, code, test, debug, and document for projects and programs \\nLead projects, teams, or serve as a peer mentor. \\n\\nRequired Qualifications: \\n\\n5+ years of Data Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education \\n3+ years of Data management, Data Integration, Data Warehouse and BI experience \\n3+ years of experience with Dev-Ops, CICD Pipeline \\nStrong hands-on experience in SQL, Python/Spark \\nExperience Hadoop ecosystem tools relevant for real-time and batch data ingestion, processing and provisioning using tools such as Apache Flume, Apache Kafka, Apache Sqoop, Apache Flink, Apache Hive or Apache Storm \\nStrong experience in relational databases, Database design, Data Model development, querying, data warehousing, ETL process, requirements gathering and/or decision support tools. \\nHands-on experience in SQL especially in SQL Server & Teradata environment \\nHands on experience in ETL development \\n\\nDesired Qualifications: \\n\\nExperience designing and optimizing complex SQL and/or SAS queries \\nExperience working in operational reporting \\nExperience with Agile Scrum (Daily Standup, Sprint Planning and Sprint Retrospective meetings) and Kanban \\n2+ years of experience with modern software engineering technologies and tool sets \\n2+ years of experience with systems architecture and design \\n3+ years of information technology systems design and planning experience; in data, systems, applications, or architecture \\n3+ years of experience in building Data APIs/Services \\nKnowledge and understanding of Home Lending \\n\\nWe Value Diversity \\nAt Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law. \\nEmployees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements. \\nCandidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \\nCandidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process. \\nDrug and Alcohol Policy \\nWells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.\"}, {'job_title': 'Experienced Data Engineer', 'job_url': 'https://search.linkup.com/details/97c6da0f6fa1eff39d20351f74498d8c', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 26, 113647), 'description': \"What You'll Do\\nWe're looking for a Data Engineer to join our Information Security Risk space, supporting and maintaining data and analytics for our Governance, Risk, and Compliance (GRC) area. In this role, you'll apply your data engineering and analysis expertise to meet business requirements and improve effectiveness! Demonstrate independence working in more than one software development layer of the solution.\\n\\nCoordinate technical aspects of data management functions including creating, loading, transforming, cleansing, processing, analyzing, and visualizing data. \\nWork directly or in support of data science/analytics to design, develop, test and integrate data from various sources into large-scale processing systems and databases to use in providing insights that address business needs.\\nResponsible for creating data management process designs, models, and architectures by understanding architectural patterns and principles, researching new technologies and approaches, understanding requirements, testing, debugging, documentation, quality assurance review, implementation, securing and maintenance. Be persistent in the face of roadblocks, dispatch them efficiently, collaborating with others as needed.\\nDemonstrate knowledge of industry trends, creates optimized data components and systems that use appropriate development environment. Employ a variety of languages and tools (e.g. scripting languages, data movement tools) to marry systems together. Recommend ways to improve data reliability, efficiency and quality.\\nAssist in developing strategies for data acquisition and influence others within the business area through explanation of policies, patterns and practices.\\nProvide technical guidance to team members on integration and functionality of infrastructure components.\\nDemonstrate influence at the department level. Provide mentoring to team. Communicate effectively across business unit and IT.\\nIndependently conduct analysis and development, requirements, coding, automated testing, debugging, designing, documentation, quality assurance review, implementation and maintenance.\\nPerform other job-related duties or special projects as required.\\n\\nOperating at the intersection of financial services and technology, Principal builds financial tools that help our customers live better lives. We take pride in being a purpose-led firm, motivated by our mission to make financial security accessible to all. Our mission, integrity, and customer focus have made us a trusted leader for more than 140 years. \\nAs Principal continues to modernize its systems, this role will offer you an exciting opportunity to build solutions that will directly impact our long-term strategy and tech stack, all while ensuring that our products are robust, scalable, and secure!\\nWho You Are\\n\\nBachelor's degree plus 4+ years related work experience or a Master's in related field.\\nAbility to work directly with data and datastores through programming language such as SQL, Python, etc.\\nExperience with a variety of data modeling techniques and data structures.\\nAbility to optimize data for analytics and data science.\\nExperience building/operating systems for data extraction, ingestion and processing of large data sets.\\nKnowledge and direct experience using business intelligence reporting tools.\\nExperience building data products incrementally and integrating and running datasets from multiple sources.\\nExcellent planning, organizational, problem-solving, analytical, decision-making and communication skills required.\\nExcellent time management skills preferred.\\nAbility to collaborate and communicate with various levels required. Eg; effectively communicate strategies and designs to all levels of company.\\n\\nSkills That Will Help You Stand Out \\n\\nPower BI with Dax functions\\nPython scripting\\nSQL\\nCloud Technologies (i.e. AWS, Snowflake)\\n\\nSalary Range Information\\nSalary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer.\\nSalary Range\\n$77400 - $182400 / year\\nAdditional Information\\nOur Engineering Culture\\nThrough our product-driven Agile/Lean DevOps environment, we've fostered a culture of innovation and experimentation across our development teams. As a customer-focused organization, we work closely with our end users and product owners to understand and rapidly respond to emerging business needs.\\nCollaboration is embedded into everything we do – from the products we develop to the quality service we provide. We're driven by the belief that diversity of thought, background, and perspective is critical to creating the best products and experiences for our customers. \\nHours: \\nMay require some after normal business hour support.\\nWork Environment:\\nThis role offers the ability for in-office, hybrid (blending both office and remote work in a typical workweek), and remote work arrangements. You'll work with your leader to figure out which option may align best based on several factors.\\nJob Level\\nWe'll consider talent at the next level with the right experience, background and skill level.\\nWork Authorization/Sponsorship \\nAt this time, we're not considering applicants that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links.\\nNonimmigrant Workers and Green Card for Employment-Based Immigrants\\nInvestment Code of Ethics \\nFor Principal Asset Management positions, you'll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization.\\nExperience Principal \\nAt Principal, we value connecting on both a personal and professional level. Together, we're imagining a more purpose-led future for financial services – and that starts with you. Our success depends on the unique experiences, backgrounds, and talents of our employees. And we support our employees the same way we support our customers: with comprehensive, competitive benefit offerings crafted to protect their physical, financial, and social well-being. Check out our careers site to learn more about our purpose, values and benefits.\\nPrincipal is an Equal Opportunity Employer \\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.\\nLinkedIn Remote Hashtag\\nLI-Remote\"}, {'job_title': 'Horticulture Data Engineer', 'job_url': 'https://search.linkup.com/details/154024681efab3b43b738f9b2d34458d', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 30, 279432), 'description': \"Job Title:\\nHorticulture Data Engineer\\nReports to:\\nSenior Director of Data Science\\nDepartment:\\nTechnology\\nCorporate:\\nYes\\nLocation:\\nAustin, TX\\nTravel Required:\\nYes, 15%\\nFLSA:\\nExempt\\nPosition Type:\\nFulltime\\nSegmentation:\\nBlended\\nSupervisory:\\nNo\\nRevol Greens: Revolutionizing Fresh Since 2017\\nFounded in 2017, Revol Greens has quickly grown to the largest greenhouse lettuce producer in the US. With locations in Minnesota, California, Georgia, and Texas, Revol Greens harvests and delivers local lettuce and greens within 24 hours of harvest, resulting in the freshest taste and peak nutrition value. With an experienced growing team and state-of the-art greenhouses, Revol Greens is paving the way to a more sustainable future.\\nJob Description\\nSummary of Position:\\nThis Horticulture Data Engineer role will be assisting with analyzing our growing operations data, as well as assisting with visualizations throughout several different projects. This position will possess a strong understanding of business intelligence development, with verified certification in Power BI and Power Query. This role will work cross-functionally to support project life cycles, ad-hoc analysis, creation of thorough documentation, and future proofing the reporting experience.\\nOverall, this be a technical role with the expectation of acquiring, cleaning, analyzing, and then modelling crop yield, greenhouse climate, and plant nutrient data. In the beginning it will focus almost exclusively on working closely with our hydroponic experts (Growers) to obtain the data and domain knowledge necessary to build effective data analysis and models. This role will intersect data science, data engineering and our growing operations.\\nEssential Functions & Responsibilities:\\n\\nWork Closely with horticultural specialists, project managers, to understand, document, and maintain focus on their analytics needs, including critical metrics and KPIs, and deliver actionable insights. \\nProactively analyze data to answer key questions for stakeholders or yourself, with an eye on what drives business performance, and be able to present your finding to a medium sized group. \\nCreate and maintain rich interactive visualizations through data interpretation and analysis, with reporting components from multiple data sources.\\nDefine and implement data acquisition and integration logic, selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution.\\nDevelop and maintain databases by acquiring data from primary and secondary sources and build scripts that will make our data evaluation process more flexible or scalable across datasets.\\nBe open to occasional travel to our greenhouse sites.\\nBe open to learning new cutting-edge technologies in the cloud and AI space. \\nWearing multiple IT hats in the data science space to fit start needs (should not exceed 10-20% of regular time)\\n\\nKnowledge, Skills, & Abilities:\\n\\nIntermediate cloud architecture knowledge. \\nWorking knowledge and have implemented multiple modelling methods.\\n\\nClassical supervised machine learning required, any unsupervised and deep learning would a great addition.\\n\\nBeginner Linux knowledge; Able to write a Bash script, SSH into machine to get files / run python scripts, etc.\\nBasic working knowledge of software design principles: Version control, project planning software, AGILE\\n\\nEducation and Experience:\\n\\nBachelor's degree in engineering\\nIntermediate experience working with Python, SQL, & Power BI\\n5-7 years of experience as a Data Analyst \\n\\nSupervisory:\\n\\nThis position does not have any supervisory responsibilities. \\n\\nWork Environment:\\nOffice \\n\\nSitting at a desk and/or staring at a computer screen for extended periods of time\\n\\nPhysical Requirements:\\n\\nOccasionally remaining in a stationary position, often standing or sitting for prolonged periods.\\nOccasionally moving about to accomplish tasks or moving from one worksite to another.\\nConstantly communicating with others to exchange information.\\nOccasionally repeating motions that may include the wrists, hands and/or fingers.\\n\\nBenefits:\\n\\nPTO & Holiday Pay\\nHealth, Dental, and Vision Insurance \\n$10,000 company paid Life Insurance Policy\\nSTD & LTD\\nEmployee Assistance Program\\n401k plan with 4% company-match after 6 months of employment\"}, {'job_title': 'Senior Data Engineer', 'job_url': 'https://search.linkup.com/details/746e85b6d08e79bf573b254f799cb362', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 34, 994176), 'description': \"Job Description\\nSenior Data Engineers \\nProcore is looking for a Senior Data Platform Engineer to join our data engineering team. Data platform engineers are responsible for designing and implementing Procore's overarching data strategy. Critical projects include the design and operation of Procore's streaming and batching data processing infrastructure, architecture of Procore's datalake and the selection of new infrastructure technologies.\\nWe're looking for a motivated engineer with at least 5 years of experience. You must be comfortable operating in a high autonomy environment, architecting systems from the ground up and deploying technologies that are new to our organization. drive solutions to wide-ranging data engineering and infrastructure challenges for product and internal operations.\\nYou will partner with world-class developers, engineers, architects, and data scientists to drive thinking, provide technical leadership, and collaborate in defining best practices around data engineering. You will also work alongside local product management, engineering, and research teams to develop innovative solutions that will influence our product line.\\nExamples of our projects:\\n\\n\\nAn ETL pipeline for our data lake consisting of batch processing, orchestration with Airflow, monitoring with Datadog and alerting with Slack\\n\\n\\nA Maven package used by all of Product Dev teams for building Kafka consumers with built in support for configuration, error reporting, monitoring, deserialization, gRPC, Spark, Flink, and Kubernetes\\n\\nA multi-stage data lake including landing, process and serving zone\\n\\nSome of your responsibilities include:\\n\\n\\nProvide technical leadership to efforts around tooling and infrastructure that enable teams to efficiently complete and maintain data science projects\\n\\n\\nPartner with teams on modeling and analysis problems – from transforming problem statements into analysis problems, to working through data modeling and engineering, to analysis and communication of results\\n\\n\\nLead code reviews, design, and best practices\\n\\n\\nCoach and mentor senior engineers\\n\\nUse experience gained in the above and expertise in this space to influence our product roadmap, potentially working with prototype engineering team to add additional capabilities to our products to solve more of these problems\\n\\nWho You Are...\\n\\n\\n5+ years of experience in a Data Engineer role with a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.\\n\\n\\nExpertise building data pipelines (in either Real-time or batch) on large complex datasets using Spark or Flink frameworks\\n\\n\\nExperience with AWS services including EC2, S3, Glue, EMR, RDS, Snowflake, Elastic Search, Cassandra and Data pipeline/streaming tools (Airflow, NiFi, Kafka)\\n\\n\\nExperience building and optimizing data pipelines, architectures and data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets. \\n\\n\\nDeep knowledge of stream processing using Kafka and highly scalable 'big data' data stores. \\n\\n\\nExpertise in Java or Python\\n\\n\\nTeam Player. Experience supporting and working with cross-functional teams in a dynamic environment. \\n\\n\\nStrong oral and written communication skills.\\n\\nExperience of End-to-end data quality control and automated testing experience\\n\\nBonus Points: \\n\\n\\nExperience with unstructured data (PDF, contract, plan, image)\\n\\n\\nData transformation (quality, extraction)\\n\\nExperience in working within team handling all the data pipeline from extraction to Data warehouse\\n\\nAbout Us\\nProcore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, retail centers, airports, housing complexes and more. At Procore, we have worked hard to create and maintain a culture where you can own your work and are encouraged and given resources to try new ideas. Check us out on Glassdoor to see what others are saying about working at Procore. Our headquarters is located on the bluffs above the Pacific Ocean in Carpinteria, CA, with growing offices worldwide. To learn more about our team, click here.\\nWe are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\\nPerks & Benefits\\nYou are a person with dreams, goals, and ambitions—both personally and professionally. That's why we believe in providing benefits that not only match our Procore values (Openness, Optimism, and Ownership) but enhance the lives of our team members. Here are just a few of our benefit offerings: competitive health care plans, unlimited paid vacation, stock options, employee enrichment and development programs, and friends & family events.\\nAdditional Information\\nBase Pay Range $126,800-$174,350. Eligible for Equity Compensation. Procore is committed to offering competitive, fair, and commensurate compensation, and has provided an estimated pay range for this role. Actual compensation will be based on a candidate's job-related skills, experience, education or training, and location.\\nPerks & Benefits\\nAt Procore, we invest in our employees and provide a full range of benefits and perks to help you grow and thrive. From generous paid time off and healthcare coverage to career enrichment and development programs, learn more details about what we offer and how we empower you to be your best.\\nAbout Us\\nProcore Technologies is building the software that builds the world. We provide cloud-based construction management software that helps clients more efficiently build skyscrapers, hospitals, retail centers, airports, housing complexes, and more. At Procore, we have worked hard to create and maintain a culture where you can own your work and are encouraged and given resources to try new ideas. Check us out on Glassdoor to see what others are saying about working at Procore.\\nWe are an equal-opportunity employer and welcome builders of all backgrounds. We thrive in a diverse, dynamic, and inclusive environment. We do not tolerate discrimination against employees on the basis of age, color, disability, gender, gender identity or expression, marital status, national origin, political affiliation, race, religion, sexual orientation, veteran status, or any other classification protected by law.\\nIf you'd like to stay in touch and be the first to hear about new roles at Procore, join our Talent Community.\"}, {'job_title': 'Senior Data Engineer', 'job_url': 'https://search.linkup.com/details/ebb3418fbf0feb9c546457a04759025f', 'location': 'Paris, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 40, 415299), 'description': \"Voodoo is a tech company that creates mobile games and apps. With 6 billion downloads and over 150 million monthly active users, Voodoo is the #3 mobile publisher worldwide in terms of downloads after Google and Meta.\\nThe company is one of the most impressive examples of hypergrowth in the ecosystem, having raised over $1B and backed by Goldman Sachs, Tencent, and GBL.\\nVoodoo is now a team of over 750 employees worldwide, we're looking for talented individuals from across the globe to come and entertain the world with us.\\nTeam\\nThe Engineering & Data team builds innovative tech products and platforms to support the impressive growth of their gaming and consumer apps which allow Voodoo to stay at the forefront of the mobile industry. The Engineering & Data team plays a key role in Voodoo's long-term strategy. It enables Voodoo to both accelerate product diversification and provide a state of the art growth-engine to distribute and scale our games. They create innovative solutions that drive growth with a pragmatic approach, ranging from simple searching to complex machine learning systems.\\nWe are looking for a talented senior data engineer eager to deal with great volumes of data and/or willing to build the data infrastructure and pipelines of Autobid, a product that leverages Data Engineering and Machine Learning to drive Voodoo's User Acquisition. User Acquisition is at the heart of our success playing a crucial role in the growth and vitality of our mobile games. You will be part of a small and high-performing team working to solve complex problems using best-in-class technology (Spark, Python, Scala, Airflow), and have the opportunity to shape the strategies and technical solutions that drive our user acquisition efforts.\\nRole\\n\\nConstruct and manage robust data pipelines to align with ever-evolving business needs, ensuring optimal architecture support.\\nContribute to the codebase, push and maintain your changes in production, and be the evangelist of good coding and data engineering practices\\nCollaborate closely with Data Scientists to develop new ways to acquire data, build processes to create data set, set up machine learning infrastructure, etc\\nTake ownership of projects from initial discussions to release, including feature estimation & scoping, architecture design, a benchmark of new technologies, product feedback...\\nWork in a very agile environment with a fast decision process, having the opportunity to collaborate directly with people working on back-end development, data science, mobile games, broad audience mobile apps, product & marketing\\n\\nOur Stack\\n\\nSpark ⧫ Python ⧫ Scala ⧫ Airflow ⧫ Amazon Web Services ⧫ Kafka ⧫ Kubernetes ⧫ DBT ⧫ SQL\\n\\nProfile\\n\\n4 years+ of experience as a Data Engineer or another similar role\\nA proven track record of building and optimizing data pipelines for massive amounts of data\\nStrong experience in scalability, reliability, and security topics\\nStrong analytical skills and ability to work with unstructured datasets\\nExperience with Amazon Web Services\\nResult-oriented and focused on the value created by your developments\\nCurious about business needs and keen to create innovative, agile solutions to help grow the business through data\\nExcellent communication skills (you can speak & write English)\\nWorking experience in a Gaming, Advertising, or successful company\\nFamiliarity with Voodoo's ecosystem: gaming, apps, advertising, analytics, etc, at all scales\\n\\nBenefits:\\nCompetitive salary upon experience\\nComprehensive relocation package (including visa support)\\nSwile Lunch voucher\\nGymlib (100% borne by Voodoo)\\nPremium healthcare coverage SideCare, for your family is 100% borne by Voodoo\\nChild day care facilities (Les Petits Chaperons rouges)\\nWellness activities in our Paris office\\nUnlimited vacation policy\\nRemote days\\nVoodoo just won the award for Best Office Space in France\"}, {'job_title': 'Subsurface Data Engineer', 'job_url': 'https://search.linkup.com/details/4047f32514bccd3d78c0b1a34a92b771', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 44, 621391), 'description': 'Subsurface Data Management is helping Shell execute a strategy of moving from Epicure to OSDU. At the same time Shell has unleashed multiple digitalization efforts that require large volumes of SSW data.\\nYou\\'ll will be responsible for finding new ways to help Subsurface Data Management execute upon the strategic movement of SSW data to a new platform (Point C), providing opportunities to unlock value from data now (Point B), and post Point C (once OSDU is deployed).\\nYour success in this role will flow not only from your technical abilities, but your capacity to manage leaders across natural teams and convince them of the business value to your approaches.\\nWhere you fit in\\n\\nThe Integration team is part of the Integration and Seismic Data management team under the GM Subsurface Data Management & WF in the Upstream Subsurface Digital and Data VP-ship.\\nThe Integration Team works with the business and IT to improve the data landscape with ambitious and realistic plans and have a track record integrating on-premise and cloud systems in a way that delivers business value in the Point B and C timelines.\\nYou will help the business find fast and lower-cost ways to deliver the data required to optimize digital solutions, accelerate global scaling and value replication, and enable innovative ways of working.\\n\\nWhat is the role\\nAs a member of this team, you will have the following key responsibilities:\\nAssist program and project teams (e.g. X-Digi/Data, (O)SDU and Subsurface Data Management) virtualize and integrate their data in order to deliver upon the tactical and strategic goals from those programs and projects.\\nUtilize your knowledge of source systems and project needs to become a liaison between the business and Shell IT.\\nUtilize your knowledge of cloud tooling to negotiate with Shell Architects on the positioning of new technology in SSW data flows. This is convincing IT Stakeholders of the validity of our technical solutions.\\nConvey to management, programs and projects the business value of our approach to integration. This is convincing the business of the value of our solutions.\\nWork scope requires business domain knowledge and technical TIDM knowledge with demonstrable passion for identifying, developing, and deploying new ideas and ways of working. Within this role there will be significant interaction with leaders of programs, projects, IT and Subsurface Data Management, your ability to convey your technical knowledge and how it enables business value will be key to your success.\\nWhat we need from you\\nYou will bring an open and external mindset with a sense of urgency to drive strategic SSW data integration improvements. You will collaborate and work across organizational boundaries and help develop a collaborative natural team with the business stakeholders.\\nRequirements: \\n\\nMust have legal authorization to work in the US on a full-time basis\\n\\nYou have:\\n\\n6+ years in a Technical Data Management Role Or proven experience leading projects within Technical Data Management programs. Or proven experience in a relevant data engineering or data science program of project.\\nAn appetite to discover new technology solutions to improve our technical data workflows that transform our ways of working.\\nExperience with AWS services, or Azure equivalents.\\nProgramming skills utilized in the data science domain (e.g. Python).\\nSelf-starting and self-managed. You will need to move from requirements to a decomposed set of work (user stories) and deliver that work in 2-week increments (sprints).\\nBe able to convey to Product Owners, Program Managers, Chief Data Officers, and Architects the \"why\" and \"how\" of your approach to delivering work.\\nBe able to convey the business value of proposed solutions to Product Owners, Program Managers, CDOs and Architects when proposing solutions to work, or responding to challenges.\\nKnowledge, or experience with, data virtualization tools, especially Denodo would be beneficial.\\n\\nCompany description \\nShell is a global group of energy and petrochemical companies with about 84,000 employees across more than 70 countries. We aim to meet the world\\'s growing need for more and cleaner energy solutions in ways that are economically, environmentally, and socially responsible. We have expertise in exploration, production, refining and marketing of oil and natural gas, and the manufacturing and marketing of chemicals.\\nAs a global energy company operating in a challenging world, we set high standards of performance and ethical behaviors. We are judged by how we act and how we live up to our core values of honesty, integrity, and respect for people. Our Business Principles are based on these. They promote trust, openness, teamwork, and professionalism, as well as pride in what we do and how we conduct business.\\nBuilding on our core values, we aspire to sustain a diverse and inclusive culture where everyone feels respected and valued, from our employees to our customers and partners. A diverse workforce and an inclusive work environment are vital to our success, leading to greater innovation and better energy solutions.\\nAn innovative place to work\\nThere\\'s never been a more exciting time to work at Shell. Everyone here is helping solve one of the biggest challenges facing the world today: bringing the benefits of energy to everyone on the planet, whilst managing the risks of climate change.\\nJoin us and you\\'ll add your talent and imagination to a business with the power to shape the future – whether by investing in renewables, exploring new ways to store energy, or developing technology that helps the world to use energy more efficiently.\\nAn inclusive place to work\\nTo power progress together, we need to attract and develop the brightest minds and make sure every voice is heard. Here are just some of the ways we\\'re nurturing an inclusive environment – one where you can express your ideas, extend your skills, and reach your potential.\\n\\nWe\\'re creating a space where people with disabilities can excel through transparent recruitment process, workplace adjustments and ongoing support in their roles. Feel free to let us know about your circumstances when you apply, and we\\'ll take it from there.\\nWe\\'re closing the gender gap – whether that\\'s through action on equal pay or by enabling more women to reach senior roles in engineering and technology.\\nWe\\'re striving to be a pioneer of an inclusive and diverse workplace, promoting equality for employees regardless of sexual orientation or gender identity.\\nWe consider ourselves a flexible employer and want to support you finding the right balance. We encourage you to discuss this with us in your application.\\n\\nA rewarding place to work\\nCombine our creative, collaborative environment and global operations with an impressive range of benefits and joining Shell becomes an inspired career choice.\\nWe\\'re huge advocates for career development. We\\'ll encourage you to try new roles and experience new settings. By pushing people to reach their potential, we frequently help them find skills they never knew they had, or make career moves they never thought possible.'}, {'job_title': 'Data Engineer III', 'job_url': 'https://search.linkup.com/details/b498fa46bcd32fa2c5110874e25a20de', 'location': 'San Antonio, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 49, 254565), 'description': \"Job Description\\nIt's about putting our best to the test. \\nAre you described as someone with an inquisitive mind and an innovative personality? Are you never satisfied with good enough? Does solving complex problems and ensuring top-quality systems excite you? If so, being a Data Engineer III with Frost could be for you.\\nAt Frost, it's about more than a job. It's about having a flourishing career where you can thrive, both in and out of work. At Frost, we're committed to fostering an environment that reflects our values and encourages team members to be the best they can be. In joining our adaptable, integrity-driven team, you'll become part of Frost's over 150-year legacy of providing unparalleled banking services.\\nWho you are: \\nAs a Data Engineer III, you will lead the development and implementation of ETL processes and data pipelines. You'll play an important role in designing and building scalable and reliable data infrastructures. You'll use your strong problem-solving skills to ensure that the systems are performing optimally and meet our high standards. You believe in effective communication and will have the opportunity to address potential problems and solutions to complex issues.\\nWhat you'll do: \\n\\nDevelop and maintain data pipelines to automate data ingestion and processing\\nCollaborate with stakeholders to identify data requirements and ensure data infrastructure meets business needs\\nDevelop and enforce data governance policies and standards\\nMonitor data infrastructure and performance to identify and resolve issues\\nDrive best practices via code and design reviews\\nCoach, mentor, and provide technical assessments\\nProvide guidance to other Data Engineers as needed\\nStay up to date with industry trends and new technologies in data engineering\\nAlways take action using integrity, caring, and excellence to achieve all-win outcomes\\n\\nWhat you'll need: \\n\\nBachelor's degree in Computer Science, Information Technology, or related field\\n4+ Years of experience as a data engineer\\n3+ Years of experience developing in either Python, Java , Scapa or Spark\\nAdvanced understanding of database technologies such as SQL and NoSQL\\nExpertise in ETL tools and techniques\\nKnowledge of data modeling and schema design\\nStrong problem-solving and analytical skills\\nFamiliarity with Big Data technologies such as Hadoop, Spark, Hive, and Cloud native data engineering technologies\\nExperience leveraging cloud technologies to develop data pipelines \\nMastery of data modeling concepts \\nStrong understanding of ETL concepts and Data Warehousing concepts\\nExperience with CI/CD pipelines\\nExperience with version control software\\nStrong understanding of Agile Principles (Scrum)\\nExcellent written and verbal communication skills\\n\\nOur Benefits:\\nAt Frost, we care about your health, your family, and your future and strive to have our benefits reflect that. This includes: \\n\\nMedical, dental, vision, long-term disability, and life insurance\\n401(k) matching\\nGenerous holiday and paid time off schedule\\nTuition reimbursement\\nExtensive health and wellness programs, including our Employee Assistance Program\\nReferral bonus program + more!\\n\\nSince 1868, Frost has dedicated their expertise to provide exceptional banking, investment, and insurance services to businesses and individuals throughout Texas. Frost is one of the 50 largest U.S. banks by asset size and is a leader in banking customer satisfaction. At Frost, it's about being part of something bigger. If this sounds like you, we encourage you to apply and see what's possible at Frost.\"}, {'job_title': 'Data Engineer III', 'job_url': 'https://search.linkup.com/details/25118b7ecf525153b0a8a7395e185f49', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 53, 407355), 'description': \"JobID: 210435918\\nCategory: Data Engineering\\nJobSchedule: Full time\\nPosted Date: 2023-07-17T21:53:53+00:00\\nJobShift: \\n:\\nBe part of a dynamic team where your distinctive skills will contribute to a winning culture and team.\\nJob Summary\\nAs a Data Engineer III at JPMorgan Chase within the [insert LOB or sub LOB], you serve as a seasoned member of an agile team to design and deliver trusted data collection, storage, access, and analytics solutions in a secure, stable, and scalable way. You are responsible for developing, testing, and maintaining critical data pipelines and architectures across multiple technical areas within various business functions in support of the firm's business objectives.\\nJob Responsibilities\\n\\nSupports review of controls to ensure sufficient protection of enterprise data\\nResponsible for advising and making custom configuration changes in one to two tools to generate a product at the business or customer request\\nUpdates logical or physical data models based on new use cases\\nFrequently uses SQL and understands NoSQL databases and their niche in the marketplace\\nAdds to team culture of diversity, equity, inclusion, and respect\\n\\nRequired Qualifications, Capabilities, and Skills\\n\\nExperience across the data lifecycle\\nAdvanced at SQL (e.g., joins and aggregations)\\nWorking understanding of NoSQL databases\\nSignificant experience with statistical data analysis and ability to determine appropriate tools and data patterns to perform analysis\\nExperience customizing changes in a tool to generate product\\n\\nPreferred Qualifications, Capabilities, and Skills\\n\\nExperience working in development teams, using Agile techniques and Object Oriented development and scripting languages, is preferred\\nExperience with data management process on AWS is a huge Plus\\nFinancial Services and Commercial banking experience is a plus\\nFamiliarity with NoSQL database platforms(DynamoDB, Cassandra) is a plus\"}, {'job_title': 'Senior Data Engineer', 'job_url': 'https://search.linkup.com/details/e7a2368a3ce77f92053b3d2f18a20b25', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 52, 57, 893722), 'description': \"To ensure that Visa's payment technology is truly available to everyone, everywhere requires the success of our key bank or merchant partners and internal business units. The Global Data Science group supports these partners by using our extraordinarily rich data set that spans more than 3 billion cards globally and captures more than 100 billion transactions in a single year. Our focus lies on building creative solutions that have an immediate impact on the business of our highly analytical partners. We work in complementary teams comprising members from Data Science and various groups at Visa. To support our rapidly growing group we are looking for data engineers who are equally passionate about the opportunity to use Visa's rich data to tackle meaningful business problems.\\nThis position will be part of VCA (Visa Consulting & Analytics) function in building and maintaining global data assets and engineering solutions. In this role, you will be responsible for helping to develop a global engineering and solutions team focused in standardized development of Consulting Solutions. You will partner closely with Global stake holders in Visa consulting, data Science and data engineering teams. You will get chance to leverage your strategic planning, business analysis and technical knowledge of data engineering, tools and data architecture solutions. In addition to managing our portfolio of data engineering assets and solutions globally, you will play key roles in building relationships with Consulting partners to develop effective market response strategies. You will also be a hands-on expert able to direct & navigate both data engineering and data science teams to build effective data engineering solutions.\\nEssential Functions\\n\\nExposure working with Global teams & Fortune 500 companies and possess strong experience working directly in client facing roles.\\nExecute and manage large scale ETL processes to support development and publishing of reports, Datamart's and predictive models.\\nStrong Data Analytical and Visualization skills along with experience in self-service reporting tools like Tableau or Power BI with KPIs and facilitate Visa Consulting engagements including data exchange.\\nDeliver small to medium complexity dashboard projects either individually or as part of a project team.\\nUse design prototyping rigor and consultative best practices with our stakeholders\\nDevelop solutions leveraging agile principles\\nProvide operational production support for the dashboards on Tableau Server.\\nShould have strong problem-solving capabilities and ability to quickly propose feasible solutions and effectively communicate strategy and risk mitigation approaches to leadership. \\nBuild and maintain high performing ETL processes, including data quality and testing aligned across technology, internal reporting and other functional teams\\nCreate data dictionaries, setup/monitor data validation alerts and execute periodic jobs like performance dashboards, predictive models scoring for client's deliverables \\nDefine and build technical/data documentation and experience with code version control systems (e.g. git). Ensure data accuracy, integrity and consistency\\nFind opportunities to create, automate and scale repeatable financial and statistical analysis for Visa Consulting and Analytics.\\nCollaborate with Data Engineering teams in North America and other Global regions to production and maintenance of key data assets.\\nStrong written, verbal, and interpersonal skills needed to effectively communicate technical insights and recommendations with business customers and leadership team.\\n\\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.\"}, {'job_title': 'Data Engineer III', 'job_url': 'https://search.linkup.com/details/2093a8ba29661155f65323407f1801bb', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 2, 427402), 'description': \"What you'll do...\\nPosition: Data Engineer III\\nJob Location: 603 Munger Avenue, #400, Dallas, TX 75202\\nDuties: Problem Formulation: Identifies possible options to address the business problems within one's discipline through analytics, big data analytics, and automation. Applied Business Acumen: Supports the development of business cases and recommendations. Owns delivery of project activity and tasks assigned by others. Supports process updates and changes. Solves business issues. Data Governance: Supports the documentation of data governance processes. Supports the implementation of data governance practices. Data Strategy: Understands, articulates, and applies principles of the defined strategy to routine business problems that involve a single function. Data Transformation and Integration: Extracts data from identified databases. Creates data pipelines and transform data to a structure that is relevant to the problem by selecting appropriate techniques. Develops knowledge of current data science and analytics trends. Data Source Identification: Supports the understanding of the priority order of requirements and service level agreements. Helps identify the most suitable source for data that is fit for purpose. Performs initial data quality checks on extracted data. Data Modeling: Analyzes complex data elements, systems, data flows, dependencies, and relationships to contribute to conceptual, physical, and logical data models. Develops the Logical Data Model and Physical Data Models including data warehouse and data mart designs. Defines relational tables, primary and foreign keys, and stored procedures to create a data model structure. Evaluates existing data models and physical databases for variances and discrepancies. Develops efficient data flows. Analyzes data-related system integration challenges and proposes appropriate solutions. Creates training documentation and trains end-users on data modeling. Oversees the tasks of less experienced programmers and stipulates system troubleshooting supports. Code Development and Testing: Writes code to develop the required solution and application features by determining the appropriate programming language and leveraging business, technical, and data requirements. Creates test cases to review and validate the proposed solution design. Creates proofs of concept. Tests the code using the appropriate testing approach. Deploys software to production servers. Contributes code documentation, maintains playbooks, and provides timely progress updates.\\nMinimum education and experience required: Bachelor's degree or the equivalent in Computer Science, Information Technology, Engineering, or related field and 2 years of experience in software engineering or related experience; OR 4 years of experience in software engineering or related field; OR Master's degree or the equivalent in Computer Science, Information Technology, Engineering, or related field.\\nSkills required: Must have experience with: Designing, development and testing Relational Database Management Systems (MySQL, Microsoft SQL Server, Postgres); Working in fast paced environment following Agile methodologies; Data warehousing concepts, methodologies, and frameworks using current (SparkSQL, Hadoop, Kafka, Hive) distributed technologies; Designing and developing analytical dashboards using Business Intelligence Reporting Tools (Tableau, PowerBI, Looker); Coding in Object-Oriented programming languages (Java, Python, Scala); Coding in scripting language (Python, Shell scripts, Ruby, Perl); Software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source control management, build processes, testing, and operations (Git, Jenkins); Identifying business use cases and transform business problems to scalable analytical solutions; Using IDE tools (VSCode, IntelliJ); Identifying, debugging issues corresponding to the business domain and designing solutions; and Datastructures and algorithms. Employer will accept any amount of graduate coursework, graduate research experience or experience with the required skills.\\nLI-DNP #LI-DNI\\nWal-Mart is an Equal Opportunity Employer.\\nAbout Walmart\\nAt Walmart, we help people save money so they can live better. This mission serves as the foundation for every decision we make, from responsible sourcing to sustainability—and everything in between. As a Walmart associate, you will play an integral role in shaping the future of retail, tech, merchandising, finance and hundreds of other industries—all while affecting the lives of millions of customers all over the world. Here, your work makes an impact every day. What are you waiting for?\\nWalmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.\\nAll the benefits you need for you and your family\\n\\nMultiple health plan options, including vision & dental plans for you & dependents\\nFinancial benefits including 401(k), stock purchase plans, life insurance and more\\nAssociate discounts in-store and online\\nEducation assistance for Associate and dependents\\nParental Leave\\nPay during military service\\nPaid Time off - to include vacation, sick, parental\\nShort-term and long-term disability for when you can't work because of injury, illness, or childbirth\\n\\nEligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to specific plan or program terms. For information about benefits and eligibility, see One.Walmart.com/Benefits.\\nFrequently asked questions\\n\\nOn average, how long does it take to fill out an application?\\n\\nOn average, it takes 45-60 minutes to complete your application for the first time. Subsequent applications will take less time to apply as our system saves some of your application information. Please note that some positions require the completion of assessments in order to receive consideration for that role. Those would take additional time.\\n\\nCan I change my application after submitting?\\n\\nNo, you cannot change your application after submitting, so please make sure that everything is finalized before you hit the submit button.\\n\\nHow do you protect my personal information?\\n\\nProcessing of information on paper is minimal, and Walmart processes application information using an applicant tracking system (ATS). Access to the data within the ATS is restricted to authorized personnel, and the system itself is held to high security standards by Walmart.\\n\\nWhat are the recommended Internet Browsers for applying for open roles?\\nInternet Explorer 8.0+\\nFirefox 4.0+\\nSafari 4.0+\\nChrome 12+\\n\\nSee All FAQs\\nRecently viewed jobs\"}, {'job_title': 'Senior Data Engineer', 'job_url': 'https://search.linkup.com/details/51eef2a9e46cea99f3124494cbb3f916', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 6, 939821), 'description': 'Who we are: At Wunderman Thompson we exist to inspire growth for ambitious brands. Part creative agency, part consultancy and part technology company, our experts provide end-to-end capabilities at a global scale to deliver inspiration across the entire brand and customer experience. We are 20,000 strong in 90 markets around the world; our people bring together creative storytelling, diverse perspectives, inclusive thinking, and highly specialized vertical capabilities to drive growth for our clients. We offer deep expertise across the entire customer journey, including communications, commerce, consultancy, CRM, CX, data, production, and technology. \\nWho is Wunderman Thompson MAP Wunderman Thompson MAP is the world-leading center of excellence for Marketing Automation, Personalization, Loyalty and CRM at scale. Our mission is to deliver value for our clients by humanizing the relationship between the brand and the consumer. To do this, we help clients make data-driven and personalized experiences that can be scaled with efficiency and operationalized intelligently. We believe that serving consumers personal, mindful content in an omnichannel world is key to transforming experiences. With the brain of a consultancy, the heart of an agency and the power of technology and data, we work with some of the world\\'s most admired brands to help them on their transformation journey to becoming truly customer-centric. At Wunderman Thompson MAP, we are always making room for more. We are 800+ technology specialists, data scientists, strategic thinkers, consultants, operations experts, and creative minds from 40+ nationalities who collaborate closely to help our clients inspire and engage consumers on five continents. Who we are looking for: Are you a Senior Data Engineer with a passion to build, support & maintain digital marketing solutions that offers real value? Are you interested in working with the largest global brands and complex challenges in the media analytics space? Then you might be the Senior Data Engineer we\\'re looking for! What will your day look like? As our new Senior Data Engineer, you will become part of our growing Data Insights and Science team. Here, you will employ new technologies across multiple cloud platforms to help successful brands reach their next level in 1:1 retargeting, communication and CRM. More specifically, your tasks include:\\n\\nIdentify, collect, and integrate data from various sources by building high quality data pipelines and data models for analytics and business intelligence (BI) purpose.\\nDevelop and optimize code to enable pipelines at minimum cost and ease of maintenance.\\nBuild monitoring procedures & tools to ensure solid ETL flows and data quality.\\nDesign processes and tools to correct ETL incidents.\\nCollaborate with CRM developers, data scientists and data analysts and product owners to ensure the supplied data supports the business initiatives.\\nConsult our data analytics teams to ensure best practices on the technical use of data are followed.\\nDesign data architectures and collaborate in data migrations in cloud environments.Who are you going to work with?\\n\\nYou will join a team of highly skilled Architects, Data Scientists and Consultants who are passionate about unlocking insights from data through analytics. You will also get to work closely with experts from other Technology, Creative and Client Teams. What do you bring to the table? As a person, you have a team player mindset and an open-minded attitude. You can communicate ideas and technical topics honestly and clearly - also to non-experts - while respecting the views of others on the team. You are eager to understand and find solutions, allowing you to quickly adapt to changing situations and come up with new ideas. At the same time, you solve problems in an analytical and pragmatic manner. Moreover, you have:\\n\\n4+ years of experience in data engineering, big data, business intelligence or data science\\n4+ years of experience in Spark, Python, Scala or similar.\\nExcellent SQL skills enabling large scale data transformation and analysis.A comprehensive understanding of cloud data warehousing, data pipelines and data transformation (extract, transform and load) processes and supporting technologies such as Google Dataflow, Looker, DBT, EMR, CI/CD Pipelines, Airflow DAGs, and other analytics tool.\\nExperience with cloud based data infrastructures (Ideally GCP, but AWS or Azure would also suffice)\\nProgramming experience in Javascript, Python or similar.\\nExpertise in managing databases, including performance tuning, backup and recovery.\\nSolid knowledge of data quality management best practices, including data profiling, data cleansing, and data validation\\nKnowledge of strengths and limitations of visualization tool (e.g. PowerBI, Tableau, Looker etc) in terms of data modelling in the visualization tools.\\nUnderstanding of versioning control tools like GitHub to changes related to dbt models and transformations, ensuring that changes are tracked, documented, and reviewed by the appropriate stakeholders.\\nKnowledge of applying data governance principles, policies, and practices that ensure data accuracy, consistency, and security\\nKnowledge of Kubernetes would be an advantage\\n\\nPersonal skills:\\n\\nStrong desire to contribute towards keeping data tidy and well organized\\nAbility to think critically, identifying issues autonomously, and proposing corrective actions.\\nBuild great relationships with your team and stakeholders\\nA leader in personalised customer experiences\\n\\nWhat we offer:\\n\\nPassionate, driven people | We champion a culture of people that do extraordinary work.\\nConsciously cultivated culture | We aim to embody the behaviors to build an inclusive community that is in it together, bringing both positivity and active listening into the workplace as we simultaneously strive to empower creative bravery.\\nCompetitive benefits | What we offer full time hires ranges from the full spectrum of group health coverage options (medical, dental, vision) to a generous 401k match (100% dollar-for-dollar match, up to 5% of salary contribution), and a variety of paid time off offerings that reflect our investment in all aspects of your overall life balance and wellness.\\nGrowth-minded opportunities | We aim to nurture a culture of real-time feedback, growth-oriented mindset, and plenty of training opportunities through Wunderman Thompson and WPP, so you can continue to grow personally and professionally.\\n\\nWunderman Thompson is an equal opportunity employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability, or other protected group status. We believe in creating a dynamic work environment that values diversity and inclusion and strives to recruit a diverse slate of candidates to help us achieve that goal. #LI-JK1 \\nThe base salary range for this position at the time of this posting is indicated below. Individual compensation varies based on job-related factors, including location, business needs, level of responsibility, experience, and qualifications. We offer a competitive benefits package, click WPP Benefits for more details. \\n_ \\n$80,000-$140,000 USD \\nAt Wunderman Thompson, we are committed to actively building a diverse, equitable and inclusive workplace where everyone feels welcomed, valued and heard, and is treated with dignity and respect. As leaders and creative partners across industries, it is our responsibility to cultivate an environment reflective of our greatest asset; our people. We believe that this commitment inspires growth and delivers equitable outcomes for everyone as well as the clients and communities we serve. Wunderman Thompson is a WPP agency. For more information, please visit our website and follow Wunderman Thompson on our social channels via Twitter, Facebook, LinkedIn, and Instagram. Note: We rely on legitimate interest as a legal basis for processing personal information under the GDPR for purposes of recruitment and applications for employment. When you click the \"Submit Application\" button below, this will send any information you add below to Wunderman Thompson. Before you do this, we think it\\'s a good idea to read through our Recruitment Privacy Policy. California residents should read our California Recruitment Privacy Notice. This explains what we do with your personal data when you apply for a role with us, and, how you can update the information you have provided us with or how to remove it.'}, {'job_title': 'Experienced Data Engineer', 'job_url': 'https://search.linkup.com/details/e6f873d97749b467e84e3279efbf5083', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 11, 962738), 'description': \"What You'll Do\\nWe're looking for a Data Engineer to join our Information Security Risk space, supporting and maintaining data and analytics for our Governance, Risk, and Compliance (GRC) area. In this role, you'll apply your data engineering and analysis expertise to meet business requirements and improve effectiveness! Demonstrate independence working in more than one software development layer of the solution.\\n\\nCoordinate technical aspects of data management functions including creating, loading, transforming, cleansing, processing, analyzing, and visualizing data. \\nWork directly or in support of data science/analytics to design, develop, test and integrate data from various sources into large-scale processing systems and databases to use in providing insights that address business needs.\\nResponsible for creating data management process designs, models, and architectures by understanding architectural patterns and principles, researching new technologies and approaches, understanding requirements, testing, debugging, documentation, quality assurance review, implementation, securing and maintenance. Be persistent in the face of roadblocks, dispatch them efficiently, collaborating with others as needed.\\nDemonstrate knowledge of industry trends, creates optimized data components and systems that use appropriate development environment. Employ a variety of languages and tools (e.g. scripting languages, data movement tools) to marry systems together. Recommend ways to improve data reliability, efficiency and quality.\\nAssist in developing strategies for data acquisition and influence others within the business area through explanation of policies, patterns and practices.\\nProvide technical guidance to team members on integration and functionality of infrastructure components.\\nDemonstrate influence at the department level. Provide mentoring to team. Communicate effectively across business unit and IT.\\nIndependently conduct analysis and development, requirements, coding, automated testing, debugging, designing, documentation, quality assurance review, implementation and maintenance.\\nPerform other job-related duties or special projects as required.\\n\\nOperating at the intersection of financial services and technology, Principal builds financial tools that help our customers live better lives. We take pride in being a purpose-led firm, motivated by our mission to make financial security accessible to all. Our mission, integrity, and customer focus have made us a trusted leader for more than 140 years. \\nAs Principal continues to modernize its systems, this role will offer you an exciting opportunity to build solutions that will directly impact our long-term strategy and tech stack, all while ensuring that our products are robust, scalable, and secure!\\nWho You Are\\n\\nBachelor's degree plus 4+ years related work experience or a Master's in related field.\\nAbility to work directly with data and datastores through programming language such as SQL, Python, etc.\\nExperience with a variety of data modeling techniques and data structures.\\nAbility to optimize data for analytics and data science.\\nExperience building/operating systems for data extraction, ingestion and processing of large data sets.\\nKnowledge and direct experience using business intelligence reporting tools.\\nExperience building data products incrementally and integrating and running datasets from multiple sources.\\nExcellent planning, organizational, problem-solving, analytical, decision-making and communication skills required.\\nExcellent time management skills preferred.\\nAbility to collaborate and communicate with various levels required. Eg; effectively communicate strategies and designs to all levels of company.\\n\\nSkills That Will Help You Stand Out \\n\\nPower BI with Dax functions\\nPython scripting\\nSQL\\nCloud Technologies (i.e. AWS, Snowflake)\\n\\nSalary Range Information\\nSalary ranges below reflect targeted base salaries. Non-sales positions have the opportunity to participate in a bonus program. Sales positions are eligible for sales incentives, and in some instances a bonus plan, whereby total compensation may far exceed base salary depending on individual performance. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer.\\nSalary Range\\n$77400 - $182400 / year\\nAdditional Information\\nOur Engineering Culture\\nThrough our product-driven Agile/Lean DevOps environment, we've fostered a culture of innovation and experimentation across our development teams. As a customer-focused organization, we work closely with our end users and product owners to understand and rapidly respond to emerging business needs.\\nCollaboration is embedded into everything we do – from the products we develop to the quality service we provide. We're driven by the belief that diversity of thought, background, and perspective is critical to creating the best products and experiences for our customers. \\nHours: \\nMay require some after normal business hour support.\\nWork Environment:\\nThis role offers the ability for in-office, hybrid (blending both office and remote work in a typical workweek), and remote work arrangements. You'll work with your leader to figure out which option may align best based on several factors.\\nJob Level\\nWe'll consider talent at the next level with the right experience, background and skill level.\\nWork Authorization/Sponsorship \\nAt this time, we're not considering applicants that need any type of immigration sponsorship (additional work authorization or permanent work authorization) now or in the future to work in the United States. This includes, but IS NOT LIMITED TO: F1-OPT, F1-CPT, H-1B, TN, L-1, J-1, etc. For additional information around work authorization needs please use the following links.\\nNonimmigrant Workers and Green Card for Employment-Based Immigrants\\nInvestment Code of Ethics \\nFor Principal Asset Management positions, you'll need to follow an Investment Code of Ethics related to personal and business conduct as well as personal trading activities for you and members of your household. These same requirements may also apply to other positions across the organization.\\nExperience Principal \\nAt Principal, we value connecting on both a personal and professional level. Together, we're imagining a more purpose-led future for financial services – and that starts with you. Our success depends on the unique experiences, backgrounds, and talents of our employees. And we support our employees the same way we support our customers: with comprehensive, competitive benefit offerings crafted to protect their physical, financial, and social well-being. Check out our careers site to learn more about our purpose, values and benefits.\\nPrincipal is an Equal Opportunity Employer \\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.\\nLinkedIn Remote Hashtag\\nLI-Remote\"}, {'job_title': 'Sr. Data Engineer', 'job_url': 'https://search.linkup.com/details/aa2ef1a792d7433af78d8ff52d69e69e', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 16, 419582), 'description': \"OVERVIEW\\nThe S&B Family of Companies is currently seeking a highly motivated and dynamic Senior Data Engineer to join our esteemed team in Houston, TX. As a Senior Data Engineer, you will play a critical role in developing modern data architecture approaches that align with our key business objectives. You will be responsible for delivering end-to-end data solutions, encompassing analysis, design, development, testing, implementation, and initial maintenance of the solution. Moreover, you will act as a key interface between subject matter experts, product owners, executives, and our enterprise data analytics team, ensuring a holistic approach to deliver reusable data assets that empower effective data solutions. In this position, you will leverage your expertise to design and implement robust data engineering solutions that drive actionable insights and support informed decision-making. Your contributions will be instrumental in shaping our data infrastructure, enabling efficient and scalable data processing, storage, and retrieval.\\nJoin our collaborative and innovative team at S&B, where you will have the opportunity to make a significant impact by delivering cutting-edge data solutions. We foster a culture of continuous learning and growth, providing ample opportunities for professional development and advancement. If you are passionate about leveraging data to drive business outcomes and are excited about being part of a forward-thinking organization, we invite you to join us as a Senior Data Engineer in Houston, TX.\\nSUPERVISORY RESPONSIBILITIES\\nMay provide technical guidance to 1-3 data analysts or Jr. data engineers.\\nEDUCATION\\nBachelor's Degree in management information systems, computer science or related field.\\nQUALIFICATIONS AND EXPERIENCE\\n\\nRequires a minimum of 10 years of experience as a Data Engineer\\nExperience with modelling and data engineering tools tolls and platforms such as Kafka, Spark, and Hadoop.\\nYou have built large-scale data pipelines and data-centric applications using any of the distributed storage platforms such as HDFS, S3, NoSQL databases (Hbase, Cassandra, etc.) and any of the distributed processing platforms like Hadoop, Spark, Hive, and Airflow in a production setting.\\nA successful history of manipulating, processing, and extracting value from large, disconnected datasets.\\nAbility to build and optimize data sets, 'big data' data pipelines and architectures\\nComfortable taking data-driven approaches and applying data security strategy to solve business problems.\\nAbility to perform root cause analysis on external and internal processes and data to identify opportunities for improvement and answer questions.\\nAbility to build processes that support data transformation, workload management, data structures, dependency, and metadata.\\nHands on experience in writing complex SQL queries\\nExperience developing ETL scripts\\nProgramming experience in Python, Spark, Unix/shell scripting is a plus.\\nWorking knowledge of creating and maintaining data loads in the cloud (AWS, Azure, GCP).\\nStrong analytical and problem-solving skills.\\nExcellent communication and collaboration skills to work across multiple groups within the organization.\\nKnowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operation.\\n\\nTYPICAL DUTIES AND RESPONSIBILITIES\\n\\nCreate data models and speak to the tradeoffs of different modelling approaches.\\nLeverage various continuous delivery practices deploy, support, and operate data pipelines.\\nAssemble large, complex data sets that meet functional / non-functional business requirements.\\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.\\nBuild analytics that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.\\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.\\nSeamlessly incorporate data quality into the day-to-day work as well as into the delivery process.\\nPrepare data for predictive and prescriptive modeling\\n\\nLANGUAGE SKILLS\\nAbility to read, analyze and interpret general business periodicals, professional journals, and technical systems documentation. Job success often hinges upon interpersonal communication and relationship development skills, and job tasks require frequent interchange and successful completion depends in large part upon effective interaction and communication with others.\\nMATHEMATICAL SKILLS\\nBasic mathematical and algebraic equations required. Foundational knowledge of statistics.\\nPHYSICAL DEMANDS\\nOccasionally, will conduct or participate in a field trip to operating plants, construction sites or other office complexes. This requires the ability to stand, walk, clear close and distance vision, depth perception and the ability to focus.\\nWORK ENVIRONMENT\\nNormal work environment will be a business office with moderate noise. Occasionally, will conduct or participate in a field trip to operating plants, construction sites or other office complexes. This may require exposure to outdoor weather conditions, loud noises, work near moving mechanical parts, electrical energy, construction equipment, vibration, fumes, chemicals, and airborne particles.\\nABOUT S&B\\nS&B is an exceptional full-service Engineering, Procurement, and Construction (EPC) company, proudly maintaining private ownership and operation for over five decades. With our extensive experience, we have successfully undertaken diverse projects across various industries, including Oil & Gas, Chemicals, Petrochemicals, Energy Transition, Power, and Pulp & Paper. What sets us apart is our unwavering commitment to safety, timely project completion, and cost-effective solutions. Our proven track record speaks for itself, as we consistently deliver outstanding results while adhering to the highest industry standards. Moreover, our company culture is unparalleled, fostering an environment of collaboration, innovation, and excellence. At S&B, we understand the value of our talented team, and we ensure they are rewarded accordingly. We offer a competitive compensation package and a comprehensive benefits program to attract and retain the best professionals in the field.\\nLI-Hybrid\"}, {'job_title': 'Data Engineer Apprenticeship', 'job_url': 'https://search.linkup.com/details/16955240eb1184ade8dd38d0f0f1ff8a', 'location': 'Paris, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 22, 295821), 'description': \"What You'll Do:\\nMost of all, we are creators. From designing ground-breaking products to finding unique ways to solve technical challenges at an exceptional scale, our tech teams work with\\u202fstate-of-the-art\\u202fmethodologies to shape the future of advertising.\\u202f\\nThe Product Engineering team builds the products that make Criteo tick: from developing industry leading machine learning techniques, to building high scale/low latency\\u202freal-time\\u202fapplications (over 5M\\u202fQPS,\\u202fhandling over 300 Bn HTTP requests daily), to delivering first class client interfaces, both API and UI, with\\u202fforward-thinking\\u202fUX at their core, all using state of the art technology.\\u202f\\nDuring your apprenticeship (1-3 years) and according to your choice, skills and interest, you can tackle one of the following subjects: \\n\\n\\nCreate high quality, maintainable code that processes and analyzes almost 400 million events daily (and doubling every year)\\n\\n\\nUtilize one the largest private Hadoop clusters in the world and a bleeding edge suite of technologies that push the limits of modern data processing\\n\\n\\nDesign and perfect data models that isolate signal in the noise of real world data and make difficult challenges possible for fellow engineers\\n\\n\\nQuality improvement of our most valuable datasets, including fraud and low-relevance data detection.\\n\\nIn a team of 5-7, you will be working closely with your mentor to drive your project, design and ensure best practices are applied. You can ask questions and participate in all knowledge-sharing sessions/workshops, etc. You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production which will likely affect millions of users instantly. \\n\\nWho You Are:\\n\\n\\nYou are enrolled in school for study in Computer Science or Statistics/Math background. \\n\\n\\nYour school could provide an apprenticeship contract. \\n\\n\\nYou know your coding basics and understand that the future of network engineering is software defined. \\n\\n\\nYou are a strong communicator and a team player who can work efficiently with others and you are fluent in English. \\n\\nYou already have experience in Object Oriented Programming (C#, Python, Java...) or if you occasionally participate in coding competitions. \\n\\nWe acknowledge that many candidates may not meet every single role requirement listed above. If your experience looks a little different from our requirements but you believe that you can still bring value to the role, we'd love to see your application!\\nWe acknowledge that many candidates may not meet every single role requirement listed above. If your experience looks a little different from our requirements but you believe that you can still bring value to the role, we'd love to see your application!\\nWho We Are:\\nCriteo is the global commerce media company that enables marketers and media owners to deliver richer consumer experiences and drive better commerce outcomes through its industry leading Commerce Media Platform. At Criteo, our culture is as unique as it is diverse. From our offices around the world or from home, our incredible team of 3,600 Criteos collaborates to develop an open and inclusive environment. We aim to create a place where people can grow and learn from each other while having a meaningful impact. We work together to achieve our goals, push boundaries, and share successes. All of this supports us in our mission to power the world's marketers with trusted and impactful advertising encouraging discovery, innovation and choice in an open internet.\\nWhy Join Us:\\nAt Criteo, we take pride in being a caring culture and are committed to providing our employees with valuable benefits that support their physical, emotional and financial wellbeing, their interests and the important life events. We will set you up for success and empower you to have a meaningful impact in your job, and an important part of that includes comprehensive perks & benefits. Benefits may vary depending on the country where you work and the nature of your employment with Criteo. When determining compensation, we carefully consider a wide range of job-related factors, including experience, knowledge, skills, education, and location. These factors can cause your compensation to vary.\"}, {'job_title': 'Lead Data Engineer', 'job_url': 'https://search.linkup.com/details/8cab58147bafacf0b3a3f29dc5a5cbcc', 'location': 'Addison, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 26, 296478), 'description': \"Wells Fargo is seeking a Lead Data Engineer... \\nAbout this role: \\nWells Fargo is seeking a Lead Data Engineer with strong technical expertise to build a Data Pipeline using Big Data and Cloud technologies. This position will be required to have deep knowledge in Data, Steaming, self-service BI tools and Micro Services. This position will need to understand the current challenges and opportunities with existing technology implementation and drive formulate the target state aligned to our strategies. This supports our business partners in adapting new workflows, processes, and mindsets to meet their goals. Work with business stakeholders to support strategic business initiative by bringing value based and practical technology innovations and solutions. Collaborate with internal business and technical partner teams to improve effectiveness of delivery and reduce/eliminate wasteful activities (maintain service and operating level agreements) \\nIn this role, you will: \\n\\nReview and analyze complex, large-scale technology solutions for tactical and strategic business objectives, enterprise technological environment, and technical challenges that require in-depth evaluation of multiple factors, including intangibles or unprecedented technical factors \\nMake decisions in developing standard and companywide best practices for engineering and technology solutions requiring understanding of industry best practices and new technologies, influencing and leading technology team to meet deliverables and drive new initiatives \\nLead complex technology initiatives including those that are companywide with broad impact \\nAct as a key participant in developing standards and companywide best practices for engineering complex and large scale technology solutions for technology engineering disciplines \\nDesign, code, test, debug, and document for projects and programs \\nLead projects, teams, or serve as a peer mentor. \\n\\nRequired Qualifications: \\n\\n5+ years of Data Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education \\n3+ years of Data management, Data Integration, Data Warehouse and BI experience \\n3+ years of experience with Dev-Ops, CICD Pipeline \\nStrong hands-on experience in SQL, Python/Spark \\nExperience Hadoop ecosystem tools relevant for real-time and batch data ingestion, processing and provisioning using tools such as Apache Flume, Apache Kafka, Apache Sqoop, Apache Flink, Apache Hive or Apache Storm \\nStrong experience in relational databases, Database design, Data Model development, querying, data warehousing, ETL process, requirements gathering and/or decision support tools. \\nHands-on experience in SQL especially in SQL Server & Teradata environment \\nHands on experience in ETL development \\n\\nDesired Qualifications: \\n\\nExperience designing and optimizing complex SQL and/or SAS queries \\nExperience working in operational reporting \\nExperience with Agile Scrum (Daily Standup, Sprint Planning and Sprint Retrospective meetings) and Kanban \\n2+ years of experience with modern software engineering technologies and tool sets \\n2+ years of experience with systems architecture and design \\n3+ years of information technology systems design and planning experience; in data, systems, applications, or architecture \\n3+ years of experience in building Data APIs/Services \\nKnowledge and understanding of Home Lending \\n\\nWe Value Diversity \\nAt Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law. \\nEmployees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements. \\nCandidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. \\nCandidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process. \\nDrug and Alcohol Policy \\nWells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.\"}, {'job_title': 'Software Engineer III Data Engineer', 'job_url': 'https://search.linkup.com/details/1e1d498e06896934a5db16dd0c1d7d27', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 31, 315174), 'description': \"JobID: 210431976\\nCategory: Software Engineering\\nJobSchedule: Full time\\nPosted Date: 2023-07-19T15:03:27+00:00\\nJobShift: \\n:\\nWe have an exciting and rewarding opportunity for you to take your software engineering career to the next level. \\nAs a Software Engineer III at JPMorgan Chase within the [insert LOB or sub LOB], you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm's business objectives.\\nJob responsibilities\\n\\nExecutes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems\\nCreates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems\\nData domain knowledge and drive to learn about the data in the platform\\nGathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets \\nAdds to team culture of diversity, equity, inclusion, and respect\\n\\nRequired qualifications, capabilities, and skills\\n\\nFormal training or certification on software engineering concepts and 3+ years applied experience\\nHands-on practical experience in SQL to support data analysis\\nComfortable with streaming and big data concepts, build data systems and data pipelines using Java, Python, AWS Cloud Services (Redshift etc.)\\nSolid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security\\nOverall knowledge of the Software Development Life Cycle\\nFamiliar with Data Science concepts and applying them to analyze large volumes of data\\nExperience with BI technologies and management/regulatory reporting\\n\\nPreferred qualifications, capabilities, and skills\\n\\nFamiliarity with modern front-end technologies\\nExposure to cloud technologies\"}, {'job_title': 'Data Engineer (Public Sector)', 'job_url': 'https://search.linkup.com/details/b524d9ceadd34a7fbf2d7be03790aa1c', 'location': 'Arlington, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 39, 739559), 'description': \"Company Description\\nAs a Digital Business Transformation partner of choice at Publicis Sapient, we've spent nearly three decades utilizing the disruptive power of technology and ingenuity to help digitally enable our client's businesses in their pursuit of the next. Our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting, and customer obsession to accelerate our clients' businesses by designing the products and services their customers truly value. In the space between next and now is how. And we believe that how you seize that space is everything.\\nGreat Place to Work Certified in the US: https://www.greatplacetowork.com/certified-company/1000228\\nJob Description\\nPublicis Sapient is looking for a Senior Associate L2, Data Engineer to be part of our team of top-notch technologists. You will lead and deliver technical solutions for large-scale digital transformation projects. Working with the latest data technologies in the industry, you will be instrumental in helping our clients evolve for a more digital future.\\nPrimary Skill: Data Warehouse and ETL \\nQualifications\\nMust-Haves:\\n\\nApplication open to ONLY U.S. Citizens and Permanent Residents\\nMust be eligible to obtain U.S. Government Clearance (Public Trust)\\n6+ yrs of demonstrable\\u202fexp in data platforms\\u202finvolving the implementation of end-to-end data pipelines \\nHands-on exp\\u202fwith at least one of the leading\\u202fpublic cloud data platforms (Amazon Web Services, Azure, or Google Cloud) \\nExp\\u202fin implementing data pipelines for both streaming and batch integrations using\\u202ftools; Google Cloud Dataflow, Azure Data Factory, ksqlDB \\nExp working with\\u202fcode repositories and continuous integration \\nExp in data modeling, warehouse design, and fact/dimension implementations \\nStrong SQL knowledge to develop efficient and complex queries \\nExp working with Microsoft SQL Server \\nExp in data processing, transformation, and manipulation using Python (1+ yr exp)\\nExp developing, maintaining, and troubleshooting complex ETL processes using Microsoft SSIS \\nData ingest, validation, and enrichment pipeline design and implementation \\nAdheres to development standards, software development lifecycle processes \\nBachelor's degree\\u202fin Computer Science, Engineering, or a related field \\n\\nNice to have:\\n\\nExp in Snowflakes \\nExp in Tableau/ Power BI, familiarity with ArcGIS would be an asset\\nCertifications\\u202ffor any of the\\u202fcloud services\\u202flike\\u202fAWS, Google Cloud,\\u202fAzure \\nLogical\\u202fprogramming\\u202fin Spark/ PySpark /\\u202fScala \\n\\nAdditional Information\\nAnnual Pay Range: 108,000 - 135,000 USD\\nThe range shown represents a grouping of relevant ranges currently in use at Publicis Sapient. The actual range for this position may differ, depending on location and the specific skillset required for the work.\\nBenefits of Working Here:\\n\\nFlexible vacation policy\\nUnlimited PTO's\\n15 company paid holidays annually\\nWork Your World program\\nGenerous parental leave and new parent transition program\\nTuition reimbursement\\nCorporate gift matching program\"}, {'job_title': 'Data Engineer - PCHP', 'job_url': 'https://search.linkup.com/details/d1d6e5ee9ffc53e0ac2367faa081b836', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 43, 906100), 'description': \"Interested in a career with both meaning and growth? Whether your abilities are in direct patient care or one of the many other areas of healthcare administration and support, everyone at Parkland works together to fulfill our mission: the health and well-being of individuals and communities entrusted to our care. By joining Parkland, you become part of a diverse healthcare legacy that's served our community for more than 125 years. Put your skills to work with us, seek opportunities to learn and join a talented team where patient care is more than a job. It's our passion.\\nPrimary Purpose\\nThe Parkland Community Health Plan's (PCHP's) Data Engineer is responsible for maintaining the data systems including business intelligence, ETL, and supporting backup strategies in order to provide PCHP with secure, dependable, and accurate data including data transfer, data integrity, and data storage responsibilities. The Data Engineer will collaborate with Database Administrators, server team, storage team, and other teams to plan maintenance activities and with PHCP's analytics team for report or universe deployments. The Data Engineer will also be involved in dashboard and report development activities.\\nMinimum Specifications\\nEducation\\n\\nBachelor's degree in computer science, management information systems, information technology, statistics, mathematics, or related discipline.\\n\\nExperience\\n\\nSeven years of experience in maintaining business intelligence, data warehouse solutions, or ETL in a Run or Production environment.\\nSix years of experience troubleshooting ETL load related issues (SSIS or Data Solutions).\\nSix years of experience with ETL development and maintenance experience in a data warehouse environment.\\nExperience with systems engineering (hardware / software) capacity.\\nExperience with database or report portal tool administration is preferred.\\nExperience at a healthcare or managed care organization is preferred.\\n\\nEquivalent Education and/or Experience\\n\\nFive (5) years of experience with healthcare data management in a health plan or managed care organization may be considered in lieu of a degree.\\n\\nCertification/Registration/Licensure\\n\\nSystem Administration or Reporting Tool Administrative Certification is preferred. (i.e. Epic Cogito or Clarity, SAP Business Objects, Tibco Composite, Microsoft Certified Solutions Engineer (MCSE), Oracle Certified Professional (OCP), etc.)\\nPMP or other project management certificate or training is preferred.\\n\\nSkills or Special Abilities\\n\\nProficiency with ETL tool Build or Run activities.\\nAbility to create reports and/or build virtual data environments.\\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.\\nProficiency with Microsoft Office Excel, Word and Outlook is required; Access and PowerPoint are preferred.\\nDemonstrated critical thinking and troubleshooting skills accompanied by a high level of detail.\\nDemonstrated ability to plan and manage multiple processes and projects simultaneously.\\nHigh level of attention to detail.\\nStrong verbal and written communication skills.\\nDemonstrated ability to collaborate effectively and work as part of a team.\\nIndependent worker and self-starter, having the ability to provide internal motivation and drive.\\nProficiency with server or application patching, backups, scripting is preferred.\\nUnderstanding of SSIS and Apache NiFi is preferred.\\nProficiency with Business Objects Administration is preferred.\\n\\nResponsibilities\\n\\nImplements and maintains high-value business intelligence environments.\\nMaintains the data systems including business intelligence, ETL, and supporting backup strategies.\\nHas a strong understanding of all the tools within the environment, regardless of vendor, and quickly and efficiently triages, troubleshoots, and restores services during outages or service degradation.\\nResponsible for being on-call for Business Intelligence and ETL cycles.\\nWorks with the Database Analyst and storage teams to ensure proper backups are taken, test back-ups periodically, and ensures that the system can be restored in the time of a disaster.\\nProactively identifies areas for improvement in our Business Intelligence environment.\\nDocuments all routine processes and cross-trains other team members.\\nImproves function, speed, and accuracy of data distribution methods.\\nDevelops automated reports and dashboards.\\n\\nJob Accountabilities\\n\\nIdentifies ways to improve work processes and improve customer satisfaction. Makes recommendations to supervisor, implements, and monitors results as appropriate in support of the overall goals of PCHP.\\nStays abreast of the latest developments, advancements, and trends in the field by attending seminars/workshops, reading professional journals, actively participating in professional organizations, and/or maintaining certification or licensure. Integrates knowledge gained into current work practices.\\nMaintains knowledge of applicable rules, regulations, policies, laws, and guidelines that impact the area. Develops effective internal controls designed to promote adherence with applicable laws, accreditation agency requirements, and customer requirements. Seeks advice and guidance as needed to ensure proper understanding.\\n\\nParkland Health and Hospital System prohibits discrimination based on age (40 or over), race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, genetic information, disability, national origin, marital status, political belief, or veteran status. As part of our commitment to our patients and employees' wellness, Parkland Health is a tobacco and smoke-free campus.\\nNearest Major Market: Dallas \\nNearest Secondary Market: Fort Worth \\nJob Segment: Healthcare Administration, Patient Care, Public Health, EMR, Data Management, Healthcare, Data\"}, {'job_title': 'Principal- Big Data Engineer', 'job_url': 'https://search.linkup.com/details/a87fafe7f5bcef6d2c5860e3aa5b01d4', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 48, 721781), 'description': \"Job Overview \\nDUTIES: Responsible for interpreting the requirements of various Big Data analytics use cases and scenarios. Drive the design and implementation of specific data models to assist drive better business decision. Develop the necessary enables and data platform in the Big Data Lake Environment. Define data requirements, gather and mine large scale of structured and unstructured data, and validate data by running various data tools in a cloud environment. Support the standardization, customization and ad-hoc data analysis. Develop the mechanisms to ingest, analyze, validate, normalize and clean data. Implement statistical data quality procedures on new data sources, by applying rigorous iterative data analytics. Support Data Scientists in data sourcing and preparation to visualize data and synthesize insights of commercial value. Work with Big Data Policy and Security teams and Legal to create data policy and develop interfaces and retention models which requires synthesizing and anonymizing data. Develop and maintain data engineering best practices and contribute to insights on data analytics and visualization concepts, methods and techniques. Utilize Spark, Hadoop, MapReduce, Airflow, Snowflake, Hive, SQL, Scala, Python, and Linux/Unix.\\nREQUIREMENTS: Requires a Master's degree, or foreign equivalent degree, in Computer Science, Computer Engineering, Computer and Information Science or Information Technology and 3 years of experience in the job offered or 3 years of experience in a related occupation utilizing Spark, Hadoop, MapReduce, Airflow, Snowflake, Hive, SQL, Scala, Python, and Linux/Unix.\\nOur Principal- Big Data Engineers earn between $127,100 - $211,900 yearly. Not to mention all the other amazing rewards that working at AT&T offers.\\nJoining our team comes with amazing perks and benefits:\\n\\nMedical/Dental/Vision coverage\\n401(k) plan\\nTuition reimbursement program\\nPaid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year \\n\\nand 9 company-designated holidays)\\n\\nPaid Parental Leave\\nPaid Caregiver Leave\\nAdditional sick leave beyond what state and local law require may be available but is \\n\\nunprotected\\n\\nAdoption Reimbursement\\nDisability Benefits (short term and long term)\\nLife and Accidental Death Insurance\\nSupplemental benefit programs: critical illness/accident hospital indemnity/group legal\\nEmployee Assistance Programs (EAP)\\nExtensive employee wellness programs\\nEmployee discounts up to 50% off on eligible AT&T mobility plans and accessories, \\n\\nAT&T internet (and fiber where available) and AT&T phone\\nAT&T is an Affirmative Action/Equal Opportunity Employer, and we are committed to hiring a diverse and talented workforce. EOE/AA/M/F/D/V\\n\\nnp*\\n\\nJob ID 2317733 Date posted 07/20/2023 Apply Now\"}, {'job_title': 'Senior Data Engineer (Python/AWS/GCP)', 'job_url': 'https://search.linkup.com/details/ef3b7afd1bc4b5997400ed37548f700f', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 53, 530939), 'description': \"Req ID: 247008 \\nNTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.\\nWe are currently seeking a Senior Data Engineer (Python/AWS/GCP) to join our team in Dallas, Texas (US-TX), United States (US).\\nJob Duties and Responsibilities:\\n\\nUnderstand client requirements and understand case studies or current implementation for Predictive models, able to understand business domain needs and implement data pipelines & predictive models, Experience in Agile projects, work with multiple stakeholders like business, project team and deployment teams, ability to work independently and switch technical skills based on the project needs.\\nDetail oriented self-starter capable of working independently.\\n\\nExperience in ETL and ETL cloud services like AWS Data Pipeline Product Details, AWS Glue\\n\\nExperience with private or public cloud technology. \\nExcellent written and verbal communication skills with ability to document and design proposals.\\nExpert in writing software packaging and deploying into a fully automated environment.\\nExperience in Service Now.\\n\\nBasic Qualifications:\\n\\n5+ years of Release or Automation or Software Engineering experience, or equivalent.\\n5+ years Linux experience.\\n5+ years programming experience with Java or Python and scripting\\n3+ years of experience in DevSecOps toolchains/automation to achieve CICD, Blue-Green deployments, feature toggles (Git, Jenkins, uDeploy).\\n3+ years with Agile Scrum (Daily Standup, Sprint Planning and Sprint Retrospective meetings) and Kanban.\\nCADM-Cloud Apps-AWS (Amazon)- 3-5 years\\nData and Intelligence-ETL-Architecture-ETL Tools - 3-5 years\\n\\nINDFSINS\\nINDAPPS\\nAbout NTT DATA Services\\nNTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients' long-term success. Visit nttdata.com or LinkedIn to learn more.\\nNTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.\\nNearest Major Market: Dallas \\nNearest Secondary Market: Fort Worth \\nJob Segment: Cloud, Consulting, Developer, Java, Linux, Technology\"}, {'job_title': 'Principal Data Software Engineer', 'job_url': 'https://search.linkup.com/details/e16ec58ef3de98b7c051b49e76e2cc3b', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 53, 58, 249638), 'description': \"Working at Atlassian\\nAtlassians have flexibility in where they work – whether in an office, from home, or a combination of the two. That way, Atlassians have more control over supporting their family, personal goals, and other priorities. We can hire people in any country where we have a legal entity. Interviews and onboarding are conducted virtually, a part of being a distributed-first company.\\nApply for the Principal Data Software Engineer role at Atlassian and give yourself a chance to join one of our great US Based Product Development Teams working on our Enterprise Agility tools such as Jira Align. Have you heard of the Fortune 500 list? Yup, these are our Enterprise Agility Customers! They are BIG, with development teams reaching 50k users. Our tools allow data analysis of the largest software portfolios in the world. You will end up with your code helping millions of people all around the Globe!\\nWhat you'll do\\n\\nAs a Data Architect for the Enterprise Agility Engineering team, you'll work closely with multiple software engineering teams and product squads to improve Jira Align.\\nYou will refine and govern our logical data models which track team data for the largest software organizations in the world.\\nYou will guide designs and decisions for our data architecture through statistical analysis of production data.\\nYou will meet and work with our enterprise scale customers to put the personal touch on our engineering plans.\\nWe are also considering multiple database technologies to optimize the storage and retrieval for our end-users, including new solutions for data ingestion and translation. This exciting opportunity will engage you with our Site Reliability Engineering and Security teams as well the application development technical leads.\\nYou will work with design and product management team to translate our customer reporting requirements into improvements into our current mechanisms.\\nYou will work through our support and field organization to understand how our customers use our data today, to lead future changes as efficiently as possible.\\nThis role would be a great fit for an inclusive leader and coach, someone with a willingness to oversee the data architecture from every angle. You will develop and implement solutions that operate at scale - seeing your own technology efforts directly improve the product.\\nReport directly to the Senior Engineering Manager\\n\\nYour background\\n\\n15+ years of experience in Software Development\\nPublic cloud experience in AWS and/or Azure\\nTechnical leader, able to pitch ideas and lead programs to trigger across multiple teams and departments\\nProficiency in SQL, python, Java, C# or another JVM-based language\\nSuccess with designing and maintenance of systems with multiple dependencies\\nRelational and NoSQL database design and best practices\\nPrevious experience in data ingestion and translation tools\\nExperience managing customer data for Security and Privacy\\nData modeling and API design\\nDeep understanding of and experience in cross-team collaboration in large-scale projects\\n\\nAbout Teams\\n\\nJira Align Data Team Owns multiple production services that transform the team level data into enterprise decision making tools.\\n\\nCompensation\\nAt Atlassian, we tie our base pay ranges to role and level. In the United States, that means your base pay ranges will fall into one of three geographic pay zones depending on your location. Our current base pay ranges for new hires in each zone are:\\n(Zone A: $187,500 - $287,500)\\n(Zone B: $168,700 - $258,800)\\n(Zone C: $155,600 - $238,700)\\nWithin each range, base pay is ultimately determined based on your skills, expertise, and experience. This role may also be eligible for benefits, bonuses, commissions, and/or equity.\\nPlease visit go.atlassian.com/payzones for more information on which locations are included in each of our geographic pay zones. However, please confirm the zone for your specific location with your recruiter.\\nOur perks & benefits\\nAtlassian offers a variety of perks and benefits to support you, your family and to help you engage with your local community. Our offerings include health coverage, paid volunteer days, wellness resources, and so much more. Visit go.atlassian.com/perksandbenefits to learn more.\\nAbout Atlassian\\nAt Atlassian, we're motivated by a common goal: to unleash the potential of every team. Our software products help teams all over the planet and our solutions are designed for all types of work. Team collaboration through our tools makes what may be impossible alone, possible together.\\nWe believe that the unique contributions of all Atlassians create our success. To ensure that our products and culture continue to incorporate everyone's perspectives and experience, we never discriminate based on race, religion, national origin, gender identity or expression, sexual orientation, age, or marital, veteran, or disability status. All your information will be kept confidential according to EEO guidelines.\\nTo provide you the best experience, we can support with accommodations or adjustments at any stage of the recruitment process. Simply inform our Recruitment team during your conversation with them.\\nTo learn more about our culture and hiring process, visit go.atlassian.com/crh.\"}, {'job_title': 'Data Engineer - People Insights', 'job_url': 'https://search.linkup.com/details/06c35a8de2906a00de55b65a48572a1d', 'location': 'Spring, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 2, 430012), 'description': \"The People Insights team at HP is looking for an experienced Data Enablement Engineer to support the build, design, and development of analytics products and platforms. Specifically this role will focus on platform enablement through data modelling, data orchestration, data pipeline, front end feature enablement, API & connection configuration, calculation development and documentation, and tools and technology implementations.\\nResponsibilities:\\n\\n\\nDesign, develop, and create reporting, analytics, and data orchestration capabilities using applications such as Microsoft Product Stack (Azure,PowerBI), Databricks, Altyryx, Amazon Redshift etc.\\n\\n\\nAdvises and makes recommendations around building or buying solutions for the following topics: Data model storage and maintenance, data processing layers, data aggregation and data management, and advanced analytics enablement.\\n\\n\\nResponsible for making recommendations on ongoing tools and technology selection for People Insights solutions development.\\n\\n\\nResponsible for establishing connectivity and enablement between back-end databases and front- end solutions for example ODBC, WebConnector (RaaS), or API development.\\n\\n\\nDevelop, manage, and maintain centralized dimensional data model for core workforce data at HP.\\n\\n\\nResponsible for connecting and operationalizing disparate people data models from across the organization.\\n\\n\\nResponsible for testing and solutioning embedded analytics from sources not integrated into core dimensional modelling.\\n\\n\\nPresenting written recommendations, requirements, and insights through the addition of technology platforms and net new data sources. \\n\\n\\nBuild, maintain, and document centralized calculation library (Calculation Language: DAX).\\n\\nCreates and maintains documentation for data orchestration. \\n\\nExperience & Qualifications:\\n\\n\\n7-10 years of experience working in large complex global organization with responsibilities including data warehousing and business intelligence data, techniques, and technology.\\n\\n\\n7-10 years working with Business Intelligence (data visualization and reporting) tools and technology, specifically in the space of data orchestration (dataflows, datasets, data marts, business objects, security provisioning) and dimensional modelling.\\n\\n\\nExperience implementing solutions using full Microsoft Power Platform considered an asset.\\n\\n\\nHigh level of proficiency working with complex effective dated transactions, change data capture, and slowly changing dimensions. \\n\\n\\nHigh level of proficiency working with DAX or equivalent language to prepare complex and custom calculations and measures.\\n\\n\\nExposure to the application of Python, R, SQL for the purposes of statistical analytics, data querying and or process enhancement.\\n\\n\\nExperience supporting full cycle technology implementations in a large complex organization.\\n\\n\\nExposure to the field of People Insights/Analytics considered an asset.\\n\\nRequired post secondary education in the field of computer, information science, or statistics.\\n\\nAbout HP\\nYou're out to reimagine and reinvent what's possible—in your career as well as the world around you.\\nSo are we. We love taking on tough challenges, disrupting the status quo, and creating what's next. We're in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference.\\nHP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere.\\nOur history: HP's commitment to diversity, equity and inclusion – it's just who we are.\\nFrom the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you're more innovative and that helps grow our bottom line. Come to HP and thrive!\"}, {'job_title': 'Data Engineer - University Students', 'job_url': 'https://search.linkup.com/details/395af8e80be6ee0bc29faaae4ca7765d', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 7, 44600), 'description': \"You will join one of our offices in the North America. McKinsey Digital brings together the best of McKinsey's digital, design, engineering, and analytics capabilities to help create positive, enduring change in the world. We work with our clients -- from executive leadership to client engineers and analysts -- to use technology to solve their most challenging problems and transform their businesses. Blending strategic thinking with hands-on practicality, our teams of consultants and experts work to develop and implement everything from complex analytics strategies and enterprise IT modernization, to agility, cloud, cybersecurity, and digital transformations.\\nOur teams are made up of analysts, mathematicians, data scientists, designers, software engineers, product managers, and strategy consultants who each bring unique knowledge and skillsets to our cross-functional teams. You'll typically work on projects across all industries and functions and get the opportunity to work with colleagues and leaders across McKinsey & Company to help our clients deliver breakthrough products, experiences, and businesses using technology.\\nThis posting is for university students who are currently enrolled to matriculate from an undergraduate or advanced degree program. If you are not currently a student, please consider our experienced professional role postings instead.\\nAs a McKinsey technologist, you will be an integral part of our cross-functional client teams, bringing a unique perspective and technical expertise to each project.\\nData Engineer: You will be a hands-on technologist who connects and models complex distributed data sets to build repositories, such as data warehouses, data lakes, using appropriate technologies. You will work with our clients and other McKinsey experts, such as data scientists and architects to design and build cutting-edge (big) data solutions. You'll be a go-to expert for tackling data-related contexts ranging across addressing small to large data sets, structured/unstructured or streaming data, extraction, transformation, curation, modeling, building data pipelines, identifying right tools, writing SQL/Java/Scala code, etc.\\n\\nUndergraduate or master's degree candidate in a STEM-related field (e.g., computer science, etc.) \\nExpected graduation date between December 2023 - August 2024\\nStrong analytical and problem-solving skills paired with the ability to develop creative and efficient solutions\\nAbility to work collaboratively in a team environment and effectively with people at all levels in an organization\\nStrong command of the English language (both verbal and written)\\nWillingness to travel\\nAbility to structure and analyze data in appropriate framework (e.g., Excel, Access, VBA, SQL)\\nExposure to Big Data platforms like Hadoop, hbase, CouchDB, hive, Pig etc.\\nExperienced with data modeling, design patterns, building highly scalable and secured solutions\\nPassion for data tools and processes to drive business insights\\nAbility to quickly understand and appreciate underlying business context, problems and objectives of analytical projects\"}, {'job_title': 'Data Engineer - University Students', 'job_url': 'https://search.linkup.com/details/0844fbee1216cea5db70414b659e37aa', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 11, 348942), 'description': \"You will join one of our offices in the North America. McKinsey Digital brings together the best of McKinsey's digital, design, engineering, and analytics capabilities to help create positive, enduring change in the world. We work with our clients -- from executive leadership to client engineers and analysts -- to use technology to solve their most challenging problems and transform their businesses. Blending strategic thinking with hands-on practicality, our teams of consultants and experts work to develop and implement everything from complex analytics strategies and enterprise IT modernization, to agility, cloud, cybersecurity, and digital transformations.\\nOur teams are made up of analysts, mathematicians, data scientists, designers, software engineers, product managers, and strategy consultants who each bring unique knowledge and skillsets to our cross-functional teams. You'll typically work on projects across all industries and functions and get the opportunity to work with colleagues and leaders across McKinsey & Company to help our clients deliver breakthrough products, experiences, and businesses using technology.\\nThis posting is for university students who are currently enrolled to matriculate from an undergraduate or advanced degree program. If you are not currently a student, please consider our experienced professional role postings instead.\\nAs a McKinsey technologist, you will be an integral part of our cross-functional client teams, bringing a unique perspective and technical expertise to each project.\\nData Engineer: You will be a hands-on technologist who connects and models complex distributed data sets to build repositories, such as data warehouses, data lakes, using appropriate technologies. You will work with our clients and other McKinsey experts, such as data scientists and architects to design and build cutting-edge (big) data solutions. You'll be a go-to expert for tackling data-related contexts ranging across addressing small to large data sets, structured/unstructured or streaming data, extraction, transformation, curation, modeling, building data pipelines, identifying right tools, writing SQL/Java/Scala code, etc.\\n\\nUndergraduate or master's degree candidate in a STEM-related field (e.g., computer science, etc.) \\nExpected graduation date between December 2023 - August 2024\\nStrong analytical and problem-solving skills paired with the ability to develop creative and efficient solutions\\nAbility to work collaboratively in a team environment and effectively with people at all levels in an organization\\nStrong command of the English language (both verbal and written)\\nWillingness to travel\\nAbility to structure and analyze data in appropriate framework (e.g., Excel, Access, VBA, SQL)\\nExposure to Big Data platforms like Hadoop, hbase, CouchDB, hive, Pig etc.\\nExperienced with data modeling, design patterns, building highly scalable and secured solutions\\nPassion for data tools and processes to drive business insights\\nAbility to quickly understand and appreciate underlying business context, problems and objectives of analytical projects\"}, {'job_title': 'Vice President; Data Engineer II', 'job_url': 'https://search.linkup.com/details/f65802fd4cd3c4bd446caa276c2bba88', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 16, 56017), 'description': \"Job Description:\\nAt Bank of America, we are guided by a common purpose to help make financial lives better through the power of every connection. Responsible Growth is how we run our company and how we deliver for our clients, teammates, communities and shareholders every day.\\nOne of the keys to driving Responsible Growth is being a great place to work for our teammates around the world. We're devoted to being a diverse and inclusive workplace for everyone. We hire individuals with a broad range of backgrounds and experiences and invest heavily in our teammates and their families by offering competitive benefits to support their physical, emotional, and financial well-being.\\nBank of America believes both in the importance of working together and offering flexibility to our employees. We use a multi-faceted approach for flexibility, depending on the various roles in our organization.\\nWorking at Bank of America will give you a great career with opportunities to learn, grow and make an impact, along with the power to make a difference. Join us!\\nRESPONSIBILITIES:\\n\\n\\nDevelop and deliver data/ reporting solutions to accomplish technology and business goals.\\n\\n\\nCode solutions to integrate, clean, transform, and control data in operational and/or analytics data systems per the defined acceptance criteria.\\n\\n\\nAssemble large, complex data sets to meet functional reporting requirements.\\n\\n\\nBuild processes supporting data transformation, data structures, metadata, data quality controls, dependency, and workload management.\\n\\n\\nDefine and build reporting applications that enable better data-informed decision-making.\\n\\n\\nContribute to existing test suites (integration, regression, performance), analyze test reports, identify any test issues/errors, and triage the underlying cause.\\n\\n\\nDocument and communicate required information for deployment, maintenance, support, and business functionality.\\n\\n\\nWork closely with business partners to help translate functional requirements into technical approach, design, and decisions- Banking & Markets business acumen.\\n\\n\\nCreate MicroStrategy schema objects, complex attributes / metrics, conditional and level metrics, and their use within a report.\\n\\n\\nDevelop MicroStrategy dossiers & Tableau dashboards and 3rd party application report integration.\\n\\n\\nUse SQL, data warehouse concepts /architecture, dimensional modeling, and ETL solution design.\\n\\nTune and optimize query performance for large datasets-cubes, caching, aggregate structures within MicroStrategy, Tableau and various RDBMS, Hadoop backend systems.\\n\\nREQUIREMENTS:\\n\\n\\nBachelor's degree or equivalent in Computer Science, Computer Information Systems, Management Information Systems, Engineering (any) or related; and\\n\\n\\n5 years of progressively responsible experience in the Job offered or a related IT occupation.\\n\\n\\nWorking closely with business partners to help translate functional requirements into technical approach, design, and decisions- Banking & Markets business acumen;\\n\\n\\nCreating MicroStrategy schema objects, complex attributes / metrics, conditional and level metrics, and their use within a report;\\n\\n\\nDeveloping MicroStrategy dossiers & Tableau dashboards and 3rd party application report integration;\\n\\n\\nUsing SQL, data warehouse concepts /architecture, dimensional modeling, and ETL solution design; and,\\n\\nTuning and optimizing query performance for large datasets-cubes, caching, aggregate structures within MicroStrategy, Tableau and various RDBMS, Hadoop backend systems.\\n\\nIf interested apply online at www.bankofamerica.com/careersor email your resume to bofajobs@bofa.comand reference the job title of the role and requisition number.\\nEMPLOYER: Bank of America N.A.\\nShift:\\n1st shift (United States of America)\\nHours Per Week: \\n40\"}, {'job_title': 'Principal 5G RAN Data Engineer', 'job_url': 'https://search.linkup.com/details/a90cd65b910ea281b261ff4d61d5b1c4', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 20, 95044), 'description': \"Job Overview \\nJoin AT&T and reimagine the communications and technologies that connect the world. We're committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won't just imagine the future – you'll create it.\\nAs a Principal Member of Technical Staff , you'll provide solutions to complex business and technical problems or issues of complex scope using advanced engineering and technical principles.\\nKey Responsibilities:\\n\\nUnderstanding of network data, data collection, data collection system, network elements and network systems in a large and diverse carrier network including fiber, wireless RAN and wireless core networks\\nAbility to assess and evaluate the technology that facilitates the NM&A platform to capture, move, store, use, and manage network data in support of network automation, operational support, data insights, and AI use to deliver a geographically distributed and scalable platform.\\nPlan, development, and socialize a roadmap to support the introduction and rollout of the NM&A in AT&T's network in a managed fashion to provide real tangible benefits to AT&T as quickly as possible\\nProviding a comparative assessment, benefits, and recommendation for keeping the data management capabilities either separate from or integrated with the RAN NM&A Platform, both in the short term (1-2 years out) and the long term (3+ years out)\\nRecommend options and selection criteria to consolidate the many data management solutions currently in use within AT&T's network, considering the benefits, costs, and organizational difficulty with different levels of integrations, and drive the consolidation effort.\\nAs part of the above, evaluate the benefits and costs of using vendor based solutions versus open source solutions, provide recommendations and architectural support for implementation\\nApply principles and practice in broad areas of complex technical project work that requires in-depth analysis using advanced techniques, knowledge, and expertise.\\nParticipate in data management standards, coordinate architecture, & communicate out to internal team, vendors, and standards bodies such as O-RAN and ONAP\\nCommunicate and provide documentation for issues identified to both vendor and internal teams\\\\\\nRepresent the group internally across the company to provide functional and technical leadership and externally to submit vendor feature requests\\n\\nRequired Education:\\n\\nBachelor's degree or higher degree in Engineering, Computer Science, Informational Technology, Data Communications from an accredited university.\\nPhD in an approved field with 5 years of experience or Masters in an approved field with a minimum of 6 years of relevant experience or a Bachelors in an approved field with a minimum of 8 years of relevant experience. \\n\\nRequired Experience:\\n\\nExtensive familiarity with network data management capabilities and systems such as Kafka (vendor and open source products), ETL tools, Snowflake, and Databricks.\\nExpert experience in network data, data collection, data collection system, network elements and network systems.\\nExpert level oral and written communication with internal stakeholder and external vendors\\nProficiency in standard Microsoft Office products is expected, while mastery of advanced techniques and Office features is highly beneficial.\\n\\nOur Principal Member Technical Staff earn between $144,00-$289,000. Not to mention all the other amazing rewards that working at AT&T offers. Individual starting salary within this range may depend on geography, experience, expertise, and education/training.\\nJoining our team comes with amazing perks and benefits:\\n\\nMedical/Dental/Vision coverage\\n401(k) plan\\nTuition reimbursement program\\nPaid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays) \\nPaid Parental Leave\\nPaid Caregiver Leave\\nAdditional sick leave beyond what state and local law require may be available but is unprotected\\nAdoption Reimbursement \\nDisability Benefits (short term and long term)\\nLife and Accidental Death Insurance \\nSupplemental benefit programs: critical illness/accident hospital indemnity/group legal \\nEmployee Assistance Programs (EAP)\\nExtensive employee wellness programs \\nEmployee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone\\nLong Term Grants and Deferred Compensation\\n\\nA career with us, a global leader in communications and technology, comes with big rewards. As part of our team, you'll lead transformation surrounded by trailblazing industry leaders like you. You'll be empowered to go above and beyond – making a difference through company-sponsored initiatives or connecting and networking through one of our many employee groups. And regardless of where you're at in your career trajectory, you'll be rewarded by the impact that comes with making a difference in the lives of millions. With AT&T, you'll be a part of something greater, do incredible things and be rewarded with a chance to change the world.\\nReady to join us? Apply today!\\nJob ID 2319012 Date posted 07/12/2023 Apply Now\"}, {'job_title': 'Big Data Engineer with Active VOS', 'job_url': 'https://search.linkup.com/details/28fe132e5486811ccd0f7f7994878252', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 25, 785168), 'description': ''}, {'job_title': 'Manager, Data Engineer & ETL Processing', 'job_url': 'https://search.linkup.com/details/3d1712d0ac343b81cf4eff28858f7233', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 30, 570427), 'description': 'Company Description\\nAbout Spark Foundry:\\nSpark Foundry is a global media agency that exists to bring HEAT – Higher Engagement, Affinity, and Transactions – to brands. By combining flawless media fundamentals with aggressive innovation, Spark inspires consumers to pay more attention, to care more about our clients\\' brands, and to buy more products and services from them.\\nBalancing the nimble spirit of a startup with the powerhouse soul of Publicis Media, Spark Foundry delivers the best of both worlds to a client roster that spans some of the world\\'s best and most beloved brands and companies. We combine boutique-caliber insights and service with the buying clout and first-look access of a global leader, bringing the heat to challenger brands that want to act like giants, and to giant brands that want to act like challengers.\\nWith a bottom-up culture that celebrates diversity and aims for all voices to be heard, Spark has become a magnet for the industry\\'s best talent, with one of the best retention rates in the industry. And by applying a whole-person approach to professional and personal development, Spark develops a workforce that is well prepared for today\\'s challenges, and also poised to create meaningful careers in the years to come.\\nBecause we know that heat arises the intersection of complementary forces, our professionals come from myriad disciplines and backgrounds: data, analytics, and insights, content and creative production, communications and strategy, finance and marketing, and sociology, psychology, and other liberal arts disciplines.\\nJob Description\\nOverview: \\nThe Manager, Data Engineering & ETL Development is a key driver to build data platform leveraging best in class ETL practice and is also a strategic thinker and a talented data visualization expert with emphasis on dashboard reporting. The primary responsibility will be developing business intelligence platform to support media and marketing data for our clients. This position will allow you to be a significant contributor as part of the team to support easy access of data and visualizations to fuel stronger insights and media optimizations.\\nThis position requires strong technical and tactical skill sets with an eye for numbers, intellectual curiosity, proficiency at problem solving, and a critical understanding of online media. The candidate must have a proven track record in managing ETL\\'s, APIs and business intelligence platforms. Candidate should be a team player. A \"roll up the sleeves\" approach is mandatory and a \"get it done\" attitude is a must. Specific responsibilities include coordination between the research, analytics & media teams ensuring high quality data projects are effectively delivered.\\nSuccessful candidates will be multi-dimensional \\'rising-stars\\' who are able to employ complex problem solving skills, and are able to communicate these succinctly to a broad client and media stakeholder audience.\\nRole Objectives:\\n\\nResponsible for loading and validating data into the data warehouse from various source systems\\nAnalyze, develop, fix, test, review and deploy functionality, and bug fixes in ETL data pipelines\\nQuery tuning, diagnosis, and resolution of performance issues leveraging ELT and push-down if required\\nBuilding Data mappings between Source to Target systems\\nProvides support for technical issues and ensuring system availability\\nWork with business customers to identify and develop additional data and reporting needs\\nUnderstand how business intelligence platform/data technologies work and offer the ability to explain technical concepts in ordinary terms (be technically savvy - understand the opportunities and limitations)\\nEstablish and manage data integrations utilizing a taxonomy nomenclature to make recommendations for data visualization to showcase media performance through the use of Datorama or Tableau\\nPerform regular quality assurance/quality control checks on assigned client campaigns to ensure the data is processing accurately\\nDesign and build backend data streams and processes to automate reporting capability with data visualization tools\\nContribute to client status and reporting calls, including presentation of reporting as required\\nDevelop subject matter expertise in ETL, API development, and Business Intelligence platforms\\nClearly define project deliverables, timelines, and dependencies for junior team members, internal stakeholders and clients\\nCollaborate on an inclusive team, where members openly communicate and collectively problem-solve \\nStrong ability to evaluate new technologies and present findings to team\\nContribute to knowledge sharing efforts and mentorships\\nComplete other duties as assigned.\\n\\nQualifications\\n\\nBachelor\\'s degree or combination of education, and equivalent work experience is preferred in the field of computer science, management information systems or Information Technology\\n3+ years\\' related experience ETL development and business intelligence platform management\\nUnderstanding of BI/ETL development in the IT industry with recent development, system administration, application tuning and debugging experience.\\n3+ plus years\\' development experience with database engines including Presto, Mongo db and Hadoop.\\n3+ years\\' experience in ETL development, Strong Database (Modeling, SQL), SQL Server, Hadoop, AWS Redshift, Qubole.\\nExperience managing team of 2 or more associates/analysts preferred\\nStrong database modeling and SQL skills. Ability to write complex SQL statement, Procedures and data automation programs\\nKnowledge of ETL tools like Airflow, AWS Glue, Alteryx, SSIS, Qubole/Spark is a must\\nKnowledge of Python or similar programming languages required\\nProficiency with Datorama, Tableau, or other data visualization tools is preferred\\nExperience working with AWS or other cloud technologies\\nAdvanced user Microsoft Office Suite and reporting tools\\nDemonstrated expertise in core MS Excel functions (vlookup, pivot tables, data visualization)\\nExperience in designing jobs that can be easily promoted from one (Dev) environment to another (Test or Prod) seamlessly, without modification.\\nStrong analytical and problem-solving skills\\nStrong verbal/written communication and interpersonal skills is required\\nSelf-starter with ability to thrive in a fast-paced environment and able to function independently while providing status updates to a team of analysts\\nCooperative, flexible, conscientious, dependable, resourceful, self-motivated, and team-oriented\\nProblem solving, time management, and critical thinking skills with a professional and positive attitude\\nAbility to work independently and as part of an agile team, participating in daily stand-ups, sprint planning and sprint review\\n\\nCharacter: \\nThe following qualities help drive success as member of the Spark Data and Analytics team:\\n\\nEntrepreneurial, engaging, resourceful, curious, and self-directed spirit\\nWilling and easily roll sleeves up or down; love the nitty-gritty and the strategy\\nCollaborative approach to building cohesive, strong teams\\nLoving and living the intersections between brands, people, media, communications\\nRelentlessly passionate and resolute\\nPlanning and time management excellence.\\nEmbrace challenges\\nProactive, especially in pushing for new opportunities, approaches, and ideas.\\nKeenly focused on action and solutions; thrives with deep critical thinking and analysis.\\nPioneering insight attitude and research in-the-know.\\nResourcefulness, flexibility and adaptability, strong ability to pivot when the need arises.\\nInspired to be part of the insight journey/revolution with a growing, dedicated team\\n\\nAdditional Information\\nAll your information will be kept confidential according to EEO guidelines.\\n23-2795'}, {'job_title': 'Engineer - Research Engineer - controls & Data Acquisition', 'job_url': 'https://search.linkup.com/details/39b800fa55d4867f5df2c35425a4858f', 'location': 'San Antonio, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 35, 613340), 'description': \"Who We Are: \\nThe Propulsion & Energy Machinery Section performs engineering R&D in the fields of industrial heat and power, liquid propulsion, gas turbine combustion, and air-breathing propulsion. Our technologies are powering a cleaner future and advancing state-of-the-art propulsion for air and space flight.\\nObjectives of this Role: \\n\\nAssist engineers in developing and operating custom data acquisition and control systems used for a variety tests.\\nTypical application areas include: supercritical CO2 oxy-fuel combustion systems, gas turbine combustion systems, launch vehicle components.\\nCreate custom graphical user interfaces using NI LabView to control, display, and manipulate test parameters and measured data.\\nIdentify and design instrumentation schemes in support of defined test goals. Procure, calibrate, install, and commission instruments and other hardware for experiments of various scales.\\nSupport test campaigns by trouble-shooting data acquisition and control system hardware/software issues.\\nAnalyze collected data in excel, MATLAB, or equivalent post processing tools and report data to project teams and clients.\\n\\nDaily and Monthly Responsibilities: \\n\\nDesign, procure, and assemble data acquisition systems including instrumentation, DAQ modules, hardware, and wiring.\\nUse NI Labview to develop acquisition and control modules and graphical user interfaces to assist a range of test campaigns.\\nProgram various functions and sub-VIs to monitor flow, temperature, vibration, pressure, density, etc. using various instruments.\\nUnderstand various electrical instruments including pressure transducers, eddy current probes, thermocouples, and associated DATA acquisition systems.\\n\\nRequirements: \\n\\nRequires a Bachelors, Masters or a PhD in Mechanical Engineering, Aerospace Engineering, or related engineering degree\\n1-2 years: BS with experience in Data Acquisition, LabVIEW, PLC's, Instrumentation and sensors\\n0-2 years: Master's or PhD with academic experience in Data Acquisition, LabVIEW, PLC's, Instrumentation and sensors\\nA valid/clear driver's license is required\\n\\nSpecial Requirements: \\nMust be a U.S. person (i.e., U.S. citizen, non-U.S. citizen national, lawful permanent resident, asylee, or refugee) due to ITAR work in section.\\nJob Locations: San Antonio, Texas\\nFor more information about this division, visit the Mechanical Engineering home page.\\nFor benefits information at our San Antonio location, click here.\\nFor benefits information at all other locations, click here. \\nAn Equal Employment Opportunity/Affirmative Action Employer\\nRace/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disabled/Veteran\\nCommitted to Diversity in the Workplace\"}, {'job_title': 'Data Scientist', 'job_url': 'https://search.linkup.com/details/b09ad8d15180c44bac902ab0f1cc8a4d', 'location': 'TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 40, 18184), 'description': 'SAIC seeks an experienced, results-oriented, mission-driven Data Scientist who possesses knowledge of appropriate data sources to address the specific requirements of projects for data modeling. Understand business requirements and translating into technical work. Design and implement features in collaboration with team engineers, product owners, data analysts, and business partners using Agile / Scrum methodology. \\nThis is a 100% Remote role. \\nResponsibilities:\\n\\nAbility to build and develop tools that process information\\nBuild ETL jobs and workflows to combine data from disparate sources. \\nInstall continuous pipelines of huge pools of filtered information so that data analyst/scientists can pull relevant data sets for their analyses. \\nExperience with SQL scripts and SSIS. SSIS, SSMS\\nCollaborate with business stakeholders, business operations, and product engineering teams in \\nAnalyzing business problems, in building and testing solutions and data models \\nExperience implementing and operating analytic models and services. \\nDocument the current-state and target-state software architecture and create roadmap plans for success on various software components.\\nAssist in the design, implementation, and maintenance of complex solutions.\\nBuild systems that collect, manage, and convert raw data into usable information for business analysts to interpret. \\nMake data accessible for evaluation and optimization \\nCollaborate with business stakeholders, business operations, and product engineering teams\\nCoordinate activities with other technical personnel as appropriate.\\n\\nRequired Skills and Experience\\n\\n· Must have a Masters degree and 5 years of experience. May consider an additional 8 years of experience in lieu of a degree. \\n· Bachelors in and in computer science, systems engineering, or related technical discipline is preferred.\\n· 5 years of experience as a Data Engineer/Administrator or similar role. 10 years of experience is preferred. \\n· Works the back end data and organizes it into table using SQL scripts and SSIS. SSIS, SSMS\\n· Ability to work independently with minimal direction providing technical and non-technical support to multiple users\\n· Capable of working under pressure, while handling multiple tasks simultaneously\\n· Ability to work overtime and weekends required on occasion\\n· Experience providing services to the federal government is preferred\\nMust have AWS or Azure experience\\n\\nPreferred\\n\\n· ITIL V3 Certified is a plus \\n· Ability to work independently with minimal direction providing technical and non-technical support to multiple users\\n· Capable of working under pressure, while handling multiple tasks simultaneously\\n· Ability to work overtime and weekends required on occasion\\n· Experience providing services to the federal government is preferred'}, {'job_title': 'Mechanical Engineer - HVAC Data Center Design', 'job_url': 'https://search.linkup.com/details/6693f06c2f8ea5f01454a7abc1eb62c0', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 47, 393173), 'description': 'Mechanical Engineer - HVAC Data Center Design\\n1.Who are we? \\nEquinix is the world\\'s digital infrastructure company, operating 200+ data centers across the globe and providing interconnections to all the key clouds and networks. Businesses need one place to simplify and bring together fragmented, complex infrastructure that spans private and public cloud environments. Our global platform allows customers to place infrastructure wherever they need it and connect it to everything they need to succeed.\\nWe are a fast-growing global company with 70+ consecutive quarters of growth. Through our innovative portfolio of high-performance products and services, we have created the largest, most active global ecosystem of nearly 10,000 companies, including 1,800+ networks and 2,900+ cloud and IT service providers in over 26 countries spanning five continents. \\nJoining our operations team means that you will be at the forefront of all we do, maintaining critical facilities infrastructure as part of a close-knit team delivering best in class service to our data center customers. We embrace diversity in thought and contribution and are committed to providing an equitable work environment. that is foundational to our core values as a company and is vital to our success\\nJob Summary\\nPerforms the planning, system design, system implementation, system maintenance and support for Equinix Data Centers. Lead small to medium-scale projects and the rollout of engineering initiatives. Assists with the development and implementation of engineering design standards, policies and procedures. Effectively interacts with other internal and external teams, including the design engineering, site engineering, construction management and regional operations teams, onsite support vendors and consultants on projects, policies and procedures. Plans and directs day to day operations and strategic direction of delivery of either a Construction project or delivery of operations for an IBX facility.\\nWhat you will be doing?\\nProject Management\\n\\n\\nLeads and manages a project or other design and engineering initiatives\\n\\nProvides guidance and project leadership in ensuring project or other design and engineering initiatives are meeting or exceeding company expectations\\n\\nSystem Operation and Work Practices (incl Capacity Planning)\\n\\n\\nExpert operating knowledge of engineering systems to include advanced diagnostics and repairs\\n\\n\\nAbility to apply knowledge of Equinix processes and procedures and industry standards to resolve non-routine issues\\n\\n\\nUtilizes safe working practices at an expert level (e.g. can apply procedure for lockout/tag out, can explain MSDS, etc.)\\n\\n\\nEvaluates and assures the safe working practices of others\\n\\n\\nInteracts with other engineering, design and construction disciplines\\n\\nWorks with the capacity and site engineering teams to resolve power and/or cooling limitations and optimize resource utilization\\n\\nLeadership and Communications (incl Vendor Mgmt)\\n\\n\\nContributes to mentoring junior team members\\n\\n\\nDirects all internal and external project team members\\n\\n\\nDirects external vendors per project or initiative such as general contractors, A&E design teams, commissioning agents, equipment suppliers, etc.\\n\\n\\nExpert level communication to include cross-functional SOP development and relevant technical writing\\n\\n\\nInteractions are primarily to exchange information between departments within the organization\\n\\nIncludes executive level communications in standardized templates\\n\\nPolicy & Procedure Development and Adherence\\n\\n\\nContributes to creating and maintaining best in class policies and procedures\\n\\n\\nParticipates in review of policy and procedure documents\\n\\n\\nDevelops policy documents with the input of others\\n\\nAssures adherence to developed standards and policy through review of documentation, participation in commissioning activities, design summits and IBX physicals\\n\\nProblem Solving\\n\\n\\nConsistently solves complex, cross-functional issues requiring independent action and a high degree of initiative to resolve\\n\\n\\nMakes recommendations for system level enhancements to eliminate potential problems\\n\\nTests suitability of components or action plans for deployments.\\n\\nWhat you should have\\n\\n\\nKnowledge of Data Center Mechanical Design\\n\\n\\nEfficiency and data modeling\\n\\n\\nStrong MS Excel skills for data modeling\\n\\n\\nExperience developing and managing projects with internal and external stakeholders\\n\\n\\nBachelors degree in Mechanical Engineering or equivalent experience\\n\\n\\nBi-lingual Spanish/English\\n\\n7+ Years of related experience in a critical facility or data center environment\\n\\n\"Equinix is an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard of race, color, religion, creed, national or ethnic origin, ancestry, place of birth, citizenship, sex, pregnancy / childbirth or related medical conditions, sexual orientation, gender identity or expression, marital or domestic partnership status, age, veteran or military status, physical or mental disability, medical condition, genetic information, political / organizational affiliation, status as a victim or family member of a victim of crime or abuse, or any other status protected by applicable law.\"'}, {'job_title': '2024 Summer Intern: Technology – Data & Analytics, Data Engineer & Data Science - Undergrad or Master', 'job_url': 'https://search.linkup.com/details/0676baa176ed587a59d093070aec2ded', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 52, 403710), 'description': \"Overview\\nPepsiCo products are enjoyed by consumers more than one billion times a day in more than 200 countries and territories around the world. PepsiCo generated more than $86 billion in net revenue in 2022, driven by a complimentary beverage and convenient foods portfolio that includes Lay's, Doritos, Cheetos, Gatorade, Pepsi-Cola, Mountain Dew, Quaker, and SodaStream. PepsiCo's product portfolio includes a wide range of enjoyable foods and beverages, including many iconic brands that generate more than $1 billion each in estimated annual retail sales. \\nGuiding PepsiCo is our vision to Be the Global Leader in Beverages and Convenient Foods by Winning with PepsiCo Positive (pep+). pep+ is our strategic end-to-end transformation that puts sustainability at the center of how we will create value and growth by operating within planetary boundaries and inspiring positive change for planet and people. For more information, visit www.pepsico.com. \\nFunctional Description: \\nAt PepsiCo, we're redefining what it means to be a consumer products company with a digital-first mindset. PepsiCo is using the power of data to transform the way our world famous portfolio of brands are sold every day. \\nOur Data + Analytics group influences every aspect of how we sell and move our products. In just a short period of time, they've built new capabilities that have defined the data science roadmap across all of our brands. Members of our team solve complex problems facing our rapidly changing business and get to see their work come to life in the real world. \\nPepsiCo's Information Technology focuses on delivering and supporting capabilities that improve business processes, enable associates to connect and collaborate more easily, collect and mine data for analytical insights, and enhance performance across all aspects of PepsiCo's value chain. \\nResponsibilities\\nWhat you can expect: \\nStudents are afforded opportunities for beneficial, meaningful work experience within one of PepsiCo's Technology groups - Data + Analytics or Global IT. \\nThe Data & Analytics, Data Engineer & Data Science role profile consists of - \\nData & Analytics: Develops reporting & analytical solutions to turn data into business insights. Includes the management of reusable & consistent data foundations. \\nData Engineers: designs and codes specific cross-sub-system of key algorithmic structures. They manage and evaluate solutions for large scale data processing systems, data warehousing services and solutions using advanced database technologies \\nData Scientists: are responsible for designing and building predictive models to measure data difficulty and ambiguity level and error probability. They build data models and organize structured and unstructured data to interpret solutions \\nTechnical Skills:\\n\\nArtificial neural networks \\nAzure \\nBig Data \\nChatbots \\nData architectures \\nHadoop \\nMATLAB \\nPowerBI \\nPython \\nR \\nSpark \\nSQL \\nTableau \\n\\nTake note: While final work placement will be in one of the following two locations, no specific location is guaranteed pre-offer. Actual working location will be determined and identified at the point of offer. \\n\\nPlano, TX \\nPurchase, NY \\n\\nQualifications\\nWhat we're looking for: \\n\\nCurrently pursuing a degree in: Business Administration, Business Information Systems, Computer Science, Computer Engineering, Engineering, Finance, Information Systems, MIS or Software Engineering (other related majors may be considered) \\nMinimum GPA 3.0 \\nTechnology related experience a plus \\nAbility to learn new technologies and processes information quickly \\nAbility to adapt to changes in timelines and sequences \\nExcellent verbal and written communication skills \\nAbility to participate in ten or twelve-week internship program May - August \\n\\nMinimum Qualifications - Each candidate is expected to: \\n\\nGraduate with Bachelor's or Master's degree within one (1) year of internship completion \\nThis position is limited to persons with indefinite right to work in the United States. \\n\\nEEO Statement\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.\\nPepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity.\\nIf you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.\\nPlease view our Pay Transparency Statement\"}, {'job_title': 'Senior Data Scientist - Data Ventures', 'job_url': 'https://search.linkup.com/details/07c274be6f187eb8bcbe8f886ebc3c4a', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 54, 57, 281977), 'description': \"Position Summary...\\nWhat you'll do...\\nWhat you'll do...\\nPosition Summary...\\nData Ventures, akin to a nimble startup incubated within Walmart is building the best-in-class suite of Data Products to deliver actionable, customer-centric insights and help merchants and suppliers make better business decisions\\u202fon omni channel 360 performance. \\nAs a Senior Data Scientist, you will play a pivotal role in science projects/products and take ownership of project delivery and responsibilities and be the technical SPOC for your team. You will work closely with product stakeholders and deliver outstanding business outcomes. Provide leadership with constant updates and align with directions and expectation. \\nMust have: Machine Learning, Data Science, SQL, NoSQL, Python, R, CI/CD, MLOps, Big Data, Cloud, Machine Learning\\nWhat You'll Do:\\n\\nWork in customer data science space building models for customer segmentation, customer LTV, etc.\\nWork with marketing team to build algorithms that would help in better customer targeting.\\nAnalyzes the business problem and recommends approach to resolve the business problem.\\nSelects appropriate modeling techniques for complex problems with large scale, multiple structured and unstructured data sets.\\nSelects and develops variables and features iteratively based on model responses in collaboration with the business.\\nConducts exploratory data analysis activities (for example, basic statistical analysis, hypothesis testing, statistical inferences) on available data.\\nWork on ad-hoc data science projects\\nMentor junior data scientist in the team and act as a tech SPOC from your area\\nWhat You'll Bring:\\nPassion for problem-solving, come with Analytical mindset with critical-thinking, and data skills.\\nExpertise in Machine Learning and Data Science\\nStrong technical skills in SQL, Python, R, or other programming languages commonly used in data analysis.\\nDeep expertise in Customer Data Science viz. customer segmentation, churn analysis, repeat purchase, market basket, A/B testing, etc.\\nAwareness of software engineering principles, ability to develop and deploy appropriate analytic code suitable for production.\\nWorking knowledge of CI/CD and MLOps\\nExperience working with large datasets, finding insights, and telling stories using data. \\nGood knowledge in working with distributed datastores (e.g., SQL, NoSQL), and Big Data and Cloud technologies like GCP BQ.\\nExperience in leading and mentoring a team of data scientists.\\nUnderstanding of advance ML topics viz. Deep learning (ENN, CNN, RNN, etc.), GAN, Transformers, NLP, LLM's is a plus.\\nExcellent communication skills and ability to effectively communicate technical concepts to non-technical stakeholders.\\nPrior experience working in the retail data sets is strongly preferred.\\n\\nAbout Walmart Global Tech\\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\\nFlexible, hybrid work:\\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\\nBenefits:\\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\\nEqual Opportunity Employer:\\nWalmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.\\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\\nMinimum Qualifications...\\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. \\nOption 1- Bachelor's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years' experience in an analytics related field. Option 2- Master's degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years' experience in an analytics related field. Option 3 - 5 years' experience in an analytics or related field.\\nPreferred Qualifications...\\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. \\nData science, machine learning, optimization models, Master's degree in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\\nPrimary Location...\\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\\nAbout Walmart\\nAt Walmart, we help people save money so they can live better. This mission serves as the foundation for every decision we make, from responsible sourcing to sustainability—and everything in between. As a Walmart associate, you will play an integral role in shaping the future of retail, tech, merchandising, finance and hundreds of other industries—all while affecting the lives of millions of customers all over the world. Here, your work makes an impact every day. What are you waiting for?\\nWalmart, Inc. is an Equal Opportunity Employer- By Choice. We believe we are best equipped to help our associates, customers, and the communities we serve live better when we really know them. That means understanding, respecting, and valuing diversity- unique styles, experiences, identities, abilities, ideas and opinions- while being inclusive of all people.\\nAll the benefits you need for you and your family\\n\\nMultiple health plan options, including vision & dental plans for you & dependents\\nFinancial benefits including 401(k), stock purchase plans, life insurance and more\\nAssociate discounts in-store and online\\nEducation assistance for Associate and dependents\\nParental Leave\\nPay during military service\\nPaid Time off - to include vacation, sick, parental\\nShort-term and long-term disability for when you can't work because of injury, illness, or childbirth\\n\\nEligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to specific plan or program terms. For information about benefits and eligibility, see One.Walmart.com/Benefits.\\nFrequently asked questions\\n\\nOn average, how long does it take to fill out an application?\\n\\nOn average, it takes 45-60 minutes to complete your application for the first time. Subsequent applications will take less time to apply as our system saves some of your application information. Please note that some positions require the completion of assessments in order to receive consideration for that role. Those would take additional time.\\n\\nCan I change my application after submitting?\\n\\nNo, you cannot change your application after submitting, so please make sure that everything is finalized before you hit the submit button.\\n\\nHow do you protect my personal information?\\n\\nProcessing of information on paper is minimal, and Walmart processes application information using an applicant tracking system (ATS). Access to the data within the ATS is restricted to authorized personnel, and the system itself is held to high security standards by Walmart.\\n\\nWhat are the recommended Internet Browsers for applying for open roles?\\nInternet Explorer 8.0+\\nFirefox 4.0+\\nSafari 4.0+\\nChrome 12+\\n\\nSee All FAQs\\nRecently viewed jobs\"}, {'job_title': 'lead Engineer - lead Analyst - Principal Engineer - systems Engineer - Data Science/analytics/Engineer', 'job_url': 'https://search.linkup.com/details/f8073bcd7f025ec7bac10cdb1f216384', 'location': 'San Antonio, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 2, 78818), 'description': \"Who We Are: \\nJoin Our Team! The Tactical Aerospace Department is a premier supplier for aerospace quality technology insertion on new and legacy DoD systems. This includes avionics, ground systems, and cutting edge third generation AI/ML.\\nObjectives of this Role: \\n\\nResponsible to develop System Architectures for Data Science/Analytics to help design data pipelines that utilizes second/third generation AI/ML.\\nWill also develop Avionics System Architectures and lead Systems engineering tasks for complex avionics/aerospace systems.\\nWork collaboratively across a multi-disciplinary engineering teams to establish hardware, firmware, and AI/ML requirements for complex flight worthy avionics hardware.\\nInteract directly with clients and company staff to establish system requirements and architectures to meet client expectations.\\nProvide technical project leadership for the Tactical Aerospace Department.\\nUtilize Model Based Systems Engineering (MBSE) processes to support system designs/architectures.\\nSupport department management in specific marketing activities, proposal development of embedded avionics programs, and in the development of product/technical roadmaps.\\n\\nDaily and Monthly Responsibilities: \\n\\nPerform as a System Engineer over embedded avionics programs.\\nLead a multi-disciplinary team to develop, integrate, and test complex avionics. This includes electrical, mechanical, firmware, data pipelines, data science, and AI/ML.\\nLead the team using schedules and earned value.\\nMeet with internal and external customers to establish system technical requirements and facilitate development of specification documents and system architectures.\\nLead trade analyses within and across the relevant domains.\\nWork with stakeholders to allocate functions to components/systems and develop those allocations into requirements for the engineers, designers, and managers to design, develop, integrate and test\\n\\nRequirements: \\n\\nRequires a Bachelors in Electrical Engineering, Data Engineering, Data Science, Data Analytics or equivalent.\\nShift work required.\\n8+ years: Bachelor's of Science degree from an accredited college in a related discipline with 8+ years of experience.\\nBroad, basic understanding of engineering activities/disciplines in avionics development (e.g. Systems, Hardware Development, Software, Firmware, Integration, Testing, Bid and Proposal efforts, CONOPS, Certification, System Safety, FMEA, Lab activities, etc).\\nExperience developing Architectures and basic/Intermediate experience using Enterprise Modeling Tools to model complex systems using SysML.\\nPrefer some experience implementing cyber requirements, implementing RTOS's, and developing technical roadmaps.\\nExperience developing, deriving, and allocating tiered Systems Engineering requirements in Avionics applications including data pipelines and tiered Data Science applications.\\nA valid/clear driver's license is required.\\n\\nSpecial Requirements: \\nApplicant selected will be subject to a government security investigation and must meet eligibility requirements for access to classified information. Applicant must be a U.S. citizen.\\nJob Locations: San Antonio, Texas\\nFor more information about this division, visit the Defense & Intelligence Solutions home page.\\nFor benefits information at our San Antonio location, click here.\\nFor benefits information at all other locations, click here. \\nAn Equal Employment Opportunity/Affirmative Action Employer\\nRace/Color/Religion/Sex/Sexual Orientation/Gender Identity/National Origin/Disabled/Veteran\\nCommitted to Diversity in the Workplace\"}, {'job_title': 'Vice President, Data Management (Chief Data Officer)', 'job_url': 'https://search.linkup.com/details/825bd31f92d52eac53c953f91bb3ed2e', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 7, 867881), 'description': \"Position Overview\\nThe Chief Data Officer (CDO) specializing in Artificial Intelligence (AI) and Machine Learning (ML), will be responsible for driving data-driven decision-making and optimizing business processes within the Wholesale & retail industry. Your primary focus will be on leveraging AI and ML technologies to extract insights, develop predictive models, and enhance customer experience. You will lead a team of data scientists and analysts, collaborate with cross-functional departments, and establish data governance and privacy frameworks. The role requires strong leadership, technical expertise, and a deep understanding of wholesale and retail operations and customer behavior.\\nJob Description\\n\\n\\nDevelop Data Strategy: Define and implement a comprehensive data strategy aligned with the organizations goals and objectives; Identify opportunities for AI/ML adoption to improve operational efficiency, enhance customer experience, and drive revenue growth; Create a roadmap for data collection, integration, storage, analysis, and visualization; Lead AI/ML initiatives through oversight of the development and deployment of AI/ML models to extract meaningful insights and drive actionable recommendations; Collaborate with cross-functional teams to identify and prioritize business challenges that can be addressed using AI/ML techniques; Stay current with the latest advancements in AI/ML technologies and ensure their incorporation into the organization's strategy; Build and Manage data engineering teams, with focus on data engineering, data warehouse and reporting, and data science and software engineering; Recruit, mentor, and lead a team of data scientists, analysts, and engineers; Define roles, responsibilities, and objectives for the team members; foster a culture of innovation, collaboration, and continuous learning; Data Governance and Privacy through establishing and enforcing data governance policies and procedures to ensure data integrity, quality, and privacy; Implement robust data security measures and compliance with relevant regulations to protect customer and company data; Develop processes for data acquisition, validation, and retention; Collaborate with Stakeholders, such as executive leadership, department heads, and business units to understand their data needs and align AI/ML initiatives with business objectives; Drive a Data-Drive Culture through fostering a deep understanding of data analytics and benefits; Educate and train employees on data-driven decision-making and the use of AI/ML tools; Advocate for the adoption of data-driven approaches in day-to-day operations; Responsible for the production readiness and availability of the product, while upholding the highest standard of performance, security, and user experience\\n\\n\\nProvide leadership, coaching, and direction to the team members including, partnering with HR to recruit, develop and retain top-tier talent, mange a growing team of passionate, collaborative, entrepreneurial technologists; Continually looking for leading-edge and innovative solutions in the recruitment, development, and retention of the workforce; Forecast future skill needs to acquire and develop an IS workforce with the appropriate mix of business knowledge, technical skills and competencies that balance between growing the agility required to achieve digital business objectives and ensuring the core IS functions are reliable, stable and efficient\\n\\n\\nDevelop the annual operating and capital expenditure budget to ensure it is consistent with the overall strategic objectives of IS and the enterprise and is within the plan\\n\\n\\nBuild a strong partnership with the IS leadership and functional teams to provide both strategic and in-depth solutions\\n\\n\\nLead vendor management activities, including vendor selection, contract negotiation, and ongoing vendor relationships\\n\\nTravel Required: 20-30%\\n\\nEnvironment\\n\\nOffice : Office Temperature (65F to 75F)\\n\\nSkills\\n\\n\\nSpecialized Knowledge : Understanding of wholesale and retail operations, customer behavior, and industry trends; Ability to apply Agile project management practices; Experience leading and managing data scientists and analyst; Familiarity with data governance frameworks, data privacy regulations, and security protocols; Strong planning and organizational skills; Detailed oriented, decisive, and goal oriented;\\n\\n\\nSpecial Skills : Extensive experience in AI, ML, data science and analytics with success in implementing AI/ML initiatives; Experience in developing AI/ML prototypes to showcase potential business impact or validate technical feasibility; Experience implementing solutions within cloud environments, including container-based environments (Docker, Kubernetes); Experience with scientific and machine learning libraries (SciPy, Scikit-learn, NumPy, spaCy); Proficiency in programming languages (Python, R) and data manipulation tools (SQL, Hadoop, Spark); Knowledge of data visualization tools (Tableau, Qlik, Power BI) to effectively communicate insights;\\n\\n\\nOther: Strong business acumen, including industry, domain-specific knowledge of the enterprise and its operating units\\n\\nTravel: 20 - 30%\\n\\nYears Of Experience\\n\\n15+ : Minimum of 10 years in an IS Leadership role\\n\\nQualifications\\nBachelor's Degree - Computer and Information Science\\nShift\\nCompany\\nC&S Wholesale Grocers, Inc.\\nAbout Our Company\\nC&S Wholesale Grocers, Inc. , based in Keene, NH, is the largest wholesale grocery supply company in the U.S. and the industry leader in supply chain innovation. Founded in 1918 as a supplier to independent grocery stores, C&S now services customers of all sizes, supplying more than 6,000 independent supermarkets, chain stores, military bases, and institutions with over 150,000 different products. At C&S, We Select the Best – those with the motivation, pride, and drive to succeed in our fast-paced world.\\nWorking Safely is a Condition of Employment at C&S Wholesale Grocers, Inc. C&S Wholesale Grocers is proud to be an Equal Opportunity and Affirmative Action employer, and considers qualified applicants without regard to race, color, creed, religion, ancestry, national origin, sex, sexual orientation, gender identity, age, disability, veteran status or any other protected factor under federal, state or local law.\\nCompany: C&S Wholesale Grocers, Inc.\\nJob Area: IT - Technology\\nJob Family: Information Technology\\nJob Type: Regular\\nJob Code: JC2114\\nReqID: R-251597\"}, {'job_title': 'Field Data Technician', 'job_url': 'https://search.linkup.com/details/e7ec0ae378918fe78acd0f6191a25d56', 'location': 'Waco, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 12, 679583), 'description': 'Responsibilities\\n\\nEngaging with clients on a variety of accessibility related projects.\\nCoordinating and collaborating with our team of in-house accessibility experts, multidisciplinary engineers and specialty consultants.\\nPerforming accessibility compliance inspections of the built environment on commercial and/or government projects.\\nUsing various data collection techniques to capture and analyze existing conditions for compliance with ADA standards and guidelines. \\nSupporting plan review services during the design phases of a project, from schematic design through construction documents.\\nSupporting data analysis and technical report writing efforts. \\nCollaborating with building owners, developers, architects, engineers, contractors, and clients on a variety of projects.\\nAssisting to develop new business and client accounts through business development engagement and activities.\\nSupporting and collaborating with the accessibility consultant group with projects locally and in other regions.\\nDeveloping and providing training packages or educational presentations to in-house staff on accessibility related topics.\\nWorking within a variety of market sectors including areas such as government, higher education, senior living, housing, public housing, tech, transient lodging, public rights-of-way, outdoor developed areas and others.'}, {'job_title': 'Data Engineering Manager', 'job_url': 'https://search.linkup.com/details/904357bf4df1453bd25b79272704d887', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 22, 455120), 'description': \"Your Job\\nAs a Data Engineering Manager for INVISTA, you will lead a global team of data engineers to create modern, sustainable solutions to accelerate value delivery towards INVISTA's Transformation vision and journey by developing and delivering strategic data assets.\\nWho You Are\\nYou are a self-driven, passionate, hands-on individual, with an execution track record for delivering high-quality data applications. You thrive in an agile development environment with the ability to guide and make rapid decisions. You are comfortable with ambiguity, driving clear action plans for your team to develop the right data engineering solutions. You are adept at solving technical problems and removing roadblocks so your team can focus on delivering projects. You enjoy coaching, mentoring, and developing a strong data engineering team and do not shy away from providing tough feedback conversations when needed. You have experience working with a diverse group of cross functional peers – data strategy, data governance, data science, architecture, and business stakeholders influencing and driving overall technical direction and decision making.\\nWhat You Will Do\\n\\nLead, Inspire, Coach, and Develop a high performing capability of data engineers.\\nPartner with Data Science, Data Governance, Architecture, and Engagement Leaders to fulfill data engineering deliverables.\\nOwn engineering standards, frameworks, practices, processes, etc. and drive team alignment and hands-on execution.\\nContribute to data architecture and platform strategy on behalf of data engineering through a collaborative challenge process and hands on development.\\nBuild relationships across Koch with other data engineering capabilities to share knowledge, drive communities of practice, and evangelize strategy.\\n\\nWho You Are (Basic Qualifications)\\n\\nExperience with modern architecture patterns, data warehousing methodologies, cloud solutioning, ETL/ELT, DevOps, DataOps, principles/frameworks, semantic layers, access management patterns, etc.\\nExperience working with large data sets (terabytes and larger) in a data ecosystem with emphasis on data reliability and availability.\\nExperience in developing and maintaining Data Engineering and Data Warehousing components as part of Advance Analytics solutions.\\nExperience working with cloud environments such as AWS Storage and Database services (S3, EC2, RDS, Redshift, Snowflake, Arora), Computing (Lambda, EMR) and serverless services (Glue, Athena) or similar other cloud components and services.\\nExperience with Git, DevOps, and CI/CD pipelines.\\nExperience with SQL, developing, deploying, data modelling and data pipelines on AWS or similar other cloud environments.\\n\\nWhat Will Put You Ahead\\n\\nExperience developing and deploying modern data architecture patterns, data warehousing methodologies, cloud solutioning, ETL/ELT, DevOps, DataOps, etc. principles/frameworks, semantic layers, access management patterns, etc.\\nExperience developing technical talent (small teams of 4-6 engineers) by providing performance feedback and mentorship while removing roadblocks and cultivating a positive team culture.\\n\\nAt Koch companies, we are entrepreneurs. This means we openly challenge the status quo, find new ways to create value and get rewarded for our individual contributions. Any compensation range provided for a role is an estimate determined by available market data. The actual amount may be higher or lower than the range provided considering each candidate's knowledge, skills, abilities, and geographic location. If you have questions, please speak to your recruiter about the flexibility and detail of our compensation philosophy.\\nHiring Philosophy\\nAll Koch companies value diversity of thought, perspectives, aptitudes, experiences, and backgrounds. We are Military Ready and Second Chance employers. Learn more about our hiring philosophy here.\\nWho We Are\\nAs a Koch company, INVISTA has a long history of working to make the world around you a better place. From parts for the automotive industry to medical equipment, air bags, food packaging and clothing, our ingredients in the nylon 6,6 and polypropylene value chains help bring many of life's essential products to market.\\nAt Koch, employees are empowered to do what they do best to make life better. Learn how our business philosophy helps employees unleash their potential while creating value for themselves and the company.\\nOur Benefits\\nOur goal is for each employee, and their families, to live fulfilling and healthy lives. We provide essential resources and support to build and maintain physical, financial, and emotional strength - focusing on overall wellbeing so you can focus on what matters most. Our benefits plan includes - medical, dental, vision, flexible spending and health savings accounts, life insurance, ADD, disability, retirement, paid vacation/time off, educational assistance, and may also include infertility assistance, paid parental leave and adoption assistance. Specific eligibility criteria is set by the applicable Summary Plan Description, policy or guideline and benefits may vary by geographic region. If you have questions on what benefits apply to you, please speak to your recruiter.\\nEqual Opportunities\\nEqual Opportunity Employer, including disability and protected veteran status. Except where prohibited by state law, all offers of employment are conditioned upon successfully passing a drug test. This employer uses E-Verify. Please visit the following website for additional information: http://www.kochcareers.com/doc/Everify.pdf\\nLI-RR1\"}, {'job_title': 'Data Scientist Apprentice', 'job_url': 'https://search.linkup.com/details/0bba9c9e75f0685be79493e1a0e7139a', 'location': 'Paris, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 28, 355885), 'description': \"Valeo is a tech global company, designing breakthrough solutions to reinvent the mobility. We are an automotive supplier partner to automakers and new mobility actors worldwide. Our vision? Invent a greener and more secured mobility, thanks to solutions focusing on intuitive driving and reducing CO2 emissions. We are leader on our businesses, and recognized as one of the largest global innovative companies.\\nAre you ready to meet the challenges of tomorrow's car? Join Valeo and its teams and take part in the revolution of the autonomous, electric and connected vehicle throughout the world!\\nWithin the Valeo Group's research and development department, you will be trained by a young,\\ndynamic and international team and will quickly grow in competence and responsibility in order to gain autonomy in the realization of various daily tasks.\\nYour main mission will be to collect and play with system data for the mobility solutions of the\\nfuture, including electric, autonomous and connected vehicles and systems related to comfort and health.\\nYour challenges :\\n\\n\\nData selection\\n\\n\\nData collection\\n\\n\\nData visualization\\n\\n\\nMachine learning\\n\\n\\nProcess automation\\n\\n\\nFind and create data and machine learning opportunities\\n\\n\\nWorking with teams from different backgrounds and networks\\n\\nAssessing the effectiveness and accuracy of new data sources and data gathering techniques.\\n\\nLet's talk about you !\\n\\n\\nYou are a student in an engineering school (2nd or last year) or university (M1/M2) with a specialization in computer science and statistics. \\n\\n\\nYou are patient, persistent, and creative with a Data-oriented personality.\\n\\n\\nYou are comfortable with Python and SQL\\n\\n\\nYou are fluent in French and English.\\n\\n\\nYou have a great interest in business topics\\n\\n\\nEager to research and learn in a self-directed way (always improving)\\n\\n\\nGood communication skills\\n\\n\\nExcellent applied statistics skills, such as distributions, statistical testing, regression, etc.\\n\\nTechnical Experience in Modelling, BI, big data and data mining is a plus.\\n\\nJoin us!\\nThanks to its innovation-based strategy, Valeo is at the heart of the three revolutions that are\\ndisrupting the automotive industry: the electrification of the vehicle, the advent of the autonomous and connected vehicle, and the development of digital mobility.\\nThese revolutions were anticipated by Valeo and are now synonymous with tremendous career\\nopportunities, including abroad! At Valeo, innovation is driven by the diversity, authenticity and\\nenergy of its talents. Do you want to experience new technological and human adventures? Then come and join Valeo and its 113,600 employees in 33 countries!\\nJob:\\nR&D Trainee/Apprentice/VIE\\nOrganization:\\nStartUp & Technology Incubator Office VHG - J\\nSchedule:\\nPart time\\nEmployee Status:\\nApprentice (Fixed Term)\\nJob Type:\\nApprenticeship fixed term\\nJob Posting Date:\\n2023-05-05\\nJoin Us !\\nBeing part of our team, you will join:\\n\\none of the largest global innovative companies, with more than 20,000 engineers working in Research & Development\\na multi-cultural environment that values diversity and international collaboration\\nmore than 100,000 colleagues in 31 countries... which make a lot of opportunity for career growth\\na business highly committed to limiting the environmental impact if its activities and ranked by Corporate Knights as the number one company in the automotive sector in terms of sustainable development\\n\\nMore information on Valeo: https://www.valeo.com\"}, {'job_title': 'Data Platform Architect', 'job_url': 'https://search.linkup.com/details/99b001d48c042fdcb71b5e092336860a', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 33, 158781), 'description': \"Overview\\nOmni Hotels and Resorts creates genuine, authentic guest experiences at 60 distinctive luxury hotels and resorts in leading business gateways and leisure destinations across North America. Omni Hotels is known for its exemplary culture, authenticity to the markets in which we operate, innovation and exceptional service. Our commitment to career development has created tenure and loyalty that enables us to perpetuate our family atmosphere.\\nJob Description\\nThe Omni Mission: To empower our family of associates to provide an exceptional guest experience served up with authentic local flavor.\\nAs digital technologies advance and regulations tighten, today's consumers – and, therefore, today's businesses – depend on accurate data that is available, useable, actionable, and secure. At Omni, we are working to establish holistic ways to effectively manage data through the modern data supply chain and facilitate consumption through analytics, modeling, AI, machine learning, dashboarding, and reporting.\\nThe Data Platform Architect is responsible for the support and modernization of Omni's central data architecture platforms and services. The incumbent is an energetic, experienced, hands-on technology leader adept at modern data architecture approaches and tooling, and will be instrumental in Omni's data strategy and leading all aspects of the data platform initiatives in alignment with Omni's business goals.\\nResponsibilities\\n\\nParticipate in the strategic direction of Omni's data engineering, data science, insights, and analytics technology stack (the Data Platform).\\nDeliver data architecture, tooling, and reusable frameworks/templates (data pipelines, data modeling, etc.) that optimize data product delivery efficiencies, quality, scale, and cost.\\nSupport and stabilize the existing data platform (SQL Server, SSIS, SSRS, Stored Procs, Functions, Power BI, Azure SQL) while determining modernization path forward.\\nModernize Omni's data architecture (data pipelines, data lake, data warehouse) that will be used to support insights, analytics, reporting, and future data products required to drive profitable growth for the business.\\nDefine data initiatives and projects with clarity, including scope, technical approach, and work estimates.\\nEffectively communicate, collaborate, and gain alignment with peers, leaders, and business partners across the organization.\\nEffectively break down work into high value deliverables and facilitate on-time delivery of projects using agile approaches.\\nBuild data quality checks, automated testing, and monitoring into solution delivery\\nProvide technical leadership and guidance to more junior data engineers, developers, and analysts.\\nProduce high quality technical documentation and artifacts that are easily consumable by technical and non-technical audiences.\\nBuild and attract data talent and cultivate high performing data teams.\\nDefine, design, and build analytical data models that are used as a central source of truth by data consumers (BI teams, analysts, etc.) making data more available, more useable, and more actionable in a self-service, secure manner.\\nGuide the process of troubleshooting complex, technical issues, root cause identification, and resolution.\\nPerform third-party vendor assessments and facilitate (or lead) prototyping and proof-of-concepts.\\nStay abreast of data platform technical trends, emerging approaches, and new technologies.\\n\\nQualifications\\n\\nBachelor's or Master's degree in information systems, computer science, data engineering, analytics, or equivalent quantitative field\\n10+ years of experience building and supporting production data platforms including data pipelines, ELT/ETL solutions, data lakes, and data warehouses\\n5+ years Azure cloud data platform experience with strong understanding of cloud computing and optimization techniques\\nAdvanced proficiency in data engineering/data ingestion techniques and standards\\nAdvanced proficiency in data lake and data warehousing modeling techniques including semi-structured (i.e. JSON) and analytical structures (i.e. star schema) and use of data modeling tooling\\nAdvanced proficiency defining and delivering centralized master data domains (conformed dimensions)\\nExperience and exposure understanding and applying data governance, security, and privacy policies into the data engineering workflow (GDPR, PII, etc.)\\nAdvanced proficiency in Microsoft data analytics ecosystem both on-premise and cloud (SQL Server, Visual Studio, SSIS, SSAS, SSRS, Azure SQL Managed Instance, Azure Data Factory, Power BI)\\nAdvanced proficiency with multiple modern data architecture stacks and tooling (such as Snowflake, DBT, Fivetran, and Airflow)\\nAdvance proficiency writing, updating, and troubleshooting complex ANSI SQL\\nFully experienced utilizing (and leading) Agile delivery concepts, tools, and process\\nAbility to work flexible hours, as needed, given tight project deadlines\\nMust adhere to organizational codes of conduct and confidentiality.\\n\\nWhat We'd Like To See (Preferred Qualifications)\\n\\n3+ years relevant data leadership experience in the travel and hospitality industry\\nProficiency programming in cloud data ecosystem (Python, R or Scala)\\nExposure and experience working with advanced analytics architectures and solutions (data science, machine learning, financial planning platforms, statistical analytic platforms)\\nExposure and experience working with big data tooling (Spark, Hudi, Kafka, Kinesis)\\nExposure and experience working with event streaming and event monitoring use cases\\n\\nOmni Hotels & Resorts is an equal opportunity employer - vets/disability. The EEO is the Law poster and its supplement are available using the following links: EEOC is the Law Poster and the following link is the OFCCP's Pay Transparency Nondiscrimination policy statement If you are interested in applying for employment with Omni Hotels & Resorts and need special assistance to apply for a posted position, please send an email to applicationassistance@omnihotels.com.\"}, {'job_title': 'Clinical Data Reviewer', 'job_url': 'https://search.linkup.com/details/0158f4163040bc2152a25502e91c3eea', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 37, 800659), 'description': \"POSITION SUMMARY:\\nThe Clinical Data Reviewer Is responsible for the accurate and timely work to effect filing of Insurance claims both pre and post claim submission. This person will identify invalid clinical values to help drive clean claims and revenue pull through on all products and services. \\nThis position will support the Clinical Data Specialist team and report to the Clinical Data Specialist Supervisor\\nEssential Duties and Responsibilities:\\n\\nIdentify order and reimbursement deficiencies - both clinical and code related \\nInvestigate and correct, where appropriate, deficient clinical claim information \\nIdentify and escalate missing, and sometimes invalid, clinical order data for timely contact resolution with supporting cross functional teams\\nPartner with multiple internal cross-functional teams and successfully manage multiple product projects simultaneously. \\nResearch claim and account information using various systems and portals internal and external\\nStay current with relevant medical billing regulations, rules and guidelines\\nComplete position responsibilities within the appropriate time frame while adhering to quality standards\\nTranslate data into meaningful information and knowledge that supports decision making or determining action that drives performance improvement and quality\\nIdentifies and uses internal and external sources of information for benchmarking and comparative performance, which includes networking with clinical communities, researching literature and agencies, and staying current on new indicators and other requirements\\nSupport and comply with the company's policies and procedures. \\nMaintains strictest confidentiality, and adheres to all HIPAA guidelines/regulations\\nRegular and reliable attendance.\\nAbility to work on a mobile device, tablet, or in front of a computer screen and/or perform typing for approximately 90% of a typical working day.\\nAbility to meet productivity and quality standards set by Clinical Data Specialists.\\n\\nQualifications:\\nMinimum Qualifications:\\n\\n1+ years professional coding experience and understanding of International Classification of Diseases (ICD-10) and Coding Procedure Terminology (CPT) and HCPCS coding.\\nAuthorization to work in the United States without sponsorship. \\nSuperior organization skills, detail oriented, and ability to be persistent and follow through\\nProblem-solving, ability to adapt, flexibility in approaches to accomplishing tasks, and ability to independently arrive at creative solutions to problems\\nExcellent communication skills, both verbal and written, particularly the ability to convey technical information in an accessible and understandable manner\\nAbility to work both independently and in collaboration with individuals from various disciplines\\n\\nPreferred Qualifications:\\n\\n2+ years of experience coding in the medical/healthcare billing area- Lab a plus\\nAny years of experience in the revenue cycle function to include third party payer experience.\\nUnderstanding of professional coding, documentation, medical billing processes.\\nKnowledge and familiarization with Medicare billing regulations and reimbursement methodologies for Laboratory\\n\\nThe pay range is listed and actual compensation packages are based on a wide array of factors unique to each candidate, including but not limited to skill set, years & depth of experience, certifications and specific office location. This may differ in other locations due to cost of labor considerations.\\nNew York\\n$17—$21 USD\\nOUR OPPORTUNITY\\nNatera is a global leader in cell-free DNA (cfDNA) testing, dedicated to oncology, women's health, and organ health. Our aim is to make personalized genetic testing and diagnostics part of the standard of care to protect health and enable earlier and more targeted interventions that lead to longer, healthier lives.\\nThe Natera team consists of highly dedicated statisticians, geneticists, doctors, laboratory scientists, business professionals, software engineers and many other professionals from world-class institutions, who care deeply for our work and each other. When you join Natera, you'll work hard and grow quickly. Working alongside the elite of the industry, you'll be stretched and challenged, and take pride in being part of a company that is changing the landscape of genetic disease management.\\nWHAT WE OFFER\\nCompetitive Benefits - Employee benefits include comprehensive medical, dental, vision, life and disability plans for eligible employees and their dependents. Additionally, Natera employees and their immediate families receive free testing in addition to fertility care benefits. Other benefits include pregnancy and baby bonding leave, 401k benefits, commuter benefits and much more. We also offer a generous employee referral program!\\nFor more information, visit www.natera.com.\\nNatera is proud to be an Equal Opportunity Employer. We are committed to ensuring a diverse and inclusive workplace environment, and welcome people of different backgrounds, experiences, abilities and perspectives. Inclusive collaboration benefits our employees, our community and our patients, and is critical to our mission of changing the management of disease worldwide.\\nAll qualified applicants are encouraged to apply, and will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, disability or any other legally protected status. We also consider qualified applicants regardless of criminal histories, consistent with applicable laws.\\nIf you are based in California, we encourage you to read this important information for California residents. \\nLink: https://www.natera.com/notice-of-data-collection-california-residents/\\nPlease be advised that Natera will reach out to candidates with a @natera.com email domain ONLY. Email communications from all other domain names are not from Natera or its employees and are fraudulent. Natera does not request interviews via text messages and does not ask for personal information until a candidate has engaged with the company and has spoken to a recruiter and the hiring team. Natera takes cyber crimes seriously, and will collaborate with law enforcement authorities to prosecute any related cyber crimes.\\nFor more information:\\n\\nBBB announcement on job scams \\nFBI Cyber Crime resource page\"}, {'job_title': 'Manager, Data Visualization', 'job_url': 'https://search.linkup.com/details/b921021a730a0c7911959d44a20715da', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 42, 482074), 'description': \"With a company culture rooted in collaboration, expertise and innovation, we aim to promote progress and inspire our clients, employees, investors and communities to achieve their greatest potential. Our work is the catalyst that helps others achieve their goals. In short, We Enable Possibility℠.\\nStrategic Analytics is a growing team at Arch that develops innovative predictive models and analytical tools to improve proﬁtability and growth as well as providing deep analytical insight for decision makers. Advanced analytics techniques play a critical role in this mission. To be successful, we need to develop powerful models, tools and insights that give Arch a unique, competitive advantage. \\nAs Manager, Data Visualization you will play a crucial role in developing the team's visualization capability. You will work on high-proﬁle visualization projects that support the teams wider predictive analytics work and this will drive the company's decision-making and strategy. You will work alongside a talented team of data engineers, data scientists and other visualization experts to build best-in-class analytics insight. As an important member of the Strategic Analytics team, you will help advance our visualization capabilities.\\nThis is a hybrid position that can be based out of our Jersey City, NJ, Philadelphia, PA, Hartford, CT, or Dallas, TX office - 2x/week in office. \\nJob Responsibilities:\\n\\n\\nCollaborate with data scientists and business partners to develop and implement wireframes aimed at business actions based on data driven insights\\n\\n\\nDevelop dashboards based on wireframes\\n\\n\\nDesign end to end reporting solution sufficing business needs\\n\\n\\nBuild data models sourcing data from various data sources viz. Azure SQL Server, SQL Server, Snowflake for reporting\\n\\n\\nOptimize the existing dashboards to improve user experience\\n\\n\\nImplement writeback capabilities in the reporting tool leveraging various automation tools\\n\\n\\nLeverage technology to automate manual tasks and reporting needs\\n\\n\\nDevelop pixel perfect reports where appropriate\\n\\n\\nBuild & support applications in Power Apps and integrate it with Power BI\\n\\n\\nResearch marketplace visuals and R/Python visuals to create new dashboard enhancements\\n\\n\\nAbility to troubleshoot and maintain existing VBA scripts\\n\\n\\nDevelop & implement visualization best practices across the team\\n\\nBuild POC's to explore new features, tools & technologies\\n\\nDesired Skills/Experience:\\n\\n\\nDemonstrated experience in building dashboards/reports to support analytics/actuarial functions in an insurance company setting\\n\\n\\nExperience in reporting tools viz. Power BI, Report builder\\n\\n\\nAbility to handle technical tasks/problems independently - managing tasks and engaging people across the team\\n\\n\\nStrong problem solving and critical thinking skills\\n\\n\\nExceptional collaboration and relationship building skills\\n\\n\\nA mind set of continued learning, and the desire to explore new tool choices and understand how data can be used to drive change\\n\\nExceptional written and verbal communication, including the ability to explain complex concepts\\n\\nRequired Skills/Experience:\\n\\n\\n5-7 years of experience in developing reports & dashboards leveraging visualization tools viz. Power BI, QlikView, Tableau\\n\\n\\n2-3 years of recent experience in Power BI visualization tool along with prior experience in any other visualization tool\\n\\n\\nStrong experience in building data models (Star Schema/Snowflake) in the visualization tool\\n\\n\\nProficient in writing complex measures in the visualization tool (DAX)\\n\\n\\nAbility to writing complex SQL queries to pull the data into visualization tool and for querying data for analysis purpose\\n\\n\\nExperience in pixel perfect reporting (Paginated Reports/SSRS)\\n\\n\\nExperience in building geo mapping capabilities in the visualization tool\\n\\n\\nIntermediate experience in Power Automate (Microsoft Flow/Power Apps)\\n\\nIntermediate experience in R/Python scripting\\n\\nEducation:\\n\\n\\nBachelor's in Computer Science, Information Technology degree, Data Analytics or equivalent\\n\\nTechnical certification in any BI technology would be preferred\\n\\nLI-LH1\\nFor individuals assigned or hired to work in Jersey City, New York City, and/ or Westchester County, the base salary range is listed below. This range is as of the time of posting. Position is incentive eligible.\\n$148,614 - $201,066/year\\n\\n\\nTotal individual compensation (base salary, short & long-term incentives) offered will take into account a number of factors including but not limited to geographic location, scope & responsibilities of the role, qualifications, talent availability & specialization as well as business needs. The above range may be modified in the future\\n\\nClick here to learn more on available benefits\\n\\nDo you like solving complex business problems, working with talented colleagues and have an innovative mindset? Arch may be a great fit for you. If this job isn't the right fit but you're interested in working for Arch, create a job alert! Simply create an account and opt in to receive emails when we have job openings that meet your criteria. Join our talent community to share your preferences directly with Arch's Talent Acquisition team.\"}, {'job_title': 'Data Governance Advisor', 'job_url': 'https://search.linkup.com/details/a129bb5fd7d1bac4be5f974a9a8d337e', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 47, 702890), 'description': 'ENGIE is committed to reshaping the energy future through the global implementation of a lower carbon energy economy in order to preserve the world\\'s natural resources. We are looking for talented and driven people who are committed to making the vision a reality.\\nThe Data Governance Advisor is responsible for helping identify and manage Enterprise Data and associated meta data for GEM US as directed by the Commercial Data Officer (CDO). This position resides in the Commercial Data Management Office (CDMO), participating in use case data classification and data related stakeholder committee meetings and informal communications required to manage the Company\\'s Enterprise Data. This role will work directly with key data owners and IT to help determine the plans for managing the associated Enterprise Data. All data inputs and output of IT and strategic business technology projects are subject to the review of the CDMO. Enterprise Data will be managed in Collibra via the collection and storage of the associated metadata. The upkeep of this metadata in Collibra will be the responsibility of the CDMO comprised of the Commercial Data Officer (CDO) and the Data Governance Advisor. This role is expected to be heavily involved with the Collibra platform on a day-to-day hands-on manner. Data is the responsibility of the GEM US business as a whole, and as such, this position will be transversal with respect to supporting the different departments in GEM US and will work with the CDO to set goals and execute the plan for data management. This role contributes to operational excellence goals of GEMS and also drives business value.\\nThis position is located in Houston, TX and reports to CDO, Commercial Data Officer. \\nWhat you\\'ll do:\\n\\nPerform planning with the CDO and appropriate stakeholders and execute the data management strategy\\nWork up front on technology projects to identify Enterprise Data and include this data in the scope of data governance on the Collibra platform\\nWork with data owners, data engineers, data champions and data stewards in the organization to build and manage a consistent, sustainable data management platform and build the required consensus across teams\\nEnter and maintain Enterprise Data into Collibra consistent with the rollout plan and leverage auto-population of metadata via Dataiku, Databricks and other associated digital analytical platform tools\\nWork towards goal of providing efficient, secure and reliable community access of all Enterprise Data for all designated departments with quality control measures\\nWork closely with the CDO and market data services contracts leader to understand and catalog all related data sources and understand the use of this data in the organizations, while looking for opportunities to save on cost and avoid duplication of data services and assist with termination of data services that are no longer needed\\nWork with key data owners and data scientists to understand and catalog model data outputs that qualify for publishing as Enterprise Data\\nWork closely with IT to identify and catalog sources of Enterprise Data that come from our IT systems and understand the related integration of our Enterprise Data\\nPresent status updates to the stakeholders and the CDO and help resolve related issues\\nHelp produce KPIs and ROI on our data management investments\\nAssist in training other team members and business users where needed\\nReview and adopt the required Group level data policies, processes and procedures to work in GEM US.\\nActs as a team member with all employees of ENGIE staff.\\nComplies with all ENGIE NA policies and procedures.\\n\\nData Management implementation in use cases:\\n\\nIdentifies strategic use cases with an opportunity to deploy the governance framework\\nParticipates in the proper specification and onboarding of new use cases\\nDrives data modeling in GEMS strategic data catalog\\nImplements follow-up action plans including the improvement of data quality checks and remediatio\\n\\nTransversal Data Management responsibilities:\\n\\nGuarantees the proper evolution of the data catalog and quality of its content to facilitate both data quality and sharing of reliable information\\nAssists in developing and updating the Commercial Data Management Office (CDMO) roadmap\\nAssists in updating and monitoring KPIs & data objectives allowing to supervise the governance program\\nProvides support to enrich and improve the GEMS Data Toolbox (Collibra, Data Quality tooling, etc.)\\n\\nProject Management:\\n\\nHelp manage data subscriptions related tasks as assigned by the CDO\\n\\nWhat you bring:\\n\\nBachelor\\'s degree in a business and/or related business technical field preferred\\nMinimum 7 years of general business or IT experience\\nMinimum 5 years of work with data in IT systems, external data sources, associated data tools\\nMinimum 5 years professional experience in similar role or business analyst capacity with ideally a previous experience in data management initiatives, including the working with metadata in platforms and its subsequent upkeep\\nExperience with data governance and related operations\\nExperience supporting the data needs of a Power and/or Natural Gas related commercial operation\\nProficient with Microsoft Office products (Excel, Word, Visio, PowerPoint, PowerBI)\\nISO Market systems knowledge preferred\\nSQL Server database and modern cloud platform knowledge\\nUnderstanding of the types of data used in forward modelling of physical assets and transactions in natural gas and electricity markets and related risk management concepts. \\nExposure to short term optimization and operations of generating assets in ISO markets and to ISO market design concepts.\\nExcellent interpersonal skills, eager to learn, work with diverse groups\\nAbility to deliver results in tight timelines\\nAbility to interact at the detailed level with both business and IT teams and develop an understanding of the usage of Enterprise Data throughout GEM US\\nPrior experience with Collibra or similar data governance product\\n\\nAdditional Information/Conditions:\\n\\nMust be eligible to work for any U.S. employer without the need for sponsorship now or in the future\\nMust be willing and able to comply with ENGIE\\'s policy with respect to COVID vaccination and testing\\nMust be willing and able to comply with all ENGIE ethics and safety policies\\nAbility to meet highest attendance requirements\\nAbility to communicate effectively, both written and verbally\\nAbility to handle multiple assignments on a timely basis with a high degree of accuracy\\nAbility to use a company computer, calculator, \\nCould involve some lifting \\nWork environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job\\nReasonable accommodations may be made to enable individuals with the needed assistance to perform the essential functions \\nEligible for a hybrid schedule consisting of in-office and work-from-home opportunities\\n\\nWhy ENGIE?\\nENGIE North America isn\\'t just participating in the Zero-Carbon Transition, we\\'re leading it! Join us as we develop energy that is renewable, efficient, and accessible to everyone. \\nUnite with us in leading the transformation of the world of energy! ENGIE is looking for talented and motivated individuals to create the future of energy and customer solutions. Join a rewarding and flexible work environment that encourages innovation and creativity to help customers meet their energy challenges today and in the future. Are you up for the challenge?\\nAt ENGIE, our goal is to support, promote, and thrive on diversity, equity, and inclusion. We do so for the benefit of our employees, customers, products and services, and community. ENGIE is proud to be an equal opportunity workplace, and we are firmly committed to creating an equitable and inclusive environment for all employees.\\nWe are committed to providing employees with a work environment free of discrimination and harassment.\\u202f All employment decisions at ENGIE are based on business needs, job requirements, and individual qualifications.\\u202f ENGIE is committed to providing equal employment opportunities regardless of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship, age, sex or gender (including pregnancy, childbirth, and related medical conditions), gender identity, or gender expression (including transgender status), sexual orientation, marital status, civil union, or domestic partnership status, military service or veteran status, physical or mental disability, protected medical condition, genetic information, or any other legally protected category (referred to as \"protected characteristics\") as defined by applicable federal, state or local law in the locations where we operate. \\n\\nSalary Range: $79,305 - $202,540, annually \\nActual salary offered may vary depending on geography, experience, education, internal pay alignment, or other bona fide factors \\nIn addition to salary, this position is eligible for a competitive bonus / incentive plan\\nAt ENGIE we understand that benefits matter, we offer competitive benefit options including medical, dental and vision coverage, life insurance, employer paid short-term and long-term disability insurance, paid vacation, holidays, sick leave, parental leave, and a 401(k) Retirement Savings Plan option with a company match\\nMore information can be found here: Discover our employee benefits \\n\\nENGIE complies with all federal, state, and local minimum wage laws. \\nYour talent acquisition partner can share more specific information regarding the salary for the position based on the work location. \\nIf you need assistance with this application or a reasonable accommodation due to a disability, you may contact us at ENGIENA-ENGIEHR@engie.com. This email address is reserved for individuals with disabilities in need of assistance and is not a means of inquiry regarding positions or application status.\\nBusiness Unit: GEMS\\nDivision: GEMS - BP AMERICAS\\nLegal Entity: ENGIE ENERGY MARKETING NA, INC.\\nContract Type: Permanent\\nJob Type: Full - Time\\nProfessional Experience: Skilled ( >3 experience\\nEducation Level: Bachelor\\'s Degree'}, {'job_title': 'Data Quality Engineer - All-Payor Claims Database - Hybrid', 'job_url': 'https://search.linkup.com/details/a4c5a01049a0a9b282a89c4db4f44fce', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 52, 516134), 'description': \"What we do here changes the world. UTHealth Houston is Texas' resource for healthcare education, innovation, scientific discovery, and excellence in patient care. That's where you come in.\\nWe are seeking a Full-Time Data Quality Engineer to join the UTHealth Center for Healthcare Data as part of the School of Public Health in Houston, TX 77030. This is a hybrid position that requires the employee to reside in Texas. In this position, you will join a fantastic team that strives to make a meaningful difference in the quality of data available to researchers doing innovative healthcare research. The Data Quality Engineer is a skillful team player with a clear track record of transforming big data into actionable insights, which leads to improvements in data quality and associated standards and processes. This individual is a deliberate and systematic scientist who can clearly articulate the goals of the data quality program, practice with rigor and precision, and maintain a balanced/independent point of view to achieve targeted data quality standards. \\nOnce you join us you won't want to leave. It's because we reward our team for the excellent service they provide. Our total rewards package includes the benefits you'd expect from a top healthcare organization (benefits, insurance, etc.), plus: \\n\\n100% paid medical premiums for our full-time employees \\nGenerous time off (holidays, preventative leave day, both vacation and sick time – all of which equates to around 37-38 days per year) \\nThe longer you stay, the more vacation you'll accrue! \\nLongevity Pay (Monthly payments after two years of service) \\nBuild your future with our awesome retirement/pension plan! \\n\\nWe take care of our employees! As a world-renowned institution, our employees' wellbeing is important to us. We offer work/life services such as... \\n\\nFree financial and legal counseling \\nFree mental health counseling services \\nGym membership discounts and access to wellness programs \\nOther employee discounts including entertainment, car rentals, cell phones, etc. \\nResources for child and elder care \\nPlus many more! \\n\\nPosition Summary:\\nThe Data Quality Engineer is a skillful team player with a clear track record of transforming big data into actionable insights which lead to improvements in data quality and associated standards and processes. This individual is a deliberate and systematic scientist who can clearly articulate the goals of the data quality program, practice with rigor and precision, and maintain a balanced/independent point of view to achieve targeted data quality standards. Applies the principles of data quality across a range of data sets and their intersection, including but not limited to administrative claims, electronic health records, social determinants of health data sets, and others. It is essential for this person to be a very effective communicator who can evangelize data quality standards throughout the organization.\\nPosition Key Accountabilities:\\n\\nUses a variety of tools and techniques to develop a suite of data quality metrics which provide benchmarks for assessing data quality both at points in time and across periods of time leveraging key elements of the Patient Demographic Data Quality (PDDQ) Framework developed by the Office of the National Coordinator for Health IT (ONC). \\nPlans, implements and is responsible for maintaining a metadata management program using the Common Data Layout (CDL) based on CDL specifications published by the APCD Council/NAHDO including standardized definitions of data attributes and associated documentation designed for broad consumption.\\nBuilds quality measurement and scoring models and monitoring frameworks which allow for the proactive and automated assessment of quality across diverse data sets including administrative, clinical, and social determinants of health data when applicable. Conducts periodic assessments and drives processes for continuous improvement.\\nApplies a variety of methods based on standards and metrics to review and improve data acquisition and data management processes such as statistical analysis, machine learning, data mining, predictive analytics, time series analysis, multivariate regression analysis, statistical process control and optimization solutions.\\nCollaborates with the Data Linkage Scientist and other team members to improve Master Person Index (MPI), Master Provider Registry (MPR), and other link index match rates.\\nPerforms as a results-oriented problem solver to quickly synthesize complex scenarios, conduct root cause investigations, apply appropriate methods, and plan/implement practical and timely solutions.\\nServes as a champion for data quality throughout the organization using a collaborative approach to fully realize the talents of colleagues such as data stewards, IT staff, business analysts, business stakeholders and industry experts.\\nInterfaces and collaborates with all other functions within the organization and with data submitters on quality-related issues.\\nPerforms other duties as assigned.\\n\\nCertification/Skills:\\n\\nMastery of data discovery and data profiling techniques and tools.\\nFamiliarity with health care claims data and associated X12 knowledge\\nAbility to influence and collaborate broadly within the organization as a data quality champion\\nProficiency with statistical packages, databases and programming languages for data preparation, storage, transformation, analysis or visualization. Examples include R, SAS, STATA, SQL, Python, PySpark, Tableau, Excel and other big data frameworks.\\nAbility to work with a wide variety of large dataset formats/sources such as relational databases, Parquet, ORC, XML, JSON, CSV, streams and geolocation\\nEffective communication skills including written, oral, listening and interpersonal.\\n\\nMinimum Education:\\n\\nMaster's degree in mathematics, engineering, informatics, or a related field.\\n\\nMinimum Experience:\\n\\nThree (3) years of enterprise experience as a data scientist, informaticist, senior analyst or related role. \\nFive (5) years of relevant data analysis experience. \\n\\nPhysical Requirements: Exerts up to 50 pounds of force occasionally and/or up to 20 pounds frequently and/or up to 10 pounds constantly to move objects. Security Sensitive: This job class may contain positions that are security sensitive and thereby subject to the provisions of Texas Education Code § 51.215 Residency Requirement: Employees must permanently reside and work in the State of Texas.\"}, {'job_title': 'Senior Data Warehouse Engineer - US Based Remote Opportunity', 'job_url': 'https://search.linkup.com/details/ab74ecd82277919d75465cec30220306', 'location': 'Arlington, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 55, 57, 191148), 'description': \"Do you have a passion for higher education? Do you want to make a positive impact on the college admissions process? Our staff helps to remove barriers and encourage students forge their path to a better future. Common App is a not-for-profit organization dedicated to the pursuit of access, equity, and integrity in the college admission process. Each year we support more than one million students, one-third of whom are first-generation, apply to our over 900 diverse member college & universities using the Common App's free online application. If you are a data warehouse professional, with full life cycle data warehouse development experience in an agile environment and want to be part of a mission-driven non-profit that uses innovative technology to advance the college admission process, Common App may be a great match for you. \\nWe are looking for a Senior Data Warehouse Engineer that demonstrates enthusiasm for the education technology market and a passion for creating products that can transform the lives of students. Reporting to the Associate Director Development, the individual in this role will understand, and apply enterprise level data warehouse technical standards, principles, concepts, techniques and provide solutions to a variety of technical problems of moderate to high scope and complexity. \\nThis individual develops a deep knowledge and understanding of the data warehouse and data management assets (RDS) available within our data platforms and acts as the subject matter expert on the data and its utility for operational use. Your duties will include: \\n\\nConsulting with the data management group\\nCreating and designing a refined data warehousing environment\\nExtracting data from various internal and external sources\\nAdding to the data warehouse's capabilities\\nTesting the environment upon completion\"}, {'job_title': 'Data Center Facility Manager', 'job_url': 'https://search.linkup.com/details/69e1f613f2caa1441c10b1c98d0c3db4', 'location': 'Red Oak, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 1, 732062), 'description': \"Minimum qualifications:\\n\\n\\nBachelor's degree or equivalent practical experience.\\n\\n\\n5 years of experience in critical facilities management (e.g., facility, technical, and team management).\\n\\nExperience working as a facilities manager or chief engineer.\\n\\nPreferred qualifications:\\n\\n\\nExperience in mission Critical Systems operations (e.g., power generation, data center, refinery, chip fabrication, chemical processing, or other high consequence environments).\\n\\n\\nExperience in collaborating with other business units to meet company goals and standards.\\n\\n\\nKnowledge of Electrical and Mechanical systems in a Data Center Environment.\\n\\n\\nAbility to collaborate and advice at all levels.\\n\\nExcellent people management and leadership skills.\\n\\nAbout the job\\nThe Data Center team designs and operates some of the most sophisticated electrical engineering, mechanical engineering and HVAC systems in the world. Facility Technicians at Google data centers operate, monitor and support physical facilities conditions. Some duties will include heating and cooling of air and water, power supply, generators, UPS systems, electrical distribution and control and monitoring systems. You regularly help inspect, maintain and repair various data center systems such as piping and non-critical electrical or mechanical system components). You'll provide daily assistance to senior technicians as you read blueprints/schematics, conduct tours of systems and assess their working order.\\nYou will develop creative approaches to reducing operational costs while improving overall data center efficiency. You ensure that environmental and safety standards are consistently met, identifying problems and making repairs quickly In emergency situations or abnormal conditions, you manage data center performance issues and outages to minimize the recovery time from failures.\\nBehind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running. From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible. We're proud to be our engineers' engineers and love voiding warranties by taking things apart so we can rebuild them. We keep our networks up and running, ensuring our users have the best and fastest experience possible.\\nThe US base salary range for this full-time position is $121,000-$181,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.\\nPlease note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google.\\nResponsibilities\\n\\nResponsible for meeting service level agreements (SLAs) with internal teams on uptime, efficiencies and cost. \\nLead efforts to integrate Google-wide strategy and execution with internal and external business partners.\\nCreate strategy for cost effective operations, focused on total cost of ownership.\\nDemonstrate critical thinking and innovation in approaching traditional data center and emergent challenges.\\nDemonstrate the ability to implement and drive the safety culture at the site.\"}, {'job_title': 'Software Engineer Lead - AI/Analytics - Enterprise Data Management Team', 'job_url': 'https://search.linkup.com/details/4a6f64bcb842b492b04b4a5ac946d91e', 'location': 'Farmers Branch, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 6, 339551), 'description': \"Position Overview\\nAt PNC, our people are our greatest differentiator and competitive advantage in the markets we serve. We are all united in delivering the best experience for our customers. We work together each day to foster an inclusive workplace culture where all of our employees feel respected, valued and have an opportunity to contribute to the company's success. As a Software Engineer Lead within PNC's AI / Analytics - Enterprise Data Management Team (EDMT), you will be based in Pittsburgh, PA; Cleveland, OH; Dallas, TX or Birmingham, AL.\\nThis role will focus on building the infrastructure needed to support PNC's Data Science community with a stable production platform to execute models that have been developed in PNC labs. This role will work closely with the teams supporting the models to ensure continuity and transition from the labs to the production platform. A strong Unix background is a must. An understanding of AI / Analytics or Data Science (including Python and R) is a plus.\\nJob Description\\n\\nCreates and leads the technical design and development of software solutions.\\nProposes & designs software solutions to address complex business needs. Prepares technical and procedural documentation required.\\nFacilitates complex problem resolution.\\nProvides technical guidance and support to colleagues. Reviews coding, testing, and documentation of software.\\nApplies modern principles, methodologies and tools to advance business initiatives and capabilities.\\n\\nPNC Employees take pride in our reputation and to continue building upon that we expect our employees to be:\\n\\nCustomer Focused - Knowledgeable of the values and practices that align customer needs and satisfaction as primary considerations in all business decisions and able to leverage that information in creating customized customer solutions.\\nManaging Risk - Assessing and effectively managing all of the risks associated with their business objectives and activities to ensure they adhere to and support PNC's Enterprise Risk Management Framework.\\n\\nCompetencies\\nApplication Delivery Process – Knowledge of major tasks, deliverables, and formal application delivery methodologies; ability to utilize these in order to deliver new or enhanced applications.\\nApplication Design, Architecture – Knowledge of application design activities, tools and techniques; ability to utilize these to convert business requirements and logical models into a technical application design.\\nApplication Development Tools – Knowledge of and ability to utilize a variety of specific tools and toolkits for the development and support of applications.\\nApplication Testing – Knowledge of application testing and ability to design, plan and execute application testing strategies and tactics to ensure software quality throughout all stages of application development.\\nPackaged Application Integration – Knowledge of and the ability to implement packaged application software and integrate it with company applications, databases and technology platforms.\\nSystem Development Life Cycle – Knowledge of project management techniques and the ability to plan, design, develop, test, implement and maintain system development life cycle segments and phases.\\nTechnical Troubleshooting – Knowledge of technical troubleshooting approaches, tools and techniques, and the ability to anticipate, recognize, and resolve technical (hardware, software, application or operational) problems.\\nWork Experience\\nRoles at this level typically require a university / college degree, with 3+ years of relevant / direct industry experience. Certifications are often desired. In lieu of a degree, a comparable combination of education and experience (including military service) may be considered.\\nEducation\\nBachelors\\nAdditional Job Description\\nBenefits\\nPNC offers employees a comprehensive range of benefits to help meet your needs now and in the future. Depending on your eligibility, options for full-time employees include medical/prescription drug coverage (with a Health Savings Account feature); dental and vision options; employee and spouse/child life insurance; short- and long-term disability protection; maternity and parental leave; paid holidays, vacation days and occasional absence time; 401(k), pension and stock purchase plans; dependent care reimbursement account; back-up child/elder care; adoption assistance; educational assistance and a robust wellness program with financial incentives. To learn more about these and other programs, including benefits for part-time employees, visit pncbenefits.com > New to PNC.\\nDisability Accommodations Statement:\\nThe PNC workplace is inclusive and supportive of individual needs. If you have a physical or other impairment that might require an accommodation, including technical assistance with the PNC Careers website or submission process, please call 877-968-7762 and select Option 4: Recruiting or contact us via email at pathfinder@pnc.com. \\nThe Human Resources Service Center hours of operation are Monday - Friday 9:00 AM to 5:00 PM ET.\\nEqual Employment Opportunity (EEO):\\nPNC provides equal employment opportunity to qualified persons regardless of race, color, sex, religion, national origin, age, sexual orientation, gender identity, disability, veteran status, or other categories protected by law.\\nCalifornia Residents \\nRefer to the California Consumer Privacy Act Privacy Notice to gain understanding of how PNC may use or disclose your personal information in our hiring practices.\"}, {'job_title': 'Software Engineer II - Big Data (Java, Spark, ETL, Informatica)', 'job_url': 'https://search.linkup.com/details/27a1d006d122fc245d974d027a59b8ab', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 11, 157102), 'description': \"JobID: 210402473\\nCategory: Software Engineering\\nJobSchedule: Full time\\nPosted Date: 2023-07-19T18:02:39+00:00\\nJobShift: Day\\n:\\nAs an experienced Software Engineer, you will work in a dynamic, agile team to enhance, build, and deliver trusted market-leading technology products in a secure, stable, and scalable way. Depending on the team that you join, you could be developing mobile features that give our customers and clients more control over how they bank with us, strategizing on how big data can make our trading systems quicker, creating the next innovation in payments for merchants, or supporting the integration of our private and public cloud platforms. \\nJob Responsibilities\\n\\nExecutes standard software solutions, design, development, and technical troubleshooting\\nWrites secure and high-quality code using the syntax of at least one programming language with limited guidance\\nDesigns, develops, codes, and troubleshoots with consideration of upstream and downstream systems and technical implications\\nApplies knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation\\nApplies technical troubleshooting to break down solutions and solve technical problems of basic complexity\\nGathers, analyzes, and draws conclusions from large, diverse data sets to identify problems and contribute to decision-making in service of secure, stable application development\\nLearns and applies system processes, methodologies, and skills for the development of secure, stable code and systems\\nBuild ETL workflows that will run on the bank's internal cloud / on-prem and the public cloud platform\\n\\nRequired Qualifications, Capabilities, and Skills\\n\\nFormal training or certification on software engineering concepts and 2+ years applied experience\\nHands-on practical experience in system design, application development, testing, and operational stability\\nExperience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages\\nDemonstratable ability to code in one or more languages\\nExperience across the whole Software Development Life Cycle\\nKnowledge or experience on ETL technologies like Informatica or Ab-initio would be preferable along with Java/AWS\\nEmerging knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)\\n\\nPreferred Qualifications, Capabilities, and Skills\\n\\nFamiliarity with ETL development using Java / spark\\nExposure to cloud technologies\"}, {'job_title': 'Data Analyst (PMWeb Tech)', 'job_url': 'https://search.linkup.com/details/66d0cb87c44dc9ee11269081f6394390', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 16, 36724), 'description': \"Data Analyst (PMWeb Tech)\\nJob ID\\n128945\\nPosted\\n17-Jul-2023\\nService line\\nGWS Segment\\nRole type\\nFull-time\\nAreas of Interest\\nDigital & Technology/Information Technology\\nLocation(s)\\nDallas - Texas - United States of America, Des Moines - Iowa - United States of America, Houston - Texas - United States of America, Kansas City - Kansas - United States of America, Kansas City - Missouri - United States of America, Minneapolis - Minnesota - United States of America, Omaha - Nebraska - United States of America, Orlando - Florida - United States of America, Overland Park - Kansas - United States of America, Phoenix - Arizona - United States of America, San Antonio - Texas - United States of America, South Houston - Texas - United States of America, St. Louis - Missouri - United States of America\\nOur Digital & Technology organization sits at the heart of CBRE. As part of our team, you'll be able to learn from the most brilliant engineers, designers, and product managers while solving tough problems that will drive our technology forward. \\nAbout The Role \\nThe purpose of this position is to provide PMWeb technical application support to project management teams using the technology platform. The Analyst is responsible for solving application data issues and customer workflow problems. This person will problem-solve, educate users, and follow resolution protocols. The Data Analyst will also raise complaints, document issues, and participate in quality assurance of applications, and testing. Additionally, this person will monitor BAU production operations of PMWeb and responds to performance log inquiries.\\nWhat You'll Do \\n\\nReview the accuracy of information provided by customers and provide resolutions by applying problem-solving techniques.\\nDevelop data structures and pipelines to coordinate, collect, cleanse, and standardize data in order to generate insights and address reporting needs. Replicate and document issues for further partner concern.\\nDefine data requirements and gathers and validate information, using judgment and statistical tests. Participate in quality assurance and application testing of software as required.\\nApply programming and analytical tools, including open-source programs to formulate models and/or extract insights.\\nProficient in identifying patterns and insights from data sets, applying graphs, trees and/or other data representation techniques as the need arises. Monitor production operations of applications including reviewing and reacting to performance logs.\\nDesign workflows and procedures.\\nFind opportunities to improve data usage, applying modeling and optimization methods to develop new strategies and improve business performance.\\nDevelop ad-hoc analytics and reporting based on analysis of existing data sources, using a variety of tools (i.e. SSRS, Tableau).\\n\\nWhat You'll Need \\n\\nBachelor's degree\\nDemonstrable experience in PMWeb, application/system, and end-user support, analysis, data modeling and reporting.\\nExcellent written and verbal communication skills.\\nAbility to deliver efficient, timely, reliable, and courteous service to customers.\\nAbility to optimally present information.\\nStrong analytical skills.\\nAbility to comprehend, analyze, and interpret documents.\\nAbility to solve problems involving several options in situations.\\nProficient in Microsoft Office Suite including Word, PowerPoint, Excel, and Outlook.\\n\\nWhy CBRE? \\nCBRE is the world's largest commercial real estate services and investment firm, and we have been ranked #1 on Fortune's World's Most Admired Company: (2019, 2020, 2021,2023). With services, insights, and data that span every dimension of the industry, we build digital solutions for clients of every size, in every sector, and across every geography.\\nApplicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future\\nCBRE is an equal opportunity employer that values diversity. We have a long-standing commitment to providing equal employment opportunity to all qualified applicants regardless of race, color, religion, national origin, sex, sexual orientation, gender identity, pregnancy, age, citizenship, marital status, disability, veteran status, political belief, or any other basis protected by applicable law. We also provide reasonable accommodations, as needed, throughout the job application process. If you have a disability that inhibits your ability to apply for a position through our online application process, you may contact us via email at recruitingaccommodations@cbre.com or via telephone at +1 866 225 3099 (U.S.) and +1 866 388 4346 (Canada).\\nNOTE: Some, but not all, of our positions may have an additional requirement to comply with COVID-19 health and safety protocols, including COVID-19 vaccination proof and/or rigorous testing. If you have questions about the requirement(s) for this position, please inform your Recruiter.\"}, {'job_title': 'Senior Manager, Data Engineering', 'job_url': 'https://search.linkup.com/details/44b019c643d3e29251d4d472f2ec7041', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 20, 775649), 'description': \"Ready to guide all aspects of Data Engineering assurance while developing innovative technology? You can do that. Do you want to assemble and guide a high-performing team? As a Senior Manager of Data Engineering at Spectrum Enterprise, you can do that.\\nSpectrum Enterprise provides modern enterprise technology solutions that meet the unique needs of some of the country's biggest brands. If you're looking to build your most successful career, support client growth and work alongside intelligent, driven professionals, you can do that. We're ready to go all in on your future and create an engaging environment. \\nBe part of the connection:\\nYou empower client businesses through technological innovation that meets network compliance and capital budgets. You manage a team of Data Engineers through the configuration, installation and deployment of existing and new network technologies. You collaborate with teams in person and digitally within an office environment.\\nHow you can make a difference:\\n\\nIdentify and develop processes to streamline production and maintain procedures.\\nProvide technical guidance and coordination to Data Engineering and other internal teams.\\nComplete all reports efficiently and accurately for senior leadership to leverage.\\nDevelop effective front-line leadership and manage a cross-functional technical team while encouraging growth.\\nMitigate risks by adhering to industry-specific local, state and federal regulations.\\n\\nWhat you bring to Spectrum Enterprise\\nRequired qualifications:\\n\\nExperience: Two or more years of project management experience; Five or more years of management experience in a 24/7 operations center; Eight or more years of network operations and implementation experience.\\nEducation: Master's degree in engineering, a related field or equivalent experience.\\nTechnical skills: Hands-on experience with network and element management tools; Knowledge of LAN, WAN, TCP/IP, SNMP and HFC networks; Proficient in Microsoft Office.\\nSkills: Issue resolution, prioritization, organizational, analytical and English communication skills.\\nAbilities: Deadline-driven with the ability to lead multiple projects simultaneously.\\n\\nPreferred qualifications:\\n\\nIndustry-specific network certifications. \\nTechnical skills: Knowledge of coding and scripting using Python, R or shell scripts; Experience with SQL, Tableau and ETL techniques; Expert in data storage; Familiar with Spark, Hadoop, JavaScript, API, Rest API or data extract APIs; History of working with Tableau, Denodo, Teiid or Jboss; Data workflow or data preparation platform experience using Informatica, Pentaho or Talend; Starburst and Object Storage\\nProficient in Microsoft Office. \\n\\nWhat you can enjoy every day:\\n\\nEmbracing diversity: A culture of excellence that celebrates diversity, innovative thinking and dedication to exceeding client expectations.\\nLearning culture: Company support in obtaining technical certifications.\\nDynamic growth: Paid training and clearly defined paths to advance within the company.\\nTotal rewards:Comprehensive benefits that encourage a work-life balance. \\n\\nApply now, connect a friend to this opportunity or sign up for job alerts.\\nENE601 2023-18050 2023 \\nHere, employees don't just have jobs, they build careers. That's why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success, supports all aspects of their well-being, and delivers real value at every stage of life.\\nA qualified applicant's criminal history, if any, will be considered in a manner consistent with applicable laws, including local ordinances.\\nGet to Know Us Charter Communications is known in the United States by our Spectrum brands, including: Spectrum Internet, TV, Mobile and Voice, Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you're joining a strong community of more than 93,000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most. Watch this video to learn more.\\nWho You Are Matters Here We're committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. EOE, including disability/vets. Learn about our inclusive culture.\\nApply Now\"}, {'job_title': 'Director, AI Data Platform', 'job_url': 'https://search.linkup.com/details/be8f69dd74413f98fca89b47dacc7f52', 'location': 'Austin, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 25, 894185), 'description': \"Our Company\\nChanging the world through digital experiences is what Adobe's all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We're passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen. \\nWe're on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!\\nThe Opportunity\\nWe are seeking a highly motivated data leader to head our centralized, ethically sourced training dataset repository for all the training groups in Adobe Research. As the AI Data Platform leader, you will be responsible for managing and curating a library of datasets that are relevant to Adobe's needs (mostly creative document formats), ensuring that they are high-quality, ethically sourced, and continuously enriched with useful metadata like styles.\\nYou will lead the development and maintenance of internal tools and platforms for dataset management, such as Databricks, used by your group and other groups at Adobe to manage AI datasets. Your role will also include working closely with the Sensei training platform team for a deep integration.\\nYou will also collaborate with our legal and ethics department, complying with data privacy and access regulations and analyzing our datasets' inherent biases and investing in reducing them. We take our customer's privacy very seriously at Adobe, and the managed datasets have to be continuously updated to respect the opt-in/opt-out customers' settings.\\nWhat you'll do\\n\\n\\nLeading the curation and organization of a centralized, ethically sourced training dataset repository for all the training groups in Adobe Research.\\n\\n\\nLeading the development and maintenance of internal tools and platforms for dataset management, such as Databricks.\\n\\n\\nBuilding a large repository of training datasets, enriching Adobe Stock data, purchasing custom datasets and adding public domain data on a variety of modalities - images, vectors, video, text.\\n\\n\\nCollaborating with the Sensei training platform team for a deep integration, ensuring that the dataset management platform is seamlessly integrated with the training platform.\\n\\n\\nCollaborating with the legal and ethics department to ensure compliance with data privacy and access regulations, and analyzing and reducing inherent biases in the datasets.\\n\\n\\nImplementing processes to update the datasets to respect opt-in/opt-out customers' settings.\\n\\n\\nLeading a team of data engineers, data scientists and data analysts in designing, building and maintaining a robust, scalable and efficient AI data platform\\n\\nMonitor, analyze and report on the performance of the platform, identifying areas for improvement and making data-driven decisions to optimize the platform's performance and return on investment.\\n\\nWhat you need to succeed\\n\\n\\nStrong experience in data management, including building and scaling data lake management systems and data pipelines\\n\\n\\nStrong experience in data curation and ethical sourcing of data, with knowledge of data privacy regulations\\n\\n\\nStrong experience in product management with a track record of delivering successful products and features in the AI/ML space\\n\\n\\nA Bachelor's or Master's degree in Computer Science, Electrical Engineering, or a related field, or equivalent industry experience.\\n\\n\\nStrong analytical and problem-solving skills, with the ability to think strategically and make data-driven decisions\\n\\n\\nExperience with agile development methodologies and best practices for software development\\n\\nStrong leadership skills, with the ability to inspire and motivate team members to achieve their best work\\n\\nOur compensation reflects the cost of labor across several\\u202f U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position\\u202fis $163,900 -- $335,200 annually. Pay\\u202fwithin this range varies by work location\\u202fand may also depend on job-related knowledge, skills,\\u202fand experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.\\nAt Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).\\nIn addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.\\nAdobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.\\nAdobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.\\nAdobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other's employees.\"}, {'job_title': 'Commercial Data Officer, Director', 'job_url': 'https://search.linkup.com/details/8168074cc2bfb8ef8d3535ee4674d4ce', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 30, 920377), 'description': 'ENGIE is committed to reshaping the energy future through the global implementation of a lower carbon energy economy in order to preserve the world\\'s natural resources. We are looking for talented and driven people who are committed to making the vision a reality.\\nThe Commercial Data Officer is responsible for identifying and managing enterprise data for GEM US and coordinating all platform related approaches to managing this data with our European counterparts. This position is responsible for forming and leading the Commercial Data Management Office (CDMO), participating in use case data classification and lead data related stakeholder committee meetings and informal communications required to manage the Company\\'s enterprise data. The Commercial Data Officer will assist in meeting global data governance program objectives, budget constraints and timelines associated with new projects and legacy data. The CDO will have responsibility for leading a cultural shift in which business staff and data users contribute to creating increased efficiency and value by providing meta data and assisting in the cataloging of enterprise data. This role will work directly with key data owners and IT to determine the plans for managing the associated enterprise data. All data inputs and output of IT and strategic business technology projects are subject to the review of the CDO. Enterprise data will be managed in Collibra via the collection and storage of the associated metadata. The upkeep of this metadata in Collibra will be the responsibility of the CDO and supporting resources. Data is the responsibility of the GEM US business as a whole, and as such, this position will be transversal with respect to supporting the different departments in GEM US and will work with the leadership team to set goals and execute the plan for data management. This role contributes to operational excellence goals of GEMS and also drives business value.\\nThis position is located in Houston, TX and reports to VP, Commercial Operations. \\nWhat you\\'ll do:\\n\\nPerform planning with stakeholders and execute the data management strategy\\nWork up front on technology projects to identify enterprise data and include this data in the scope of data governance\\nGuide acculturation of the company\\'s data policies within the organization\\nWork with data owners, data engineers, data champions and data stewards in the organization to build and manage a consistent, sustainable data management platform and build the required consensus across teams\\nEnter and maintain enterprise data into Collibra consistent with the rollout plan and leverage auto-population of metadata via Databricks and other associated digital platform tools\\nWork with the leadership team and project teams to prioritize including of enterprise data into the platform\\nEnable efficient, secure and reliable community access of all enterprise data for all departments with quality control measures implemented\\nWork closely with the market data services contracts leader to understand and catalog all related data sources and understand the use of this data in the organizations, while looking for opportunities to save on cost and avoid duplication of data services and assist with termination of data services that are no longer needed\\nWork with key data owners and data scientists to understand and catalog model data outputs that qualify for publishing as enterprise data\\nWork closely with IT to identify and catalog sources of enterprise data that come from our IT systems and understand the related integration of our enterprise data\\nCoordinate and communicate progress in setting up the data management functions\\nPresent status updates to the stakeholders and the Chief Data Officer for GEM (Europe) and resolve related issues\\nWork with leadership on developing KPIs and ROI on our data management investments\\nHire and lead data analysts to perform all related tasks associated with data management platform work\\nAssist in training other team members and business users where needed\\nReview and adopt the required Group level data processes and procedures to work in GEM US.\\nActs as a team member with all employees of ENGIE staff.\\nComplies with all ENGIE NA policies and procedures.\\n\\nData Management implementation in use cases:\\n\\nIdentifies strategic use cases with an opportunity to deploy the governance framework\\nParticipates in the proper specification and onboarding of new use cases\\nDrives data modeling in GEMS strategic data catalog\\nIdentifies and nominates data roles in use cases especially where data pain points are detected\\nManages follow-up action plans including the improvement of data quality checks and remediation\\n\\nTransversal Data Management responsibilities:\\n\\nGuarantees the proper evolution of the data catalog and quality of its content\\nAssists in developing and updating the Data Office roadmap\\nAssists in defining and monitoring KPIs & data objectives allowing to supervise the governance program\\nProvides support to enrich and improve the GEMS Data Toolbox (Collibra, Data Quality tooling...)\\nEnsures that IS & Enterprise Data Architects are aligned on identified data governance & management activities\\n\\nResource, budget & timeline monitoring:\\n\\nMonitors resource, budget & timeline in data use cases\\nMonitors resource & budget availability and allocation for the Data Office\\nHelp manage data subscriptions\\n\\nChange management / Acculturation:\\n\\nCommunicates and promotes the governance framework to identified audiences using prescribed channels\\nAssists in alignment with HR in concerning the development of skills of various data actors\\nWorks with HR to post new positions and manages work releases for contractors.\\nSupports onboarding of new data roles\\n\\nWhat you bring:\\n\\nBachelor\\'s degree in a business and/or related business technical field preferred\\nMinimum 15 years of general business experience\\nMinimum 5 years of work with data in IT systems, external data sources, associated data tools and some leadership/management experience\\nExperience with data governance and related operations\\nMinimum 5 years\\' experience supporting the data needs of a Power and/or Natural Gas related commercial operation\\nProficient with Microsoft Office products (Excel, Word, Visio, PowerPoint, PowerBI)\\nISO Market systems knowledge preferred\\nSQL Server database and modern cloud platform knowledge\\nMinimum 5 years professional experience in similar role or business analyst capacity with ideally a previous experience in data management initiatives, including the establishment of metadata in platforms and its subsequent upkeep\\nDeep knowledge of all the types of Commercial data used in our operations and analytical functions\\nExcellent interpersonal skills, eager to learn, work with diverse groups\\nAbility to manage tight timelines with respect to deliverables\\nAbility to interact at the detailed level with both business and IT teams and develop an understanding of the usage of enterprise data throughout GEM US\\nGood knowledge of the energy industry and associated data uses, preferably the Power Industry and/or the Natural Gas Industry\\nPrior experience with Collibra or competing data governance product\\n\\nAdditional Information/Conditions:\\n\\nMust be eligible to work for any U.S. employer without the need for sponsorship now or in the future\\nMust be willing and able to comply with ENGIE\\'s policy with respect to COVID vaccination and testing\\nMust be willing and able to comply with all ENGIE ethics and safety policies\\nAbility to meet highest attendance requirements\\nAbility to communicate effectively, both written and verbally\\nAbility to handle multiple assignments on a timely basis with a high degree of accuracy\\nAbility to use a company computer, calculator, \\nCould involve some lifting \\nWork environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job\\nReasonable accommodations may be made to enable individuals with the needed assistance to perform the essential functions \\nEligible for a hybrid schedule consisting of in-office and work-from-home opportunities\\n\\nWhy ENGIE?\\nENGIE North America isn\\'t just participating in the Zero-Carbon Transition, we\\'re leading it! Join us as we develop energy that is renewable, efficient, and accessible to everyone. \\nUnite with us in leading the transformation of the world of energy! ENGIE is looking for talented and motivated individuals to create the future of energy and customer solutions. Join a rewarding and flexible work environment that encourages innovation and creativity to help customers meet their energy challenges today and in the future. Are you up for the challenge?\\nAt ENGIE, our goal is to support, promote, and thrive on diversity, equity, and inclusion. We do so for the benefit of our employees, customers, products and services, and community. ENGIE is proud to be an equal opportunity workplace, and we are firmly committed to creating an equitable and inclusive environment for all employees.\\nWe are committed to providing employees with a work environment free of discrimination and harassment.\\u202f All employment decisions at ENGIE are based on business needs, job requirements, and individual qualifications.\\u202f ENGIE is committed to providing equal employment opportunities regardless of actual or perceived race, color, creed, religion, national origin, ancestry, citizenship, age, sex or gender (including pregnancy, childbirth, and related medical conditions), gender identity, or gender expression (including transgender status), sexual orientation, marital status, civil union, or domestic partnership status, military service or veteran status, physical or mental disability, protected medical condition, genetic information, or any other legally protected category (referred to as \"protected characteristics\") as defined by applicable federal, state or local law in the locations where we operate. \\n\\nSalary Range: $105,910 - $270,530, annually \\nActual salary offered may vary depending on geography, experience, education, internal pay alignment, or other bona fide factors \\nIn addition to salary, this position is eligible for a competitive bonus / incentive plan\\nAt ENGIE we understand that benefits matter, we offer competitive benefit options including medical, dental and vision coverage, life insurance, employer paid short-term and long-term disability insurance, paid vacation, holidays, sick leave, parental leave, and a 401(k) Retirement Savings Plan option with a company match\\nMore information can be found here: Discover our employee benefits \\n\\nENGIE complies with all federal, state, and local minimum wage laws. \\nYour talent acquisition partner can share more specific information regarding the salary for the position based on the work location. \\nIf you need assistance with this application or a reasonable accommodation due to a disability, you may contact us at ENGIENA-ENGIEHR@engie.com. This email address is reserved for individuals with disabilities in need of assistance and is not a means of inquiry regarding positions or application status.\\nBusiness Unit: GEMS\\nDivision: GEMS - BP AMERICAS\\nLegal Entity: ENGIE ENERGY MARKETING NA, INC.\\nContract Type: Permanent\\nJob Type: Full - Time\\nProfessional Experience: Skilled ( >3 experience\\nEducation Level: Bachelor\\'s Degree'}, {'job_title': 'Mgr., Data Warehouse - PCHP', 'job_url': 'https://search.linkup.com/details/e05a3579c979b3a7cc3a0cbf6fcf98bf', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 35, 422423), 'description': \"Interested in a career with both meaning and growth? Whether your abilities are in direct patient care or one of the many other areas of healthcare administration and support, everyone at Parkland works together to fulfill our mission: the health and well-being of individuals and communities entrusted to our care. By joining Parkland, you become part of a diverse healthcare legacy that's served our community for more than 125 years. Put your skills to work with us, seek opportunities to learn and join a talented team where patient care is more than a job. It's our passion.\\nPrimary Purpose\\nParkland Community Health Plan's (PCHP's) Manager, Data Warehouse is responsible for providing oversight of PCHP's Data Warehouse Team to advance and maintain PCHP's capabilities to capture, store, manage, and protect PCHP's internal data assets. The Manager is expected to provide hands-on leadership to ensure the effectiveness of PCHP's strategic Data Warehouse implementation efforts while also leveraging established best-practice around PCHP's ongoing data-management operations. \\nMinimum Specifications\\nEducation\\n\\nBachelor's degree in computer science, management information systems, information technology, statistics, mathematics, or related discipline is required.\\nMaster's degree in related disciplines is preferred.\\n\\nExperience\\n\\nSix (6) years of progressive experience working directly in complex Data Warehouse environments.\\nFour (4) years of experience performing heavy data integration across multiple source systems, including two (2) years using MS SSIS and SSMS.\\nFour (4) years of experience in Data Modeling and / or Database Administration, including two (2) years in a MS SQL Server environment.\\nTwo (2) years of experience with Data Warehouse implementation and data integration within a Healthcare Organization supporting both business and clinical functions.\\nTwo (2) years of experience supporting healthcare interoperability requirements.\\nTwo (2) years of leadership experience supporting data warehouse implementations and managing teams of database administrators, data engineers, and data architects.\\n\\nSkills or Special Abilities\\n\\nMust be critical thinker who is able to understand business / clinical requirements and architect solutions requiring complex data integration and data management\\nMust be skilled in data analysis and Infomart design\\nHas clear understanding of data environments across on-premise, cloud, and hybrid platforms\\nWorking knowledge of Data Vault 2.0 is strongly desired\\nAbility to work under pressure and manage team to meet deadlines\\nExcellent verbal and written communication skills\\nStrong organizational skills and the ability to manage multiple competing projects and deadlines\\nCustomer service orientation and ability to understand end-user needs\\nSound understanding of computer systems, networks, security, databases, and reporting\\nProficiency with Microsoft Office Excel, Word, and Outlook\\nWorking knowledge of healthcare related IT concepts such as EDI, HIE, and Interoperability\\n\\nResponsibilities\\n\\nProvides leadership, guidance, and support for the Data Warehouse Team\\nOversees day-to-day DW operations and supporting infrastructure, ensuring that processes are well defined and that process controls are in place to trigger required interventions\\nSupports approved IT projects in line with organizational objectives\\nResponsible for ensuring appropriate security controls exist for inbound and outbound DW processes\\nParticipates on PCHP's Data Governance Committee\\nCollaborates with Parkland Health IT and other business partners / vendors to ensure cross-system effectiveness\\nProposes strategic solutions and recommends new systems, software, and infrastructure\\nCommunicates ongoing progress on project status and ongoing process improvement opportunities\\nAssists in preparing annual budgets and operates in adherence with budget parameters.\\n\\nJob Accountabilities\\n\\nIdentifies and analyzes the design of jobs, work processes, workflows, etc. for the area and implements appropriate changes to improve effectiveness, productivity, and efficiency that support the overall goals of the department and Parkland.\\nStays abreast of the latest developments, advancements, and trends in the field by attending seminars/workshops, reading professional journals, actively participating in professional organizations, and/or maintaining certification or licensure. Integrates knowledge gained into current work practices.\\nMaintains knowledge of applicable rules, regulations, policies, laws, and guidelines that impact the area. Develops effective internal controls designed to promote adherence with applicable laws, accreditation agency requirements, and federal, state, and private health plans. Seeks advice and guidance as needed to ensure proper understanding.\\nDevelops and monitors annual budgets that ensure the department has the necessary funds to carry out the goals and objectives that have been established for the department.\\nDevelops, implements, monitors, and revises annual goals and objectives for the department that support the missions and objectives of Parkland.\\nSelects, trains, schedules, motivates, supervises, and evaluates employees making recommendations for disciplinary actions up to and including termination, to ensure maximum utilization of individual and group capabilities. Ensures that assigned employees receive opportunities to further their knowledge.\\n\\nParkland Health and Hospital System prohibits discrimination based on age (40 or over), race, color, religion, sex (including pregnancy), sexual orientation, gender identity, gender expression, genetic information, disability, national origin, marital status, political belief, or veteran status. As part of our commitment to our patients and employees' wellness, Parkland Health is a tobacco and smoke-free campus.\\nNearest Major Market: Dallas \\nNearest Secondary Market: Fort Worth \\nJob Segment: Patient Care, Healthcare Administration, Business Process, Data Analyst, Data Modeler, Healthcare, Management, Data\"}, {'job_title': 'Data & Control Systems Technician', 'job_url': 'https://search.linkup.com/details/2bd0537c5df16f00fa8c93da26d4233a', 'location': 'TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 40, 130818), 'description': \"SpaceX was founded under the belief that a future where humanity is out exploring the stars is fundamentally more exciting than one where we are not. Today SpaceX is actively developing the technologies to make this possible, with the ultimate goal of enabling human life on Mars.\\nDATA & CONTROL SYSTEMS TECHNICIAN\\nThe Data and Control Systems Technician will support the build-up and maintenance of our data and control systems. These systems consist of varying data acquisition and control hardware, wiring and interface harnesses, and a wide variety of instrumentation. The goal of the Data and Control Systems group is to meet a variety of test requirements to achieve safe, economical, and reliable access to space.\\nRESPONSIBILITIES:\\n\\nPerform complex technical assignments involving instrumentation and data acquisition/processing systems\\nMaintain, calibrate, configure, monitor, test, troubleshoot, install, and repair instrumentation, process controls, data acquisition systems, and electrical systems\\nInvestigate, diagnose, correct, and document instrumentation or system malfunctions\\nAnalyze results of calibrations and processed data and assist in the interpretation of test data\\nAdjust, repair, or replace faulty components of test setups and equipment\\nLay out, build, test, troubleshoot, repair, and modify developmental and production electrical and electronic units, assemblies, components, parts, equipment, and systems\\nConfigure the data acquisition hardware\\nPerform wire terminations to a variety of instruments and verify sensor health: pressure transducers, thermocouples, valves, limits and flow meters\\nInstall connectors, connector pins, terminals and lugs\\nPerform continuity checks, locate and correct wiring errors using measuring instruments such as ohmmeters and sequential continuity checkers\\nAdjust, calibrate, align, and modify circuitry and components and record effects on unit performance\\nRead and interpret planning documents, schematics, wiring diagrams, specifications, drawings, manuals, blueprints and engineering sketches\\nPerform lay out and wiring of electrical panels\\nCollaborate with design engineers to troubleshoot failures and issues derived from test data\\nPerform other related duties, as assigned, for the purpose of ensuring an efficient and effective work environment\\n\\nBASIC QUALIFICATIONS:\\n\\nAssociate degree in instrumentation, control technology, electrical systems, or other electrical field (3+ years of professional experience working with controls or electrical systems will be considered in lieu of degree)\\n2+ years of experience working with instrumentation such as: pressure transducers, thermocouples, valves, flow meters, multimeters or oscilloscopes \\n\\nPREFERRED SKILLS AND EXPERIENCE:\\n\\nExperience working with any of the following instrumentation: resistance temperature devices (RTDs), silicon diode temperature devices, strain gauges, load cells, displacement transducers, pressure transducers, thermocouple, and flow meters (turbine, coriolis, and ultrasonic)\\nBasic knowledge of Wheatstone bridge theory, ability to apply ohms law, and an understanding of DC electronics\\nOperational knowledge of an oscilloscope and multi-meter, soldering wires and connectors, operation of various crimping tools, wire stripping, continuity testing, pinning out a military type connector, routing and tie wrapping cables, drilling and tapping holes, and building junction boxes\\nSystem level trouble-shooting skills and the ability to logically solve instrumentation system problems and determine corrective action\\nExperience with Variable Frequency Drives and motor starters and knowledge in troubleshooting\\nKnowledge in signal conditioning concepts for various types of sensors, to include the following: thermocouple Types K, S, and E; TC bonding concepts: resistance weld on and adhesive bond on types; TC probes through thermowell sheaths; cold junction compensation concepts\\nBackground should include experience with the following devices: DC power supplies, DC-DC convertors, UPS installations, heat shrink tubing, cable harnessing, lacing, and proper strain relief concepts\\nWorking knowledge of transducers, operational amplifiers, and the knowledge of measurement techniques for temperature, pressure, flow, displacement, vibration and the application strain gauges are also highly desired. Ability to identify required data, data acquisition plans and test parameters, setting up equipment to conform to these specifications\\nWorking knowledge multiple bus architectures (PCI/PCIe, PXI/PXIe, GPIB, Serial, USB, etc.) and data communication technologies\\nDemonstrated capabilities in the development of comprehensive project plans that include all tasks; stage/gate milestones, and reviews necessary to successfully develop and implement solutions\\nIntermediate skill level using Windows Operating Systems\\nIntermediate skill level using Microsoft Office (Excel, PowerPoint, Word, Outlook, OneNote)\\nKnowledge in data acquisition concepts, hardware, and interfacing (SCXI and PXI based)\\n\\nADDITIONAL REQUIREMENTS:\\n\\nFlight hardware typically is built in tight quarters and physical dexterity is required\\nAbility to lift heavy objects is required in this position, up to 25 lbs. unassisted\\nAbility to perform job duties that require standing, kneeling, crouching, twisting upper body, working in cramped positions in small openings and climbing hand over hand\\nAbility to work at elevated heights\\nTypically exposed to work in extreme outdoor environments – heat, cold, rain\\nWork performed in an environment requiring exposure to fumes, odors, and noise\\nSchedule varies depending on site operational needs; some travel required\\nValid driver's license\\n\\nCOMPENSATION AND BENEFITS: \\nPay range: \\nData & Control Systems Technician/Level 1: $21.00/hour \\nData & Control Systems Technician/Level 2: $26.00/hour \\nData & Control Systems Technician/Level 3: $31.00/hour \\nYour actual level and base salary will be determined on a case-by-case basis and may vary based on the following considerations: job-related knowledge and skills, education, and experience.\\nBase salary is just one part of your total rewards package at SpaceX. You may also be eligible for long-term incentives, in the form of company stock, stock options, or long-term cash awards, as well as potential discretionary bonuses and the ability to purchase additional stock at a discount through an Employee Stock Purchase Plan. You will also receive access to comprehensive medical, vision, and dental coverage, access to a 401(k) retirement plan, short and long-term disability insurance, life insurance, paid parental leave, and various other discounts and perks. You may also accrue 3 weeks of paid vacation and will be eligible for 10 or more paid holidays per year. \\nITAR REQUIREMENTS:\\n\\nTo conform to U.S. Government export regulations, applicant must be a (i) U.S. citizen or national, (ii) U.S. lawful, permanent resident (aka green card holder), (iii) Refugee under 8 U.S.C. § 1157, or (iv) Asylee under 8 U.S.C. § 1158, or be eligible to obtain the required authorizations from the U.S. Department of State. Learn more about the ITAR here. \\n\\nSpaceX is an Equal Opportunity Employer; employment with SpaceX is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender, national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other legally protected status.\\nApplicants wishing to view a copy of SpaceX's Affirmative Action Plan for veterans and individuals with disabilities, or applicants requiring reasonable accommodation to the application/interview process should notify the Human Resources Department at (310) 363-6000.\"}, {'job_title': 'Principal Data Engineer, Security Research, FedRamp (Xpanse)', 'job_url': 'https://search.linkup.com/details/583774b8cbe80af81bd416a603d1b3e4', 'location': 'Arlington, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 44, 837570), 'description': \"Description\\nTo comply with U.S. federal government requirements, U.S. citizenship is required for this position \\nOur Mission \\nAt Palo Alto Networks everything starts and ends with our mission: \\nBeing the cybersecurity partner of choice, protecting our digital way of life. \\nOur vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we're looking for innovators who are as committed to shaping the future of cybersecurity as we are. \\nFLEXWORK is an employee-centric reimagining of how we work. We built FLEXWORK based on employee feedback – it is about flexibility, trust, and choice whenever possible. It's been a journey of disruption that has yielded the best of our values. We offer as much flexibility as possible, and choices that enable you to be most productive, including benefits that meet your needs and learning opportunities that you feel passionate about. \\nYour Career \\nWe're looking for a Data Engineer to join the Cyber Research team at Xpanse, the latest addition to Palo Alto Networks Cortex. \\nWe expect office-based employees to be in the office four days per week, with one day working from where they choose. We believe being together facilitates casual conversations and those magic moments where we can work on issues and ideas informally. These moments build capability and deepen trusted relationships and allow our people to feel safe in taking risks and being disruptive. Like so many companies, we are working through the details and things could change …. but in general if a role is deemed office-based we want our teams to be together four days per week. \\nYour Impact \\nAt Xpanse, you will: \\n\\nHelp bring a new threat intelligence product to market \\nDesign and implement methods to store, query, and analyze datasets ranging in size from gigabytes to petabytes in unconventional ways to produce unparalleled cybersecurity insights \\nDevelop novel techniques and approaches for understanding the Internet and characterizing data for insights relevant to cyber threat intelligence \\nEmpower threat intelligence analysts at Palo Alto and its customers to counter bad actors across the internet \\n\\nYour Experience \\nRequired \\n\\n4+ years of experience as a professional Software Engineer or Data Engineer for a SaaS business \\nProfessional experience designing and implementing solutions for large-scale data storage and analysis, using tools such as Google BigQuery, ClickHouse, Google BigTable, Apache HBase, or ElasticSearch \\nExperience developing and maintaining stream-processing pipelines using Apache Apache Beam or Apache Spark \\nFamiliarity with ETL management tools, such as Apache Airflow \\nExperience in software development, including some level of proficiency in Python \\nExcited to work closely with analysts to build a toolkit for discovering and tracking APT campaigns across the internet \\nHigh-level understanding of computer networks, protocols, and how the Internet works \\n\\nNice to have \\n\\nBackground or interest in threat intelligence and applied security \\nFamiliarity with datasets associated with cyber threat hunting \\nKnowledge of Google Cloud Platform services \\n\\nThe Team \\nXpanse's Cyber Research Engineering team is a cross-functional team that uses Xapnse's unique datasets to deliver cybersecurity insights and help defend Fortune 500 companies and government networks. \\nOur Cyber Research Engineers work with datasets ranging in size from gigabytes to petabytes in unconventional ways. Our work is varied, exciting, and meaningful. You will rapidly prototype new capabilities to address specific customer needs, you will work to improve our Internet intelligence through new forms of data collection, and you will develop, maintain, and use our tools to perform threat hunting. \\nOur Commitment \\nWe're trailblazers that dream big, take risks, and challenge cybersecurity's status quo. It's simple: we can't accomplish our mission without diverse teams innovating, together. \\nWe are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com . \\nPalo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics. \\nAll your information will be kept confidential according to EEO guidelines. \\nThe compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $139,400/yr to $225,500/yr. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found here . \\nLI-LC1\"}, {'job_title': 'AI Engineer', 'job_url': 'https://search.linkup.com/details/69f1094b7f43fc37163a6f1859e84ba8', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 49, 682900), 'description': \"Docyt, a FinTech startup that provides businesses with complete and accurate real-time financial data, is looking for an AI Engineer to join their team. As a member of the computer software industry, the successful candidate will play a pivotal role in developing Docyt's super app, applying AI across the accounting tech stack. Working alongside a highly skilled team, the AI Engineer will be at the forefront of Docyt's mission to bring order to financial data chaos, empowering businesses to make well-informed, timely decisions.\\nResponsibilities\\n\\nDesign and implement machine learning models, deep learning algorithms, and statistical models to improve the quality of financial data analysis.\\nCreate and maintain real-time data pipelines, ensuring that data is processed efficiently and accurately.\\nCollaborate with other engineers to integrate machine learning models and algorithms into the Docyt super app.\\nDevelop and maintain software tools and frameworks to support data processing, transformation, and visualization.\\nConduct experiments and tests to validate the performance of machine learning models and algorithms.\\nCommunicate technical ideas and research to cross-functional teams, as well as work with product management to develop new product features.\\nStay up to date with the latest industry trends and developments in artificial intelligence and machine learning.\"}, {'job_title': 'ML Engineer', 'job_url': 'https://search.linkup.com/details/e973139362d5b71b565e1a605e34d7e9', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 53, 956178), 'description': 'Docyt, a fast-growing Fintech startup based in Silicon Valley, is seeking a talented ML Engineer to join its team in revolutionizing financial data management. Docyt is a super app that uses AI across the entire accounting tech stack, digitizing financial data, automating income and expense workflows, continuously reconciling QuickBooks, and generating real-time financial statements. As the ML Engineer, you will work closely with our product and engineering teams to develop and implement machine learning models that will help our customers extract the maximum value from their financial data. You will also help build and deploy cloud-based machine learning infrastructures, develop and tune machine learning algorithms, and work closely with engineering to ensure optimal performance of the developed models.\\nResponsibilities\\n\\nDesign and develop innovative machine learning models and algorithms for financial data management.\\nBuild and deploy cloud-based machine learning infrastructures, including data pipelines, training, and scoring services.\\nImplement machine learning algorithms into production with engineering team.\\nWork to troubleshoot and optimize machine learning models performance.\\nParticipate in the design of experiments and data collection.\\nCollaborate closely with cross-functional teams, including product, engineering, and business teams, to ensure delivery of high-quality features in a timely manner.\\nStay up-to-date with the latest trends in machine learning, artificial intelligence, and cloud computing.'}, {'job_title': 'Application Engineer', 'job_url': 'https://search.linkup.com/details/0456f2ff642e3f75c8060a03aa6c406f', 'location': 'Houston, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 56, 58, 857795), 'description': 'LyondellBasell  \\nBasic Function  \\nLyondellBasell has fully committed to achieving its vision as “The Chemical Company of the Future” and an industry leader in the areas of Sustainability and Customer Experience. The Digital Enterprise that will act as the foundation for enabling this vision will be built upon three pillars: A modern and extensible technology architecture, an ERP backbone that supports new business models, and a team of talented technologists that are empowered to build innovative solutions and digital products.\\nAt the intersection of these pillars, the Data & Analytics Center of Excellence is building the data foundation and a catalog of data products, analytical applications, and enterprise services that give users across our company the tools, data, and guidance to generate insights.\\nThe Application Engineer will be a key member of the D&A CoE team, responsible for building, maintaining and performing analytical duties using the OT/IoT application that streams and manages real-time data from the plant sites. The role requires strong understanding of OT/IoT technologies, cloud applications and server management, as well as ability to work with cross-functional teams like security, cloud ops and infrastructure.  \\nRoles & Responsibilities  \\nResponsible for managing and maintaining the global deployment of the OT/IoT application.  \\nAct as a technical expert for the product, providing support (with SLA) and guidance to customers and internal teams.  \\nPerform upgrades on the application and the ingestion data pipelines based on the demand driven by the project teams.  \\nAssure the reliability of the data consumption and address the needs for any break fixes required.  \\nConfigure and deploy IoT devices and gateways in various environments.  \\nCollaborate with cross-functional teams, including engineering, architecture, security, infrastructure, product teams to gather requirements and manage the product to ensure it meets customer expectations.  \\nCreate and maintain documentation for the deployment of the OT application.  \\nOwn end to end operations, performance, hardware and servers required for the application from deployment to execution by working with the respective LYB teams and the vendor.  \\nWork with the site IT teams and engineers to understand the mapping of the systems to consume the tags from the instruments and assets.  \\nStay current with industry developments and advancements in IoT technology and cloud services.  \\nContinuous learning to get acquaintance with the engineering process at the site and its association with the data.\\nMin. Qualifications  \\nBachelor’s degree in Computer Science, Information Systems, Engineering or a related discipline.  \\nMinimum of 10 years of relevant IT experience  \\nMinimum of 5-7 years of experience in OT / IoT and cloud technologies  \\nExperience working with common OT/IoT protocols such as MQTT, OPC UA, etc.  \\nSolid experience in working with messaging and event-based services with a strong understanding on it operational impacts.  \\nFamiliarity with cloud platforms such as Azure, AWS, GCP.  \\n1-2 years of hands-on experience in implementing Kubernetes and Docker containers and how application workloads are deployed on it.  \\nStrong scripting skills in either PowerShell, Unix or Python.  \\nSolid understanding and actual hands-on experience in maintaining secured real-time data streaming solutions at scale.  \\nExperience with server management, including Linux administration and container orchestration.  \\nClear understanding of network protocols, architecture and design  \\nFamiliarity with REST API driven product integrations  \\nStrong problem-solving skills along with excellent communication and collaboration abilities.  \\nIndustrial, Manufacturing and OT background is a plus\\nPreferred Qualifications  \\nExperience working with real-time OT / IoT data ingestion products such as Uptake, Litmus, Emerson Plant Web Optics or similar.  \\nSome experience in working with Historians such as Aspen tech IP21, OSI PI, Honeywell, Bentley Nevada.  \\nExperience in working with Azure event hub, Azure IoT Hub, Azure Digital Twins.  \\nKnowledge in Control discipline such as Historians, Distributed control systems (DCS), Programmable logic controllers (PLC), Supervisory control and Data Acquisition (SCADA)  \\nReal-time ingestion: Kafka, Confluent, Message queues.  \\nIoT, event-driven, microservices, containers/Kubernetes in the cloud  \\nCertifications in Azure or any cloud data products or services.  \\nFunctional experience in manufacturing business domain.  \\nExperience with global enterprise environment or major consulting firm is a plus.\\nThe Application Engineer will work in a fast-paced environment and must be able to adapt to changing priorities and customer needs. The successful candidate will have a strong drive to learn and grow professionally and will be highly motivated to deliver high-quality solutions to customers.\\nLI-SS1\\nLI-Hybrid\\nCompetencies  \\nBuilds effective teamsCollaboratesCultivates innovationCustomer focusDemonstrates courageDrives resultsEnsures accountabilityInstills trust and exemplifies integrity\\nWe are LyondellBasell – a leader in the global chemical industry creating solutions for everyday sustainable living. Through advanced technology and focused investments, we are enabling a circular and low carbon economy. Across all we do, we aim to unlock value for our customers, investors and society. As one of the world’s largest producers of polymers and a leader in polyolefin technologies, we develop, manufacture and market high-quality and innovative products for applications ranging from sustainable transportation and food safety to clean water and quality healthcare. For more information, please visit www.lyondellbasell.com or follow @LyondellBasell on LinkedIn.\\nMust be at least 18 years of age and must be legally authorized to work in the United States (US) on a permanent basis without visa sponsorship.\\nLyondellBasell does not accept or retain unsolicited résumés or phone calls and/or respond to them or to any third party representing job seekers.\\nLyondellBasell is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, veteran status, and other protected characteristics. The US EEO is the Law poster is available here.'}, {'job_title': 'Software Engineer', 'job_url': 'https://search.linkup.com/details/7c59573b1db4da716c0b47f331b8ccaf', 'location': 'Plano, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 6, 715289), 'description': \"JobID: 210434301\\nCategory: Software Engineering\\nJobSchedule: Full time\\nPosted Date: 2023-07-17T15:49:48+00:00\\nJobShift: \\n:\\nDESCRIPTION:\\nDuties: Perform application design, development, and maintenance of the data warehouse. Perform, Extract, Transform, and Load (ETL) from source systems, staging tables, fact tables, and other objects. Provide support to the business reporting users and groups and assist them in the proper use of the data. Enhance the existing business solution for better application performance and efficiency. Translate business specifications into programming modules. Develop application test plans and test software at the unit level. Produce documentation for all phases of the data warehouse. Participate in code review and testing of the application solution and provide feedback. Identify and resolve the application related issues and participate in creating job-scheduling scripts.\\nQUALIFICATIONS:\\nMinimum education and experience required: Bachelor's degree in Computer Engineering, Computer Science, Information Technology, Data Analytics, or related field of study plus 5 [five] years of experience in the job offered or as Software Engineer, Application Developer, Senior Data Engineer, IT Analyst, or related occupation.\\nSkills Required: Requires experience in the following: Ab-Initio; Informatica Developer; ETL Design; data warehousing concepts including CDC and star schema; SQL; Java Spark Developer; Big Data Systems; HDFS; Java; Spark; UNIX; Hive; Junit; Microservices; Performance Testing; Shell Scripting; Hadoop; Software Development; and PRANA.\\nJob Location: 8181 Communications Pkwy, Plano, TX 75024.\"}, {'job_title': 'ML Engineer', 'job_url': 'https://search.linkup.com/details/d4e3395b2be9e478c4a77b8cb7514e51', 'location': 'Irving, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 11, 566106), 'description': \"When you're the best, we're the best. We instill an environment where employees feel engaged, satisfied and able to contribute their unique skills and talents while living and working as their authentic selves. We provide extensive opportunities for personal and professional development, building both employee competence and organizational capability to fuel exceptional performance through an inclusive environment both now and in the future.\\nSummary:\\nIn this role, you will facilitate and support the Machine Learning (ML) lifecycle using ML platforms by utilizing and building necessary infrastructure. You will support, onboard, and maintain models that are of strategic importance. You will partner with Data Scientists, cloud operations and stakeholder teams to implement production-grade models with necessary infrastructure, analytics and integrated workflow.\\nResponsibilities:\\n\\nAssist to design, architect, and execute building ML models.\\nParticipate in Agile team meetings to plan and estimate stories.\\nCreate and test algorithm prototypes based on project specifications.\\nTroubleshoot and address problems with deployed models to improve user experience.\\nEncourage innovation while experimenting and adopting new technologies.\\nWork closely with operations, data science and other teams to improve architecture and scalability.\\nRemain up to date on the latest innovations in machine learning.\\n\\nQualifications:\\n\\nRelevant degree in Computer Science, Machine Learning, Artificial Intelligence, Math or similar preferred.\\n5 or more years of relevant experience in ML development required. \\nSolid engineering foundation in ML or Artificial Intelligence (AI) required.\\nStrong knowledge of Python and R programming to develop software required.\\nStrong mathematics and statistics skills required.\\nExperience with technologies including ML, Natural Language Processing (NLP), data mining, distributed computing, and computer vision preferred.\\nIn-depth knowledge of ML data structures and modeling, software architecture, libraries and frameworks to create AI preferred.\\nCreative thinking skills to devise new solutions and unique approaches.\\nSound problem-solving skills to refine prototypes and troubleshoot performance issues.\\nYou must be authorized to work in the United States without sponsorship.\\n\\nLI-JB1\\nIDS\\nEstimated Hiring Range:\\n$102,400.00 - $152,200.00\\nThis position is also incentive eligible.\\nVizient has a comprehensive benefits plan! Please view our benefits here:\\nhttp://www.vizientinc.com/about-us/careers\\nEqual Opportunity Employer: Females/Minorities/Veterans/Individuals with Disabilities\\nThe Company is committed to equal employment opportunity to all employees and applicants without regard to race, religion, color, gender identity, ethnicity, age, national origin, sexual orientation, disability status, veteran status or any other category protected by applicable law.\"}, {'job_title': 'Software Engineer', 'job_url': 'https://search.linkup.com/details/555fc6d02699636e884b3dc51142ccdc', 'location': 'TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 16, 484332), 'description': \"SAIC is seeking qualified Software Engineers for a REMOTE opportunity supporting the US Air Force Agency for Modeling and Simulation (AFMS) program. \\nAFMS is the premier agency responsible for implementation, integration, and development of Modeling and Simulation (M&S) and training and analysis standards that support the US Air Force (USAF), Department of Defense (DoD), and mission partners requiring these capabilities to support the Warfighter in full-spectrum operations.\\nJOB DESCRIPTION: \\n\\nDesigns, develops, documents, tests and debugs application software.\\nConducts analysis and collaborates with subject matter experts in the planning, design, development, and utilization of electronic data processing systems for information storage, processing, presentation, manipulation, display, or reporting.\\nEnd product may be special use, customized, or commercial software.\\nDetermines computer user needs; analyzes system capabilities to resolve problems on program intent, output requirements, input data acquisition, programming techniques and controls; prepares operating instructions; designs and develops autonomous services, desktop applications, web applications, scripts, and utility programs.\\nEnsures software standards are met. \\nBachelor's and nine (9) years, Master's and seven (7) years experience; or relevant years of experience in lieu of degree.\\nMust be US Citizen and currently possess an Interim or Secret Clearance\\nDoD 8750 certification in IAT Level II certification or above (Security CE, CASP CE, CISSP, etc.) or ability to obtain within 90 days.\\nExperience with web applications including front end development, consuming and developing REST APIs.\\nExperience using PHP, JavaScript, HTML, CSS, Web Sockets.\\nExperience with SQL (MySQL, PostgreSQL) and/or NoSQL (MongoDB) Databases.\\nFamiliarity with Learning Management Systems (LMS) and Learning Record Stores (LRS).\\nFamiliarity with all or some of the following tools: Moodle, Big Blue Button, Rustici, IntelliBoard.\"}, {'job_title': 'Materials Engineer', 'job_url': 'https://search.linkup.com/details/aca3a0fa8155f3381d52cfede6fb584a', 'location': 'Sugar Land, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 21, 178644), 'description': \"Job Title: Materials Engineer\\nLocation: Sugar Land - United States\\nDescription:\\nThe Materials Engineer consults with field organization on materials related issues, applies seasoned technical knowledge to various engineering projects on materials and material processing issues providing innovative and cost-effective solutions.\\nResponsibilities:\\n\\nDevelop and evaluate innovations and concepts, including performing tests and simulations if needed, to determine the best way to address corrosion management. \\nAdvise on material selection, property data and failure avoidance.\\nDevelop and evaluate new materials through characterization, testing and analysis.\\nDevelop, evaluate and qualify special processes such as welding, heat treating, compounding and extrusion, and their applications.\\nPerform failure and predictive analyses, and data analysis to develop advancements for products, focusing on material selection, modification and processing effects.\\nProduce detailed technical reports and provide effective technical presentations to technical and management audiences.\\nProvide material consultation, training, and support to internal stakeholders (manufacturing, supply chain, sales, management, operations etc) and external stakeholders (customers, suppliers, subcontractor representatives etc).\\nInterface with suppliers and subcontractor representatives on material related activities.\\nShare expertise via SLB learning tools and expand the informal network throughout the organization: field, research, engineering, manufacturing, other domains, and clients.\\nComply with applicable company policies', including Personnel, Quality System and Health, Safety and Environment standards and procedures.\\n\\nQualifications and Experience:\\n\\nBS/MS degree in Corrosion, Metallurgy, Materials Science & Engineering, or related degree. Other qualifications may be considered based on relevant experience.\\n3 years minimum experience.\\nExcellent communication and leadership skills with demonstrated ability to influence and gain alignment at all organizational levels.\\nAble to travel to office, field locations and suppliers (domestic and international). Travel expectation is approximately 5%.\"}, {'job_title': 'Materials Engineer', 'job_url': 'https://search.linkup.com/details/31881776170c6b6125c87cee919c2b12', 'location': 'Katy, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 26, 210407), 'description': \"The Materials Engineer is responsible for evaluating new elastomer/rubber materials, processes, suppliers, and end applications.\\u202f This person applies seasoned technical knowledge to various engineering projects on materials and material-processing issues. The overarching goals of the projects are to improve the performance, reliability, and sustainability of elastomer-enabled mechanical tools for subterranean exploration and production of energy. \\nRoles and Responsibilities:\\n\\n\\nAdvise on material selection, property data and failure avoidance.\\n\\n\\nDevelop and evaluate new elastomeric materials through characterization, testing, analysis, and modeling. \\u202fCandidates with experiences on FEA modeling are preferred. \\n\\n\\nDevelop, evaluate, and qualify special processes such as compounding, extrusion, injection molding, compression molding, additive manufacturing, and their applications. \\n\\n\\nWrite materials and process specifications and standards.\\n\\n\\nPerform failure and predictive analyses to develop advancements for products, focusing on material selection, modification, and processing effects.\\u202f Experiences in automation of data analysis are highly desired. \\n\\n\\nProvide material consultation to InTouch engineers, field locations and customers.\\n\\n\\nProvide material engineering review and approval of contract and subcontract statements of work and specifications.\\n\\n\\nPrepare and maintain source control and other procurement documentation and guidance for material procurement activities; assign quality requirements for procurements and subcontracts.\\n\\n\\nInterface with suppliers and subcontractor representatives on material related activities.\\n\\nProduce detailed technical reports and provide effective technical presentations.\\n\\nQualifications and Experience\\u202f:\\n\\n\\nBachelor's degree in Materials Science and Engineering, Chemistry, or Chemical Engineering with minimum 3 years direct experience\\n\\nCandidates must be able to legally work and reside in the US, without sponsorship\"}, {'job_title': 'Senior-System Engineer', 'job_url': 'https://search.linkup.com/details/81cd4d9569c17cddacdeb7032f6b9cc7', 'location': 'Dallas, TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 31, 292976), 'description': \"Job Overview \\nJoin AT&T and reimagine the communications and technologies that connect the world. We're committed to those who seek to discover the undiscoverable and dare to disrupt the norm. Bring your bold ideas and fearless risk-taking to redefine connectivity and transform how the world shares stories and experiences that matter. When you step into a career with AT&T, you won't just imagine the future – you'll create it. \\nAs a Senior System Engineer, you'll be responsible for translating business needs into technical solutions and defining solutions to problems through reasoned application of information technology.\\nThis position works in support of multiple ServiceNow environments, responsible for the overall health and performance of the platform. Applicants should have a solid understanding of the following ServiceNow applications, modules, technologies, and functionality.\\nKey Roles and Responsibilities: \\n\\nDesigns, develops, documents, and analyzes overall architecture of systems, including hardware and software. \\nDetermines integrated hardware and software architecture solutions that meet performance, usability, scalability, reliability, and security needs. \\nCoordinates design and integration of total system including subsystems. \\nResearches and recommends technology to improve the current systems.\\nSupports technical initiatives normally as part of a larger project.\\nWorks on development of new technologies or maintenance of existing technologies.\\nExchanges complex technical information and provides training and guidance to others in work area by breaking down information in a systematic and logical manner. \\n\\nOur Senior Systems Engineers earn between $115,600 – $231,100 annually. Not to mention all the other amazing rewards that working at AT&T offers. Individual starting salary within this range may depend on geography, experience, expertise, and education/training.\\nJoining our team comes with amazing perks and benefits:\\n\\nMedical/Dental/Vision coverage\\n401(k) plan\\nTuition reimbursement program\\nPaid Time Off and Holidays (based on date of hire, at least 23 days of vacation each year and 9 company-designated holidays)\\nPaid Parental Leave\\nPaid Caregiver Leave\\nAdditional sick leave beyond what state and local law require may be available but is unprotected\\nAdoption Reimbursement\\nDisability Benefits (short term and long term)\\nLife and Accidental Death Insurance\\nSupplemental benefit programs: critical illness/accident hospital indemnity/group legal\\nEmployee Assistance Programs (EAP)\\nExtensive employee wellness programs\\nEmployee discounts up to 50% off on eligible AT&T mobility plans and accessories, AT&T internet (and fiber where available) and AT&T phone\\n\\nA career with us, a global leader in communications and technology, comes with big rewards. As part of our team, you'll lead transformation surrounded by trailblazing industry leaders like you. You'll be empowered to go above and beyond – making a difference through company-sponsored initiatives or connecting and networking through one of our many employee groups. And regardless of where you're at in your career trajectory, you'll be rewarded by the impact that comes with making a difference in the lives of millions. With AT&T, you'll be a part of something greater, do incredible things and be rewarded with a chance to change the world.\\nReady to join the #LifeAtATT? Apply today!\\nRequired Qualifications:\\n\\n5-8 years of related experience.\\nServiceNow Certified System Administrator (CSA) certification\\nBasic Linux or Unix familiarity including basic shell scripting (Bash, CSH, etc…) and common tools such as vi/vim, grep, sed/awk, etc…\\nBasic Windows administration including PowerShell and/or batch scripting\\nJavaScript, HTML, AJAX, XML, REST, JSON, SOAP, and related web technologies including common API methods and design patterns\\nBasic networking and firewall technologies\\nAgile software development methodology (SCRUM)\\nITIL and ITSM certification or similar experience\\n\\nDesired Qualifications:\\n\\nDegree in Engineering, Information Systems, or related technical field.\\nServiceNow Certified Application Developer (CAD) certification\\nExperience in building multiple versions systems addressing performance and scale.\\nExperience developing technical documentation on applications and systems.\\nAbility to work with technical and business-oriented teams.\\nT Operations Management (ITOM)\\nIT Service Management (ITSM)\\nProject Portfolio Management (PPM)\\nHardware and Software Asset Management (HAM & SAM)\\nConfiguration Management Database (CMDB)\\nCommon Services Data Module (CSDM)\\nServiceNow scripting using JavaScript\\nMID server management\\nSingle Sign-On (SSO) configuration using both LDAP and SAML technologies\\nHW and SW Asset Discovery\\nCommon NOW development components including data sources, transforms and RTE, Integration Hub ETL Flow Designer, script includes, scoped applications, update sets, Delegated Development, etc…\\nCommon user access tools such as ACL's and Data Filters\\n\\nJob ID 2315682-1 Date posted 07/17/2023 Apply Now\"}, {'job_title': 'Network Engineer', 'job_url': 'https://search.linkup.com/details/20781ebc7249db57f76b8225f81bc778', 'location': 'TX', 'posted': datetime.datetime(2023, 7, 24, 15, 57, 36, 346560), 'description': \"Network Engineer \\nRemote\\nAbout Us\\nWhat do we do?\\nAt Soluna, we are using computing to accelerate a future where renewable energy is the primary source of energy in the world.\\nOur company is driven by three fundamental beliefs:\\n\\nThe world needs more renewable energy.... and computing can be a powerful catalyst for meeting that need.\\nStranded renewable energy -- usable clean energy that often goes to waste -- is one of the biggest unsolved problems for the economics of renewable energy.\\nSustainable Computing is not only ready for scale, but it will play an integral role in solving this problem.\\n\\nOur estimate is that around 225 Terawatt hours of renewable energy are spilled globally.\\nThat's a lot of energy!\\nMost renewable power plant operators struggle to sell all of the energy they generate. We build small-footprint data centers to buy & use all of their wasted energy. So they earn profits & tax credits for every megawatt they produce.\\nOur specialized data centers run computing-intensive applications powered by clean energy for: Cryptocurrency Mining • Artificial Intelligence • Deep Learning • Machine Learning • Scientific Computing • Natural Language Processing • Video Transcoding and more.\\nWe're solving the wasted renewable energy problem…\\nOur mission is to help power plant owners get more megawatts to the grid.\\nWith us, they can SELL. EVERY. MEGAWATT.\\nAnd…\\nWe help the data scientists of the world solve the world's most pressing problems with the comfort of knowing that they are not destroying the planet in the process.\\nWhy do we want you?\\nOur company is growing fast and we need people like you who want to be part of something big. People who want a real challenge in a place where they can learn about a host of emerging technologies, including blockchain, digital assets, and renewable energy. \\nWe need entrepreneurs at heart. \\nWe are a people-first, data-driven organization that is seeking individuals who want to do meaningful work. \\nWhat You'll Do\\nThe Network Engineer will be responsible for all aspects of Soluna's networks and ensure maximum uptime while continuously improving resiliency, security and maintainability. This role will include designing, documenting and increasing the security of new and existing networks. This role will be responsible for life cycle management, change control processes, new deployments, network traffic analysis, and maintenance of existing networks. Our Network Engineer will also interact and manage key vendor relationships for network support and OEM Equipment Providers. This role will require travel to Soluna facilities for network maintenance, upgrades, and initial standup. \\nOur ideal Network Engineer will take full ownership of our networks, they are the backbone of our business. The Network Engineer is key to ensuring maximum uptime for each data center location. Additionally, our expansion into HPC will rely heavily on fast and efficient network design. If you are a hands-on learner who loves problem-solving, owns their work but knows when to ask questions, and eager to be a part of the future of digital assets, then you will love working at Soluna.\\nThe Network Engineer will work as part of the Engineering organization and work closely with Engineering, Product, Operations and IT. Our ideal candidate is a great written and verbal communicator, self-directed, obsessed with attention to detail, works well in cross functional teams and driven to find the proven root cause of an issue. Reporting to the VP, Engineering, this role will be an experienced and efficient leader with excellent people skills, business acumen, and an exemplary work ethic.\\nYou will:\\n\\nDesign and implement new network solutions and improve the efficiency of current networks\\nInstall, configure, and support network equipment including firewalls, switches, VLANs, DNS and DHCP servers\\nManage tenders and procure network equipment \\nManage subcontractors involved with network installation, maintenance and support\\nConfigure firewalls, routing and switching to maximize network efficiency and security\\nConfigure and monitor AWS networking stacks\\nDevelop a monitoring and troubleshooting process in order to optimize and maintain network performance\\nDevelop a scheduled cadence and process for network updates and improvements\\nInvestigate faults in the network and generate a root cause analysis report after resolution\\nMaintain all network equipment at the latest versions and patches\\nDevelop a reporting process for network status to key stakeholders, especially non-technical experts\\nIdentify and raise critical issues in a timely manner to stakeholders\\n\\nWhat You Need to Get the Job Done\\n\\nExperience in AWS networking, VPN, and subnet control\\nExperience in designing, debugging and maintaining heavily VLAN'd networks\\nFamiliarity with both copper and fiber connections\\nComprehensive understanding of network protocols such as BGP, TCP/IP, UDP, multicast, Spanning tree, VRRT, OSPF and EIGRP\\nComprehensive knowledge of multiple DHCP servers such as DHCPd, Windows server, pfsense, DHCP failover, and the DHCP option 82 schema\\nFamiliarity with pfSense and Fortinet firewalls\\nFamiliarity with Dell, Buffalo, and TP-link layer 3 managed switches\\nExperience using or implementing network tools like Netflow, Infoblox, and others.\\nDemonstrated ability to monitor, analyze and evaluate networks, identify issues and provide solutions to ensure networks are operating reliably\\nExperience designing, implementing and troubleshooting Wi-FI and security infrastructure\\nExperience managing multiple projects simultaneously from design to implementation to ongoing operations\\n5+ years of experience as a network engineer in a corporate environment or datacenter\\nWillingness to travel up 25% and potentially on short notice\\nPotential weekend change windows and on call times\\nUseful (not required) networking certifications include:\\nCisco Certified Network Associate (CCNA)\\nCompTIA Network+\\nAWS Certified Advanced Networking\\nSolarWinds Certified Professional\\nDell DCA-Networking\\n\\nWhy join Soluna?\\nWe are a diverse, driven team of entrepreneurs, energy experts, private equity leaders, and engineers. We are passionate about making the world greener and we have conviction about how we will bring change on a global scale.\\nWe are equally as zealous about championing our teams, relentless about developing our people, and believe strongly that Soluna's goals and commitment to our mission are strengthened by our employee's voices. \\nWe offer all of our employees:\\n\\nCompetitive salary + equity \\nComprehensive health insurance (medical, dental, and vision) \\n401k plan with company match\\nLife insurance and disability plans \\nAmple paid time off\\nPaid parental leave\\nProfessional development opportunities\"}]\n"
     ]
    }
   ],
   "source": [
    "page_data = scrape_one_page(job_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_url</th>\n",
       "      <th>location</th>\n",
       "      <th>posted</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://search.linkup.com/details/6eeaf5490181...</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>2023-07-24 15:33:57.656435</td>\n",
       "      <td>Req ID: 246917 \\nNTT DATA Services strives to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://search.linkup.com/details/969f19899c23...</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>2023-07-24 15:34:01.933090</td>\n",
       "      <td>Job Title: (Back End) Data Engineer\\nLocation:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://search.linkup.com/details/052ed23cc835...</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>2023-07-24 15:34:06.239552</td>\n",
       "      <td>At Greystar, we've launched a program aimed at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://search.linkup.com/details/fd1b92f4facb...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>2023-07-24 15:34:10.839136</td>\n",
       "      <td>Position Summary\\nAre you an experienced, pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer II</td>\n",
       "      <td>https://search.linkup.com/details/e6bdfe673e3e...</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>2023-07-24 15:34:15.858708</td>\n",
       "      <td>Company: \\nCox Automotive - USA\\nJob Family Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Quality Engineer</td>\n",
       "      <td>https://search.linkup.com/details/0ec614fb5b74...</td>\n",
       "      <td>Fort Worth, TX</td>\n",
       "      <td>2023-07-24 15:39:54.293827</td>\n",
       "      <td>We are global, we are impacting the lives of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Materials Engineer</td>\n",
       "      <td>https://search.linkup.com/details/31881776170c...</td>\n",
       "      <td>Katy, TX</td>\n",
       "      <td>2023-07-24 15:39:58.488624</td>\n",
       "      <td>The Materials Engineer is responsible for eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>https://search.linkup.com/details/ab06b15b3391...</td>\n",
       "      <td>TX</td>\n",
       "      <td>2023-07-24 15:40:02.635328</td>\n",
       "      <td>NTT is a leading global IT solutions and servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>https://search.linkup.com/details/555fc6d02699...</td>\n",
       "      <td>TX</td>\n",
       "      <td>2023-07-24 15:40:07.398689</td>\n",
       "      <td>SAIC is seeking qualified Software Engineers f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Materials Engineer</td>\n",
       "      <td>https://search.linkup.com/details/aca3a0fa8155...</td>\n",
       "      <td>Sugar Land, TX</td>\n",
       "      <td>2023-07-24 15:40:12.319479</td>\n",
       "      <td>Job Title: Materials Engineer\\nLocation: Sugar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title                                            job_url  \\\n",
       "0        Data Engineer  https://search.linkup.com/details/6eeaf5490181...   \n",
       "1        Data Engineer  https://search.linkup.com/details/969f19899c23...   \n",
       "2        Data Engineer  https://search.linkup.com/details/052ed23cc835...   \n",
       "3        Data Engineer  https://search.linkup.com/details/fd1b92f4facb...   \n",
       "4     Data Engineer II  https://search.linkup.com/details/e6bdfe673e3e...   \n",
       "..                 ...                                                ...   \n",
       "70    Quality Engineer  https://search.linkup.com/details/0ec614fb5b74...   \n",
       "71  Materials Engineer  https://search.linkup.com/details/31881776170c...   \n",
       "72    Network Engineer  https://search.linkup.com/details/ab06b15b3391...   \n",
       "73   Software Engineer  https://search.linkup.com/details/555fc6d02699...   \n",
       "74  Materials Engineer  https://search.linkup.com/details/aca3a0fa8155...   \n",
       "\n",
       "          location                     posted  \\\n",
       "0        Plano, TX 2023-07-24 15:33:57.656435   \n",
       "1      Houston, TX 2023-07-24 15:34:01.933090   \n",
       "2       Irving, TX 2023-07-24 15:34:06.239552   \n",
       "3       Austin, TX 2023-07-24 15:34:10.839136   \n",
       "4       Austin, TX 2023-07-24 15:34:15.858708   \n",
       "..             ...                        ...   \n",
       "70  Fort Worth, TX 2023-07-24 15:39:54.293827   \n",
       "71        Katy, TX 2023-07-24 15:39:58.488624   \n",
       "72              TX 2023-07-24 15:40:02.635328   \n",
       "73              TX 2023-07-24 15:40:07.398689   \n",
       "74  Sugar Land, TX 2023-07-24 15:40:12.319479   \n",
       "\n",
       "                                          description  \n",
       "0   Req ID: 246917 \\nNTT DATA Services strives to ...  \n",
       "1   Job Title: (Back End) Data Engineer\\nLocation:...  \n",
       "2   At Greystar, we've launched a program aimed at...  \n",
       "3   Position Summary\\nAre you an experienced, pass...  \n",
       "4   Company: \\nCox Automotive - USA\\nJob Family Gr...  \n",
       "..                                                ...  \n",
       "70  We are global, we are impacting the lives of m...  \n",
       "71  The Materials Engineer is responsible for eval...  \n",
       "72  NTT is a leading global IT solutions and servi...  \n",
       "73  SAIC is seeking qualified Software Engineers f...  \n",
       "74  Job Title: Materials Engineer\\nLocation: Sugar...  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting to dataframe\n",
    "df = pd.DataFrame(page_data)\n",
    "df.to_csv('linkup.csv',index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
